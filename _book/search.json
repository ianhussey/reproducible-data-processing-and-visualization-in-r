[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reproducible Data Processing and Visualization",
    "section": "",
    "text": "Introduction\nThis Open Source eBook provides materials for the semester-long Master’s seminar course “Reproducible Data Processing and Visualization in R” that I deliver at the University of Bern’s Institute of Psychology.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-book",
    "href": "index.html#how-to-use-this-book",
    "title": "Reproducible Data Processing and Visualization",
    "section": "How to use this book",
    "text": "How to use this book\nThis book is made up of individual Quarto (.qmd) workbooks. Many of the exercises are easiest to complete in your own local copy of these .qmd files.\nI suggest that you download the .zip file of all the .qmd files and their supporting data and cheatsheets and use the eBook as a reference book. If the the .zip file does not contain the most recent versions, please contact me and I’ll updated it. If I’m slow or you’re feeling impatient, you can also download the most recent versions from GitHub, along with the other files that create this eBook.\nYou can also copy and paste the code for any chapter directly from the website. Click the “&lt;/&gt; Code” button on the top right of each page to see the full .qmd file’s code. You can copy and paste this into a .qmd file. However, it’s probably easier to download all the .qmd files and data as mentioned above.\nLearning to code is a practice skill. Almost anyone can become competent in writing reproducible code for data processing and visualization with practice. More than anything else, completing this course requires that you practice in your own time, using not only the examples provided but also ones you create yourself. Take real data sets from your own studies, or the thousands available on the Open Science Framework (osf.io), or create simulated messy datasets with my R package {truffle} and practice.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#other-learning-resources",
    "href": "index.html#other-learning-resources",
    "title": "Reproducible Data Processing and Visualization",
    "section": "Other learning resources",
    "text": "Other learning resources\nThere are many excellent Open Source resources to learn R and {tidyverse} for data processing and visualization. Readers are encouraged to seek them out to support the materials already provided in this book. I can particularly recommend the following ones:\n\nLisa DeBruine et al.’s (2021) Open Source textbook Data Skills for Reproducible Research\n\nSection on {dplyr}\nSection on {tidyr}\n\nAllison Horst’s interactive web app for learning {dplyr}\nHadley Wickham’s Open Source textbook R For Data Science (aka R4DS)\n\nSection on data transformation\n\nGarrick Aden-Buie’s tidyexplain gifs for understanding how {tidyr}’s pivot functions work\ndatasciencebox.org\n\nInteractive tutorials that very useful for practicing processing and visualization skills once you’ve already learned the functions (i.e., don’t start here)\n\nPractice the functions ggplot\nPractice the functions ggplot, pipe, mutate\nPractice the functions ggplot, pipe, select, arrange, summarize, count, filter\nPractice the functions count, arrange, summarize\n\nRecorded presentations on many relevant topics",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#find-me-elsewhere",
    "href": "index.html#find-me-elsewhere",
    "title": "Reproducible Data Processing and Visualization",
    "section": "Find me elsewhere",
    "text": "Find me elsewhere\nYou can find my recent and current research interests, a summary of the courses I teach, and occasional blog posts on my personal website mmmdata.io.\nYou can find me on Bluesky at @ianhussey.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "Reproducible Data Processing and Visualization",
    "section": "Contributing",
    "text": "Contributing\nIf you are interested in contributing to or adapting this eBook, all code and data are available on GitHub.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/setup.html",
    "href": "chapters/setup.html",
    "title": "1  Installation and setup",
    "section": "",
    "text": "1.1 Install the base R language and the RStudio IDE\nYou should install the base R language and the RStudio IDE from here.\nThere are detailed steps available for Windows and Mac here.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installation and setup</span>"
    ]
  },
  {
    "objectID": "chapters/setup.html#rstudio-settings-and-options",
    "href": "chapters/setup.html#rstudio-settings-and-options",
    "title": "1  Installation and setup",
    "section": "1.2 RStudio settings and options",
    "text": "1.2 RStudio settings and options\n\n1.2.1 Important settings to change for reproducibility\nFor reproducibility, please ensure RStudio’s settings never save the objects in your environment to disk on exist or load them again when opening RStudio. Open the Tools&gt;Global Options menu, go to General, and untick the following box and set save to ‘Never’.\n\n\n\n1.2.2 RStudio themes\nRStudio can be skinned with different themes, including dark themes that may be easier on your eyes or are, at least, objectively cooler.\nThe objectively coolest theme of them all is Synthwave85, which can be installed by running the following line of code in RStudio’s console: rstudioapi::addTheme(\"https://raw.githubusercontent.com/jnolis/synthwave85/master/Synthwave85.rstheme\", TRUE, TRUE, FALSE)\nTo change themes, click the ‘Tools’ drop down menu, then ‘Global Options’, then ‘Appearance’, then ‘RStudio Theme’.\n\n\n\n1.2.3 RStudio fonts\nCertain monospaced fonts provide the advantage of rendering common R characters or functions more nicely.\nThis is the same code displayed using Monaco, a built-in font:\n\nAnd using JetBrainsMono, which supports rendering the base-R pipe (|&gt;) and non-equivalence symbols as single characters\n\nIf you prefer the latter, you can download JetBrainsMono from here and install on your computer. Restart RStudio, then change the font by clicking the ‘Tools’ drop down menu, then ‘Global Options’, then ‘Appearance’, then ‘Editor font’.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installation and setup</span>"
    ]
  },
  {
    "objectID": "chapters/setup.html#install-slack-and-github",
    "href": "chapters/setup.html#install-slack-and-github",
    "title": "1  Installation and setup",
    "section": "1.3 Install Slack and GitHub",
    "text": "1.3 Install Slack and GitHub\nIf you are reading this book as part of a course with me at the University of Bern, please:\n\nInstall the Slack app. You can download it for Windows here or for Mac here.\nI will send an invitation to the course’s Slack workspace to all students enrolled in the course. Please check your @students.unibe.ch email address.\nInstall the GitHub desktop app. You can download here.\nMake an account yourself on https://github.com and log into it on the GitHub desktop app. University of Bern does provide you access to a branded GitHub account, but you’ll lose access to it after you finish your studies, so it’s better to make your own private account.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installation and setup</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html",
    "href": "chapters/fundamentals.html",
    "title": "2  Fundamentals",
    "section": "",
    "text": "2.1 What’s the difference between Base R, RStudio IDE, and tidyverse?\nThis is an understandable point of confusion, so let’s clarify:\nThere is a long-standing debate about whether base R (alone) or R+{tidyverse} is better. Thankfully, I can resolve this question for you immediately: R+{tidyverse} is better. All hail the One True Language, {tidyverse}.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#whats-the-difference-between-base-r-rstudio-ide-and-tidyverse",
    "href": "chapters/fundamentals.html#whats-the-difference-between-base-r-rstudio-ide-and-tidyverse",
    "title": "2  Fundamentals",
    "section": "",
    "text": "Base R is the coding language that we learn in this course.\nRStudio IDE (Integrated Development Environment) is the application we use to write R code in. There are others but RStudio is the best option, although this could change in future.\n{tidyverse} is a set of R packages that enhance base R’s utility and usability, built around the concept of Tidy Data. We’ll learn about Tidy Data in another chapter. {tidyverse} arguably changes how we write R code so fundamentally that some people argue that R+{tidyverse} should be conceptualized as a meaningfully different language with different conventions and workflows.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#rstudio-ide-basics",
    "href": "chapters/fundamentals.html#rstudio-ide-basics",
    "title": "2  Fundamentals",
    "section": "2.2 RStudio IDE basics",
    "text": "2.2 RStudio IDE basics\nGet familiar with the different parts of the RStudio IDE user interface with this cheatsheet, which you can also download as a pdf here.\n\n\n2.2.1 Source versus Visual editor\nYou can view a .qmd file’s raw code in the ‘Source’ viewer. The button for this appears on the top left above the code in RStudio.\nScreenshot of Source editor mode:\n\nYou can also view the a live preview of the rendered file, including tables, plots, math, etc., using ‘Visual’ editor mode, although there will some simplifications compared to when you render a .html file. We’ll cover rendering in a later chapter.\nScreenshot of Visual editor mode:\n\n\n\n2.2.2 Keyboard shortcuts\nOnce you have learned about some of the concepts mentioned below in later chapters, it can be useful to come back to these cheatsheets to learn the keyboard shortcuts for them.\n\n\n\n2.2.3 Particularly useful shortcuts\nWindows\n\nInsert Chunk: Ctrl + Alt + I\nInsert Pipe (|&gt;): shift + Ctrl + M\nMulti-line typing: Alt + Mouse click-and-highlight multiple lines, then type\nMove cursor by word instead of by character: Alt + arrows\nHighlight words: Shift + alt + arrows\nFix Indentation: Mouse click-and-highlight multiple lines + Ctrl + I\nComment out (#) multiple Lines: Mouse click-and-highlight multiple lines, then Shift + Ctrl + C\n\nMac\n\nInsert Chunk: Cmd + Alt + I\nInsert Pipe (|&gt;): shift + Cmd + M\nMulti-line typing: Alt + Mouse click-and-highlight multiple lines, then type\nMove cursor by word instead of by character: Option + arrows\nHighlight words: Shift + option + arrows\nFix Indentation: Mouse click-and-highlight multiple lines + Cmd + I\nComment out (#) multiple Lines: Mouse click-and-highlight multiple lines, then Shift + Cmd + C\n\nYou can also change or set up additional keyboard shortcuts in the “Tools&gt;Modify keyboard shortcuts” drop down menu. For example, I have modified the shortcut to switch between Source viewer vs. Visual viewer to be “Cmd + `”.\nOf the above, multi-line typing is the one that reliably gets an audiable ‘whoa’ from audiences. It’s easier to see than explain:\n\nWhen you get a bit more experienced with RStudio, I highly recommend you check out this blog post on shortcuts to know about more advanced features such as Function/Variable Extraction, Renaming in Scope, Code Snippets, and advanced search and find-and-replace.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#dependencies",
    "href": "chapters/fundamentals.html#dependencies",
    "title": "2  Fundamentals",
    "section": "2.3 Dependencies",
    "text": "2.3 Dependencies\nInstall libraries from CRAN with install.packages(). This only needs to be done once, not on every run of the script.\n\n\nCode\ninstall.packages(tidyverse)\n\n\nIn-development libraries are sometimes not on CRAN and can be installed directly from GitHub with devtools::install_github().\n\n\nCode\ninstall.packages(devtools)\ndevtools::install_github(\"ianhussey/tides\") # username/repository\n\n\nNecessary packages (aka dependencies) can be loaded with library(). For tidiness, these should usually all be loaded at the start of your script. Some chapters in this book load libraries only when they’re used, to clearly introduce which packages provide which functions.\n\n\nCode\nlibrary(tidyverse) # umbrella package that loads dplyr/tidyr/ggplot2 and others",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#accessing-the-help-menu",
    "href": "chapters/fundamentals.html#accessing-the-help-menu",
    "title": "2  Fundamentals",
    "section": "2.4 Accessing the help menu",
    "text": "2.4 Accessing the help menu\nFor any function in a loaded package, simply type ? before the function’s name to bring up the help menu. This helps you understand the function’s purpose, its arguments, and outputs.\n\n\nCode\n?select\n\n\nIf you scroll to the bottom of a function’s help page, you’ll find an ‘Index’ hyperlink. Clicking this brings you to a list of all the package’s functions. Once you get nerdy, this can be a very useful way to discover and learn all a package’s functions.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#namespace-collisons-a-common-source-of-errors",
    "href": "chapters/fundamentals.html#namespace-collisons-a-common-source-of-errors",
    "title": "2  Fundamentals",
    "section": "2.5 Namespace collisons: a common source of errors",
    "text": "2.5 Namespace collisons: a common source of errors\nSome common packages have identically named functions with different syntax. For example, if you load both {dplyr} and {MASS}, use of the function select() can refer to either dplyr::select() or MASS::select(), and your code might not run if the other package is loaded.\nYou can see if you have two identically named functions loaded by opening the help menu and seeing if more than one entry appears (e.g. with ?select()).\nAvoid this by loading only the packages you need. Debug errors by thinking about these common namespace collisions:\n\n\n\n\n\n\n\n\n\nFunction\ntidyverse Source\nConflicting Package(s)\nNotes\n\n\n\n\nfilter\ndplyr\nstats\nstats::filter() is for signal processing (time series)\n\n\nlag\ndplyr\nstats\nDifferent semantics: dplyr::lag() is simpler\n\n\nselect\ndplyr\nMASS\nMASS::select() is for stepwise regression\n\n\nslice\ndplyr\nIRanges / S4Vectors\nCommon in Bioconductor workflows\n\n\nrename\ndplyr\nMASS\nMASS::rename() is deprecated, but may still load\n\n\nsummarise\ndplyr\nHmisc\nHmisc::summarize() differs in behavior\n\n\nintersect\ndplyr\nbase\ndplyr re-exports base::intersect()\n\n\nunion\ndplyr\nbase\ndplyr re-exports base::union()\n\n\nsetdiff\ndplyr\nbase\ndplyr re-exports base::setdiff()\n\n\ncount\ndplyr\nplyr\nDifferent behavior/output in plyr::count()\n\n\ndesc\ndplyr\nIRanges\nConflicts with IRanges sorting\n\n\nmutate\ndplyr\nplyr\nConflicts common when plyr is loaded\n\n\narrange\ndplyr\nplyr\nSubtle differences; dplyr preferred\n\n\n\nSolve this issue either by specifying which package should be used each time you use the function (e.g., dplyr::select() instead of select()) or by specifying below your library() calls which version is preferred:\n\n\nCode\nlibrary(conflicted)\nconflict_prefer(name = \"select\", winner = \"dplyr\")\n\n\n[conflicted] Will prefer dplyr::select over any other package.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#assignment-of-objects",
    "href": "chapters/fundamentals.html#assignment-of-objects",
    "title": "2  Fundamentals",
    "section": "2.6 Assignment of objects",
    "text": "2.6 Assignment of objects\nAssignment of objects is done via &lt;- by convention.\n\n\nCode\n# set the variable x to be the number 5\nx &lt;- 5\n\n# print the contents of x\nx\n\n\n[1] 5\n\n\nTechnically you can also use =, but it’s best to avoid it.\n\n\nCode\n# set the variable y to be the string \"hello\"\ny = \"hello\"\n\n# print the contents of y\ny\n\n\n[1] \"hello\"\n\n\nIt’s somewhat less well known, but you can also do “right-assignment” (-&gt;) instead of the much more common left assignment (&lt;-).\n\n\nCode\n# set the variable y to be the string \"really? yes.\"\n\"really? yes.\" -&gt; z\n\n# print the contents of z\nz\n\n\n[1] \"really? yes.\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#exercises",
    "href": "chapters/fundamentals.html#exercises",
    "title": "2  Fundamentals",
    "section": "2.7 Exercises",
    "text": "2.7 Exercises\n\n2.7.1 Fix indentation / white space\nEdit your local copy of this .qmd file to make the following changes. If you’re reading this as an eBook on the website, create a new .R file in RStudio on your computer (‘File&gt;New File&gt;R script’). Copy and paste the code below into that file.\nWe will cover the functions used in the code in later chapters - you don’t need to understand it yet. Notice that the indentation or ‘white space’ is somewhat chaotic.\nFix this with a keyboard shortcut: with your mouse, highlight the code and press Ctrl + I (Windows) or Cmd + I (Mac) to fix the indentation. Notice how much easier it is to read.\nYou can undo this with Ctrl + z (Windows) or Cmd + z (Mac) if you want to see it before/after again.\n\n\nCode\n# create table\ndat_processed_long %&gt;%\n  # summarize mean and SD by subscale\ndplyr::group_by(subscale) %&gt;%\n  dplyr::summarize(n = dplyr::n(),\nm = mean(score, na.rm = TRUE),\n               sd = sd(score, na.rm = TRUE)) %&gt;%\n  # round estimates \n  dplyr::mutate(m = janitor::round_half_up(m, digits = 2),\n  sd = janitor::round_half_up(sd, digits = 2)) %&gt;%\n# print nicer table\nknitr::kable(align = 'r') |&gt;\n  kableExtra::kable_styling()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html",
    "href": "chapters/reproducible_reports.html",
    "title": "3  Reproducible reports: Quarto and {knitr}",
    "section": "",
    "text": "3.1 Literate programming\nLiterate programming is the idea that code and text should be written in the same document to produce a narrative with reproducible results. It is therefore very suited to writing scientific reports and manuscripts.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports: Quarto and {knitr}</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#literate-programming",
    "href": "chapters/reproducible_reports.html#literate-programming",
    "title": "3  Reproducible reports: Quarto and {knitr}",
    "section": "",
    "text": "3.1.1 In line code\nCode can be written in ‘in line’ in the text as follows: 2. In the RMarkdown document, you have hover over the in line code and press enter or return to run the code.\n\n\n3.1.2 Code chunks\nFor any code that isn’t extremely short, you should write it in code chunks.\nThese are written as follows: three backticks followed by “{r}” specifies that it is a chunk of R code, then the code, then three more backticks to end the chunk. Note that backticks are not apostrophes! (` vs ’).\nYou can also insert a code chunk with Ctrl + Alt + I (Windows) or Cmd + Alt + I (Mac).\nOutput appears below chunks. You can run all code in a chunk by clicking the right-arrow button to the right of the chunk: \nYou can also run all previous chunks in a document not including the current chunk by clicking the downward arrow button to the right of the chunk: \nFor example:\n\n\nCode\n2+2\n\n\n[1] 4",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports: Quarto and {knitr}</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#rendering-and-reproducibilty",
    "href": "chapters/reproducible_reports.html#rendering-and-reproducibilty",
    "title": "3  Reproducible reports: Quarto and {knitr}",
    "section": "3.2 Rendering and reproducibilty",
    "text": "3.2 Rendering and reproducibilty\nQuarto (.qmd) and RMarkdown (.Rmd) files can produce .html files that can be viewed in any web browser. This has two key functions:\n\nIt allows you to make more attractive outputs with tables, plots, and results.\nIt can greatly increase reproducibility. Each time you ‘render’ a .html file from a .qmd/.Rmd, the code is run in a new R session in the background. The .html file is only created if all the code runs. This is extremely useful for ensuring that your code does indeed run, that you have all necessary packages loaded, etc. Note however that it does not ensure that your code is error free, that there are not unnecessary packages loaded, etc.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports: Quarto and {knitr}</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#markdown-formatting-and-levels-of-heading",
    "href": "chapters/reproducible_reports.html#markdown-formatting-and-levels-of-heading",
    "title": "3  Reproducible reports: Quarto and {knitr}",
    "section": "3.3 Markdown formatting and levels of heading",
    "text": "3.3 Markdown formatting and levels of heading\nQuarto (.qmd) and RMarkdown files (.Rmd) allow you to use markdown formatting. This is a very simple way to do basic formatting, such as headings, emphasis, bullet points and lists.\nMarkdown formatting can be used as follows.\nDon’t forget the space after the #, or spaces between lines to separate sections of different types!\n# Level 1 heading\n\n## Level 2 heading\n\n### Level 3 heading\n\nNormal text.\n\n*italic text*\n\n**bold text**\n\n- bullet points\n- bullet points\n\n1. numbered list\n2. numbered list\n\nDisplay an image in visual editor/on rendering:\n![](../images/r_meme.png)\nEach of the above are rendered as follows in the .html file once rendered:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports: Quarto and {knitr}</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#level-1-heading",
    "href": "chapters/reproducible_reports.html#level-1-heading",
    "title": "3  Reproducible reports: Quarto and {knitr}",
    "section": "3.4 Level 1 heading",
    "text": "3.4 Level 1 heading\n\n3.4.1 Level 2 heading\n\n3.4.1.1 Level 3 heading\nNormal text.\nitalic text\nbold text\n\nbullet points\nbullet points\n\n\nnumbered list\nnumbered list\n\nDisplay an image in visual editor/on rendering:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports: Quarto and {knitr}</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#table-of-contents-and-outline",
    "href": "chapters/reproducible_reports.html#table-of-contents-and-outline",
    "title": "3  Reproducible reports: Quarto and {knitr}",
    "section": "3.5 Table of contents and outline",
    "text": "3.5 Table of contents and outline\nLevels of heading are extremely useful for structuring your report.\n\nThey automatically appear as headings in the “Outline” section in RStudio, therefore allowing you to navigate your document easily. When you have a .qmd or .Rmd file open in RStudio, click the ‘Outline’ button to the top-right of the source file window, where this text appears, to see all the headings in your file. Click any of them to go to that heading in the document.\nWhen the file is rendered (.qmd) or knited (.Rmd) to a .html file, the levels of heading will appear as clickable links in the table of contents (assuming that your YAML header at the top of your file has toc: true, as this file does).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports: Quarto and {knitr}</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#math-typesetting-via-latex",
    "href": "chapters/reproducible_reports.html#math-typesetting-via-latex",
    "title": "3  Reproducible reports: Quarto and {knitr}",
    "section": "3.6 Math typesetting via LaTeX",
    "text": "3.6 Math typesetting via LaTeX\nYou can include math in line with LaTeX code placed between dollar signs: e.g., “$\\eta_{p}^{2}$ = 0.03” produces “\\(\\eta_{p}^{2}\\) = 0.03”.\nYou can also write longer chunks of LaTeX, for example to specify that the mean (\\(\\bar{x}\\)) is the sum of all elements of the vector \\(x\\) divided by number of elements in the vector (\\(n\\)).\nThis code:\n$$\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i.\n$$\nProduces this math:\n\\[\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports: Quarto and {knitr}</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#reading-processing-and-writing-data",
    "href": "chapters/reproducible_reports.html#reading-processing-and-writing-data",
    "title": "3  Reproducible reports: Quarto and {knitr}",
    "section": "3.7 Reading, processing, and writing data",
    "text": "3.7 Reading, processing, and writing data\nRaw data can be read in from .csv, .xlsx, SPSS .sav, and many other types of files. Raw data can be processed and tidied into analyzable data and saved to disk.\nWe will cover these functions in later chapters. For the moment, the point to appreciate is that clear, reproducible workflows are easy to write in R+tidyverse.\nRead the comments and code below to see if you can understand the general flow of what is being done, even without knowing these functions yet.\n\n\nCode\n# dependencies\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\n\n# load raw data\ndat_raw &lt;- readr::read_csv(\"../data/raw/data_raw_bfi.csv\")\n\n# process data\ndat_processed &lt;- dat_raw %&gt;%\n  # rename variable to make it clearer\n  dplyr::rename(race_iat = IAT_score) %&gt;%\n  # exclude participants with missing data or who did not meet performance criteria\n  dplyr::filter(complete_individual_differences_data == TRUE & exclude_iat == FALSE) %&gt;%\n  # calculate sum scores for the BFI personality subscales\n  dplyr::rowwise() %&gt;%\n  dplyr::mutate(openness = mean(c_across(starts_with(\"bfi_o\"))),\n                conscientiousness = mean(c_across(starts_with(\"bfi_c\"))),\n                extroversion = mean(c_across(starts_with(\"bfi_e\"))),\n                agreeableness = mean(c_across(starts_with(\"bfi_a\"))),\n                neuroticism = mean(c_across(starts_with(\"bfi_n\")))) %&gt;%\n  dplyr::ungroup() %&gt;%\n  # retain only the columns needed\n  dplyr::select(race_iat, openness, conscientiousness, extroversion, agreeableness, neuroticism)\n\n# create a directory to save processed data to \ndir.create(\"../data/processed\")\n\n# save data\nreadr::write_csv(dat_processed, \"../data/processed/data_processed_bfi_race_iat.csv\")\n\n# reshape to long format for tables and plots\ndat_processed_long &lt;- dat_processed %&gt;%\n  tidyr::pivot_longer(cols = c(openness, conscientiousness, extroversion, agreeableness, neuroticism),\n                      names_to = \"subscale\",\n                      values_to = \"score\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports: Quarto and {knitr}</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#tables",
    "href": "chapters/reproducible_reports.html#tables",
    "title": "3  Reproducible reports: Quarto and {knitr}",
    "section": "3.8 Tables",
    "text": "3.8 Tables\nSummary statistics such as sample sizes, means and Standard Deviations can be calculated, rounded, and presented in tables.\nAgain, we will cover these functions in later chapters. For the moment, simply notice that this is quite simple to do. As before, tead the comments and code below to see if you can understand the general flow of what is being done, even without knowing these functions yet.\n\n\nCode\n# dependencies\nlibrary(janitor)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# table\ndat_processed_long %&gt;%\n  # summarize mean and SD by subscale\n  dplyr::group_by(subscale) %&gt;%\n  dplyr::summarize(n = dplyr::n(),\n                   m = mean(score, na.rm = TRUE),\n                   sd = sd(score, na.rm = TRUE)) %&gt;%\n  # round estimates \n  dplyr::mutate(m = janitor::round_half_up(m, digits = 2),\n                sd = janitor::round_half_up(sd, digits = 2)) %&gt;%\n  # print nicer table\n  knitr::kable(align = 'r') |&gt;\n  kableExtra::kable_styling()\n\n\n\n\n\nsubscale\nn\nm\nsd\n\n\n\n\nagreeableness\n167\n4.00\n0.38\n\n\nconscientiousness\n167\n4.24\n0.48\n\n\nextroversion\n167\n4.18\n0.49\n\n\nneuroticism\n167\n3.91\n0.50\n\n\nopenness\n167\n4.37\n0.48",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports: Quarto and {knitr}</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#plots",
    "href": "chapters/reproducible_reports.html#plots",
    "title": "3  Reproducible reports: Quarto and {knitr}",
    "section": "3.9 Plots",
    "text": "3.9 Plots\nPlots can be made in {ggplot2}, e.g., scatter plots of the association between personality subscales and implicit racial bias.\nAs before, read the comments and code below to see if you can understand the general flow of what is being done, even without knowing these functions yet.\n\n\nCode\n# dependencies\nlibrary(ggplot2)\n\n# plot\nggplot(dat_processed_long, aes(score, race_iat)) +\n  geom_point(alpha = 0.7) +\n  facet_wrap(~ subscale) +\n  theme_linedraw() +\n  ylab(\"Implicit racial bias\") +\n  xlab(\"Personality subscale score\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports: Quarto and {knitr}</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#analyses",
    "href": "chapters/reproducible_reports.html#analyses",
    "title": "3  Reproducible reports: Quarto and {knitr}",
    "section": "3.10 Analyses",
    "text": "3.10 Analyses\nAnalyses can be run, and even their results extracted an interpreted, with the help of R packages such as {report} and {parameters} from the easystats cluster of packages.\n\n\nCode\n# dependencies\nlibrary(report)\n\n# fit correlation test\nres &lt;- cor.test(formula = ~ race_iat + extroversion, \n                data = dat_processed, \n                use = \"pairwise.complete.obs\")\n\n# create standard report of results\nreport::report_text(res)\n\n\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Pearson's product-moment correlation between race_iat and extroversion is\nnegative, statistically not significant, and small (r = -0.18, 95% CI [-0.39,\n0.05], t(73) = -1.52, p = 0.132)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports: Quarto and {knitr}</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#exercises",
    "href": "chapters/reproducible_reports.html#exercises",
    "title": "3  Reproducible reports: Quarto and {knitr}",
    "section": "3.11 Exercises",
    "text": "3.11 Exercises\nEdit your local copy of this .qmd file to make the following changes.\n\n3.11.1 Insert a new chunk and write code to install the following packages\nUse the install.packages() function to install the packages {tidyverse}, {janitor}, {knitr}, {kableExtra}, and {report}. Remember to exclude the “{}” and use quotation marks around the package names. Run the code to install these packages.\n\n\n3.11.2 Inserting a new chunk below this heading\nEither type it yourself using backticks or use the keyboard shortcut: Ctrl + Alt + I (Windows) or Cmd + Alt + I (Mac). Enter some code inside the chunk, e.g., “10 - 5”. Run the code in the chunk by clicking the green right-arrow: \n\n\n3.11.3 Add authorship\nAdd the following text to the YAML header on line 3, just under ‘title’: author: \"yourname\", and replace ‘yourname’ with your name. Click ‘render’ to create a reproducible report as a .html from this .qmd file. It will now list you as the author.\n\n\n3.11.4 Add date\nAdd the following text to the YAML header on line 4: date: today. Now when you render again, it will list today’s date so that you know when the report was created.\n\n\n3.11.5 Make the plot more colorful\nChange the ‘aesthetics’ call from aes(score, race_iat) to aes(score, race_iat, color = subscale). Run all previous chunks to reload and reprocess the data using this button:  Then, run the plot chunk again using this one to view your more colorful plot:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports: Quarto and {knitr}</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html",
    "href": "chapters/loading_data.html",
    "title": "4  Loading, viewing, and saving data: {readr} and {readxl}",
    "section": "",
    "text": "4.1 Using .csv files rather than Excel .xlsx files\nWhile Microsoft Excel’s .xlsx files provide many features, in the context of reproducible data processing and analysis they often introduce more risks than benefits.\nExcel allows the user to write formula to process and analyze data. However, Excel formula are less reproducible than R code as they are not always visible to the user and it is easy to make copy paste and cell location errors.\nThis isn’t merely speculation:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading, viewing, and saving data: {readr} and {readxl}</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#using-.csv-files-rather-than-excel-.xlsx-files",
    "href": "chapters/loading_data.html#using-.csv-files-rather-than-excel-.xlsx-files",
    "title": "4  Loading, viewing, and saving data: {readr} and {readxl}",
    "section": "",
    "text": "4.1.1 Case study 1: Reinhard & Rogoff (2010)\nIn the immediate aftermath of the 2008 Financial Crisis, an article by then-Harvard Professor and previously Chief Economist of the International Monetary Fund, Kenneth Rogoff, was heavily referenced by economists as part of the rationale to dramatically cut state spending (Reinhart & Rogoff (2010)). Countries including my own, Ireland, the U.K. and others adopted radical austerity policies and slashed funding to education and healthcare, from which we have not yet fully recovered from. Thomas Herndon, then a first year PhD student, found serious errors in Reinhart and Rogoff’s Excel formula (Herndon et al. (2014)). When corrected, the results indicated that austerity policies were harmful rather than helpful. Global economic history was changed by this data processing error.\n\nFor coverage of this fascinating and horrifying story:\n\nWikipedia page\nCommentary by Paul Krugman, Nobel Laureat, in the New York Times\nThe Guardian\nThe London Economic Review)\n\n\n\n4.1.2 Case study 2: Excel corrupts the genomics literature\nExcel’s automatic data conversion ‘feature’ turns certain text strings that also happen to refer to identifiers for genes (e.g., SEPT2, MARCH1) into dates or numbers. When genetics data is opened in Excel, automatically converted, and then saved, these silent changes propagated into data analyses. Ziemann et al. (2016) estimated that ~20% of papers with Excel gene lists contained such errors, demonstrating field-wide contamination of results and reproducibility risks (see coverage in Science News). Subsequent audits showed the problem persisted years later, despite awareness of the problem and guidance on how to prevent it, underscoring how Excel can corrupt bioinformatics workflows (see Abeysooriya et al., 2021).\n\n\n4.1.3 Other reasons to avoid Excel\nOther less extreme but nonetheless good reasons not to use Excel and .xlsx files also exist. Use colors (in cells or text) to carry information (e.g., “cells in red represent the outcome variables”), which can’t be easily read into R. Generally, colorful .xlsx files are a statistician’s nightmare.\nSo, we’ll use .csv files and avoid manually altering data outside of reproducible R workflows.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading, viewing, and saving data: {readr} and {readxl}</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#loading-.csv-files",
    "href": "chapters/loading_data.html#loading-.csv-files",
    "title": "4  Loading, viewing, and saving data: {readr} and {readxl}",
    "section": "4.2 Loading .csv files",
    "text": "4.2 Loading .csv files\n\n4.2.1 read.csv() and readr::read_csv()\nBase R’s read.csv() has a slightly better version in the {readr} package, readr::read_csv(), which is more explicit about how it parses column types. This can become useful in more complex data sets. I recommend you use read_csv() and will use it throughout this book.\n\n\n4.2.2 Relative vs. absolute paths: Avoid using setwd()!\nWhere to load data from?\nWhen we write .R scripts, we often use setwd() to define where files should be loaded from and saved to. The problem with setwd() is that it hard-codes file paths that are usually specific to the computer and user. For example, if I write an .R script that includes setwd(\"C:/Users/IanHussey/Documents/R_course/\"), before loading some data using read_csv(). If I email you this script and data file, it script won’t work on your machine unless your folders are identically named; you have to change the file path in setwd(). This lowers the reproducibility of the code, as it can’t be run trivially by other people on other computers.\nThis is because setwd() uses ‘absolute’ paths that point to a specific location in a directory structure. One of the very useful features of RMarkdown (.Rmd) and Quarto (.qmd) files is that they instead use ‘relative’ paths, which specify where a file or directory is in relation to the .Rmd or .qmd script. That is, the working directory is by definition wherever the .Rmd or .qmd file is, without being specified.\nIf I have a directory - located anywhere on my hard drive - called ‘R_course’ that contains the folders ‘code’ and ‘data’, and the ‘data’ directory itself contains the directories ‘processed’ and ‘raw’. Imagine the files within these directories are as follows:\nR_course/\n├── code/\n│   ├── analysis.qmd\n│   ├── data_shouldnt_usually_go_here.csv\n│   └── processing.qmd\n└── data/\n    ├── processed/\n    │   └── data_likert.csv\n    └── raw/\n        ├── data_demographics_raw.csv\n        ├── data_selfreports_raw.csv\n        ├── code_shouldnt_usually_go_here.qmd\n        └── data_behavioraltask_raw.csv\nBecause .qmd files use ‘relative’ paths, to load the ‘data_shouldnt_usually_go_here.csv’ file I only need to do the following, without any setwd() call:\n\n\nCode\ndat &lt;- read_csv(\"data_shouldnt_usually_go_here.csv\")\n\n\nOf course, code and data should be clearly separated within a project so ‘data_shouldnt_usually_go_here.csv’ should not usually go in that directory, as the name suggests.\nIf I instead wanted to load ‘data_likert.csv’, I would do this as follows. This data file actually exists in this project, so the code will run assuming you have the data files in the correct location relative to this .qmd script.\n\n\nCode\nlibrary(readr)\n\ndat_likert &lt;- read_csv(\"../data/raw/data_likert.csv\")\n\n\nThis is parsed as follows: ../ tells RStudio to go ‘up’ one directory level from ‘analysis.qmd’ to the ‘R_course’ folder that contains it. data/ then tells it to go ‘down’ one level into the ‘data’ folder inside ‘R_course’. Likewise, processed/ then tells it to go ‘down’ another level into the ‘processed’ folder, before loading the ‘data_likert.csv’ file.\nNote that ../ can be stacked to go ‘up’ multiple directory levels, e.g., ../../.\nAs long as you send move the entire ‘R_course’ folder and preserve the relative location between the code and the data, the .qmd file’s read_csv() call will still work. It doesn’t matter whether you the ‘R_course’ directory to somewhere else on your hard drive, or create a .zip file and email it to someone else, or distribute it via GitHub, or whether they’re using Windows or Mac.\nAlso note that because the directory ‘R_course’ is never specified in the read_csv() call, it can be called anything else and still work. The same goes for the name of the script which calls read_csv() - in this case, the script you’re reading is called ‘loading_data.qmd’ and the code still works.\nFYI, you can also use relative paths in regular .R files using the {here} library.\n\n\n4.2.3 Understanding directory structures with list.files(), list.dirs(), file.exists() and dir.exists()\nWhen trying to write relative paths to load or save data, it often takes me a few attempts to get it right. I go back and forth looking at the files and directories themselves in File Explorer (Widows) or Finder (Mac) and adjusting the R code.\nYou can also explore directory and file structures directly in R to make this easier using list.files() to list files and list.dirs() to list directories.\nList the files in the same folder as this .qmd file:\n\n\nCode\nlist.files() \n\n\n [1] \"binding_and_joining.qmd\"     \"data_transformation_1_files\"\n [3] \"data_transformation_1.qmd\"   \"data_transformation_2.qmd\"  \n [5] \"data_transformation_3.qmd\"   \"fundamentals.html\"          \n [7] \"fundamentals.qmd\"            \"images\"                     \n [9] \"license.qmd\"                 \"loading_data.qmd\"           \n[11] \"loading_data.rmarkdown\"      \"plots\"                      \n[13] \"privacy.qmd\"                 \"project_1.qmd\"              \n[15] \"project_2.qmd\"               \"reporting_files\"            \n[17] \"reporting.qmd\"               \"reproducible_reports_files\" \n[19] \"reproducible_reports.html\"   \"reproducible_reports.qmd\"   \n[21] \"reshaping_and_pivots_files\"  \"reshaping_and_pivots.qmd\"   \n[23] \"setup.html\"                  \"setup.qmd\"                  \n[25] \"strings_and_factors.qmd\"     \"structuring_projects.qmd\"   \n[27] \"sum_score.qmd\"               \"the_linear_model.html\"      \n[29] \"the_linear_model.qmd\"        \"the_pipe_and_renaming.qmd\"  \n[31] \"visualization_files\"         \"visualization.qmd\"          \n\n\nGo ‘up’ one directory and list the directories present:\n\n\nCode\nlist.dirs(path = \"../\", # 'up' one directory level\n          full.names = FALSE, # abbreviated dir names\n          recursive = FALSE) # only the directories, not their contents\n\n\n [1] \"_book\"             \".git\"              \".quarto\"          \n [4] \".Rproj.user\"       \"chapters\"          \"data\"             \n [7] \"images\"            \"old\"               \"project_architype\"\n[10] \"resources\"         \"site_libs\"        \n\n\nFrom the above we can see that the ‘data’ folder is up one directory level from the current .qmd file. Let’s confirm this with dir.exists() to check the directory does indeed exist:\n\n\nCode\ndir.exists(\"../data\")\n\n\n[1] TRUE\n\n\nOk, we’re getting close. So what’s in the ‘../data’ directory?\n\n\nCode\nlist.dirs(path = \"../data\", # 'up' one directory level, then 'down' into 'data'\n          full.names = FALSE, # abbreviated dir names\n          recursive = FALSE) # only the directories, not their contents\n\n\n[1] \"processed\" \"raw\"      \n\n\nIt contains the folders ‘processed’ and ‘raw’. What’s in the ‘raw’ directory?\n\n\nCode\nlist.files(\"../data/raw\") \n\n\n [1] \"data_age_gender_subset.csv\"         \"data_amp_raw.csv\"                  \n [3] \"data_amp_summary_subset.csv\"        \"data_demographics_raw_messy.csv\"   \n [5] \"data_demographics_raw.csv\"          \"data_likert_messy.csv\"             \n [7] \"data_likert.csv\"                    \"data_likert.rds\"                   \n [9] \"data_likert.xlsx\"                   \"data_raw_bfi.csv\"                  \n[11] \"data_selfreport_raw.csv\"            \"data_selfreport_summary_subset.csv\"\n[13] \"data_unique_id_subset.csv\"         \n\n\nIf we were looking to find and load the ‘data_likert.csv’ file, we know its directory path and that it exists. As already used above:\n\n\nCode\ndat_likert &lt;- read_csv(\"../data/raw/data_likert.csv\")\n\n\n\n\n4.2.4 Creating new directories with dir.create()\nSometimes, you might want to save files to a directory does not yet exist.\nOn the one hand, you could just open File Explorer (Windows) or Finder (Mac) and create a new directory manually (e.g., File&gt;New folder).\nHowever, we want our R code to be highly reproducible. Requiring manual steps like the above often breaks the code on other people’s machines.\nInstead, you can create folders directly from R using dir.create(). For example, if your analysis script is located at R_course/code/analysis.qmd, and you want to save plots that you create to a ‘plots’ directory within ‘code’, you can include this line in your ‘analysis.qmd’ file:\n\n\nCode\ndir.create(\"plots\")\n\n\n\n\n4.2.5 Other file and directory functions\nYou can also rename, copy, delete, and move files and directories with functions such as file.rename(), file.copy(), file.remove(), file.move(). Use the help menu to discover and understand these and other functions.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading, viewing, and saving data: {readr} and {readxl}</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#viewing-data-frames",
    "href": "chapters/loading_data.html#viewing-data-frames",
    "title": "4  Loading, viewing, and saving data: {readr} and {readxl}",
    "section": "4.3 Viewing data frames",
    "text": "4.3 Viewing data frames\n\n4.3.1 In your environment\nData frames (and other objects) that have already been loaded into your R environment will appear under the ‘files’ tab in RStudio.\nYou can view them by clicking on them in the ‘Environment’ tab in RStudio, running View(object) (where ‘object’ is your object’s name, e.g. View(dat_likert)), or clicking the object’s name in the Source window where code appears with Cmd+click (on Mac) or Ctrl+click (on Windows).\n\n\n4.3.2 Printing data frames below chunks\nTo print a data frame below the code chunk, you can;\nRun the object name:\n\n\nCode\ndat_likert\n\n\n# A tibble: 20 × 11\n    ...1  ...2  ...3  ...4  ...5  ...6 date      group subject likert_1 likert_2\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1     1     1     1     1     1     1 23.06.20…     1       1        1        4\n 2     2     2     2     2     2     2 23.06.20…     2       2        3        3\n 3     3     3     3     3     3     3 23.06.20…     2       3        2        1\n 4     4     4     4     4     4     4 23.06.20…     1       4        5        5\n 5     5     5     5     5     5     5 23.06.20…     1       5        3        3\n 6     6     6     6     6     6     6 23.06.20…     2       6        2        1\n 7     7     7     7     7     7     7 23.06.20…     1       7        2        1\n 8     8     8     8     8     8     8 23.06.20…     1       8        1        3\n 9     9     9     9     9     9     9 23.06.20…     1       9        2        5\n10    10    10    10    10    10    10 23.06.20…     2      10        5        2\n11    11    11    11    11    11    11 23.06.20…     1      11        1       NA\n12    12    12    12    12    12    12 23.06.20…     2      12        3       NA\n13    13    13    13    13    13    13 23.06.20…     2      13        2       NA\n14    14    14    14    14    14    14 23.06.20…     1      14        5       NA\n15    15    15    15    15    15    15 23.06.20…     1      15        3       NA\n16    16    16    16    16    16    16 23.06.20…     2      16        2       NA\n17    17    17    17    17    17    17 23.06.20…     1      17        2       NA\n18    18    18    18    18    18    18 23.06.20…     1      18        1       NA\n19    19    19    19    19    19    19 23.06.20…     1      19        2       NA\n20    20    20    20    20    20    20 23.06.20…     2      20        5       NA\n\n\nUse print():\n\n\nCode\nprint(dat_likert)\n\n\n# A tibble: 20 × 11\n    ...1  ...2  ...3  ...4  ...5  ...6 date      group subject likert_1 likert_2\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1     1     1     1     1     1     1 23.06.20…     1       1        1        4\n 2     2     2     2     2     2     2 23.06.20…     2       2        3        3\n 3     3     3     3     3     3     3 23.06.20…     2       3        2        1\n 4     4     4     4     4     4     4 23.06.20…     1       4        5        5\n 5     5     5     5     5     5     5 23.06.20…     1       5        3        3\n 6     6     6     6     6     6     6 23.06.20…     2       6        2        1\n 7     7     7     7     7     7     7 23.06.20…     1       7        2        1\n 8     8     8     8     8     8     8 23.06.20…     1       8        1        3\n 9     9     9     9     9     9     9 23.06.20…     1       9        2        5\n10    10    10    10    10    10    10 23.06.20…     2      10        5        2\n11    11    11    11    11    11    11 23.06.20…     1      11        1       NA\n12    12    12    12    12    12    12 23.06.20…     2      12        3       NA\n13    13    13    13    13    13    13 23.06.20…     2      13        2       NA\n14    14    14    14    14    14    14 23.06.20…     1      14        5       NA\n15    15    15    15    15    15    15 23.06.20…     1      15        3       NA\n16    16    16    16    16    16    16 23.06.20…     2      16        2       NA\n17    17    17    17    17    17    17 23.06.20…     1      17        2       NA\n18    18    18    18    18    18    18 23.06.20…     1      18        1       NA\n19    19    19    19    19    19    19 23.06.20…     1      19        2       NA\n20    20    20    20    20    20    20 23.06.20…     2      20        5       NA\n\n\n\n\n4.3.3 Printing nicer tables\nPrinting data frames by calling their name or using print() don’t produce very attractive tables. You can improve this using a combination of the {knitr} and {kableExtra} packages.\nNote that this code uses the ‘pipe’ (%&gt;%), which we cover in more detail in a later chapter. You don’t need to understand how it works yet, just the output that it creates.\n\n\nCode\nlibrary(knitr)\nlibrary(kableExtra)\n\ndat_likert %&gt;%\n  knitr::kable(align = \"r\") %&gt;%\n  kableExtra::kable_styling(full_width = FALSE)\n\n\n\n\n\n...1\n...2\n...3\n...4\n...5\n...6\ndate\ngroup\nsubject\nlikert_1\nlikert_2\n\n\n\n\n1\n1\n1\n1\n1\n1\n23.06.2022\n1\n1\n1\n4\n\n\n2\n2\n2\n2\n2\n2\n23.06.2022\n2\n2\n3\n3\n\n\n3\n3\n3\n3\n3\n3\n23.06.2022\n2\n3\n2\n1\n\n\n4\n4\n4\n4\n4\n4\n23.06.2022\n1\n4\n5\n5\n\n\n5\n5\n5\n5\n5\n5\n23.06.2022\n1\n5\n3\n3\n\n\n6\n6\n6\n6\n6\n6\n23.06.2022\n2\n6\n2\n1\n\n\n7\n7\n7\n7\n7\n7\n23.06.2022\n1\n7\n2\n1\n\n\n8\n8\n8\n8\n8\n8\n23.06.2022\n1\n8\n1\n3\n\n\n9\n9\n9\n9\n9\n9\n23.06.2022\n1\n9\n2\n5\n\n\n10\n10\n10\n10\n10\n10\n23.06.2022\n2\n10\n5\n2\n\n\n11\n11\n11\n11\n11\n11\n23.06.2022\n1\n11\n1\nNA\n\n\n12\n12\n12\n12\n12\n12\n23.06.2022\n2\n12\n3\nNA\n\n\n13\n13\n13\n13\n13\n13\n23.06.2022\n2\n13\n2\nNA\n\n\n14\n14\n14\n14\n14\n14\n23.06.2022\n1\n14\n5\nNA\n\n\n15\n15\n15\n15\n15\n15\n23.06.2022\n1\n15\n3\nNA\n\n\n16\n16\n16\n16\n16\n16\n23.06.2022\n2\n16\n2\nNA\n\n\n17\n17\n17\n17\n17\n17\n23.06.2022\n1\n17\n2\nNA\n\n\n18\n18\n18\n18\n18\n18\n23.06.2022\n1\n18\n1\nNA\n\n\n19\n19\n19\n19\n19\n19\n23.06.2022\n1\n19\n2\nNA\n\n\n20\n20\n20\n20\n20\n20\n23.06.2022\n2\n20\n5\nNA",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading, viewing, and saving data: {readr} and {readxl}</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#saving-.csv-files",
    "href": "chapters/loading_data.html#saving-.csv-files",
    "title": "4  Loading, viewing, and saving data: {readr} and {readxl}",
    "section": "4.4 Saving .csv files",
    "text": "4.4 Saving .csv files\nWriting .csv files to disk is as easy as loading them.\n\n\nCode\nwrite.csv(x = dat_likert, # the data frame to save\n          file = \"../data/raw/data_likert.csv\") # the file to save it to",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading, viewing, and saving data: {readr} and {readxl}</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#loading-.xlsx-files",
    "href": "chapters/loading_data.html#loading-.xlsx-files",
    "title": "4  Loading, viewing, and saving data: {readr} and {readxl}",
    "section": "4.5 Loading .xlsx files",
    "text": "4.5 Loading .xlsx files\nWhile .csv files are a good default file format to use for most projects, Excel, SPSS, and other file formats can also be loaded.\nThere are several packages available to load Excel files in particular. Any of them are fine except library(xlsx) which requires you to install rJava, which often causes compatibility issues. library(readxl) is a safer bet. Because excel files can contain multiple sheets, the source can be specified with the sheet argument.\n\n\nCode\nlibrary(readxl)\n\ndat_likert_1 &lt;- readxl::read_excel(path = \"../data/raw/data_likert.xlsx\", \n                                   sheet = \"data1\")\n\n\n\n4.5.1 Skipping rows when loading\nSometimes extra rows etc. make a data file harder to read into R. For example, the column names in ‘data_likert.xlsx’ are on the fourth row, causing a mess when you load the file.\nYou can view column names, types and the first few rows of data with head():\n\n\nCode\nhead(dat_likert_1)\n\n\n# A tibble: 6 × 5\n  `Date created: 02/04/2024` ...2  ...3    ...4     ...5    \n  &lt;chr&gt;                      &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;   \n1 subset: sample 1           &lt;NA&gt;  &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;    \n2 &lt;NA&gt;                       &lt;NA&gt;  &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;    \n3 date                       group subject likert_1 likert_2\n4 44735                      1     1       1        4       \n5 44735                      2     2       3        3       \n6 44735                      2     3       2        1       \n\n\nWith a few exceptions (e.g., removing identifying information before making data public), you should not manually modify raw data.\nIt might be tempting to open the .csv file in excel and manually delete those rows - don’t!\nHandle with with code, not by deleting the information in those rows. When using read_csv() or readxl::read_excel() this can be done using the skip argument.\n\n\nCode\ndat_likert_1 &lt;- readxl::read_excel(path = \"../data/raw/data_likert.xlsx\", \n                                   sheet = \"data1\", \n                                   skip = 3)\n\ndat_likert_1\n\n\n# A tibble: 5 × 5\n  date                group subject likert_1 likert_2\n  &lt;dttm&gt;              &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 2022-06-23 00:00:00     1       1        1        4\n2 2022-06-23 00:00:00     2       2        3        3\n3 2022-06-23 00:00:00     2       3        2        1\n4 2022-06-23 00:00:00     1       4        5        5\n5 2022-06-23 00:00:00     1       5        3        3",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading, viewing, and saving data: {readr} and {readxl}</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#combining-multiple-data-sets",
    "href": "chapters/loading_data.html#combining-multiple-data-sets",
    "title": "4  Loading, viewing, and saving data: {readr} and {readxl}",
    "section": "4.6 Combining multiple data sets",
    "text": "4.6 Combining multiple data sets\nYou can combine multiple data sets with (nearly) the same structure using dplyr::bind_rows(). In this case, ‘data_likert.xlsx’ have mostly the same columns, with sheet 1 also having the ‘likert_2’ column. Missing columns are filled with NA when using dplyr::bind_rows(). This has its advantages over base R’s rbind() which requires that column names must match between the objects.\n\n\nCode\nlibrary(dplyr)\n\ndat_likert_1 &lt;- readxl::read_excel(\"../data/raw/data_likert.xlsx\", sheet = \"data1\", skip = 3)\ndat_likert_2 &lt;- readxl::read_excel(\"../data/raw/data_likert.xlsx\", sheet = \"data2\", skip = 3)\n\ndat_likert &lt;- dplyr::bind_rows(dat_likert_1,\n                               dat_likert_2)\n\ndat_likert\n\n\n# A tibble: 10 × 5\n   date                group subject likert_1 likert_2\n   &lt;dttm&gt;              &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 2022-06-23 00:00:00     1       1        1        4\n 2 2022-06-23 00:00:00     2       2        3        3\n 3 2022-06-23 00:00:00     2       3        2        1\n 4 2022-06-23 00:00:00     1       4        5        5\n 5 2022-06-23 00:00:00     1       5        3        3\n 6 2022-06-23 00:00:00     1       6        1       NA\n 7 2022-06-23 00:00:00     2       7        3       NA\n 8 2022-06-23 00:00:00     2       8        2       NA\n 9 2022-06-23 00:00:00     1       9        5       NA\n10 2022-06-23 00:00:00     1      10        3       NA",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading, viewing, and saving data: {readr} and {readxl}</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#loading-and-writing-.rda-files",
    "href": "chapters/loading_data.html#loading-and-writing-.rda-files",
    "title": "4  Loading, viewing, and saving data: {readr} and {readxl}",
    "section": "4.7 Loading and writing .rda files",
    "text": "4.7 Loading and writing .rda files\nR objects can also be saved and loaded as .rda files. This can be very useful if you want to a) compress the data to make it smaller (using the compress = \"gz\" argument) or b) to preserve things like column types and factor levels. However, it does slightly reduce the interoperability of the data as not everyone else uses R.\n\n\nCode\nlibrary(readr)\n\n# write\nreadr::write_rds(x = dat_likert, \n                 file = \"../data/raw/data_likert.rds\",\n                 compress = \"gz\")\n\n# read\ndat_likert &lt;- readr::read_rds(file = \"../data/raw/data_likert.rds\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading, viewing, and saving data: {readr} and {readxl}</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#loading-multiple-data-files-at-once",
    "href": "chapters/loading_data.html#loading-multiple-data-files-at-once",
    "title": "4  Loading, viewing, and saving data: {readr} and {readxl}",
    "section": "4.8 Loading multiple data files at once",
    "text": "4.8 Loading multiple data files at once\nSome psychology software such as PsychoPy often saves each participant’s data as a separate .csv file. FYI you can write code to find all files of a given type (e.g., .csv) in a folder, read them all in, and bind all the data together as a single data frame. Note that this code uses some functions from the {purrr} package not explained here. It’s included here so that you know that it can be done quite easily.\n\n\nCode\nlibrary(purrr)\n\n# list all the files in a directory\nfile_names &lt;- list.files(path = \"../data/raw/individual_files\", \n                         pattern = \"\\\\.csv$\", \n                         full.names = TRUE)\n\n# use (or 'map') the read_csv function onto each of the file names \ndata_combined &lt;- purrr::map_dfr(.x = file_names, .f = read_csv)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading, viewing, and saving data: {readr} and {readxl}</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#exercises",
    "href": "chapters/loading_data.html#exercises",
    "title": "4  Loading, viewing, and saving data: {readr} and {readxl}",
    "section": "4.9 Exercises",
    "text": "4.9 Exercises\nCheck your learning with the following questions. Exercises involving running code should be run in your local copy of the .qmd files (see the Introduction to get a copy of them).\n\n4.9.1 How can you run all all the code chunks in this file with a single click?\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\nClicking the green down arrow button in the last chunk.\nSee the chapter on Reproducible Reports to refresh your knowledge.\n\n\n\nDo this in order to load all the objects into your environment so that you can complete the next exercise.\n\n\n4.9.2 What are three ways to view the contents of an object?\nDo all three ways for the dat_likert object.\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\nClicking the object’s name the ‘Environment’ tab in RStudio\nRunning View(object) (where ‘object’ is your object’s name)\nClicking the object’s name in the Source window (where code appears) with Cmd+click (on Mac) or Ctrl+click (on Windows)\n\n\n\n\n\n\n4.9.3 How would you know what arguments readxl::read_excel() takes?\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\nBy consulting the help menu with /Users/Ian-Hussey/Library/R/arm64/4.5/library/readxl/help/read_excel.\nSee the chapter on Fundamentals to refresh your knowledge.\n\n\n\n\n\n4.9.4 How to use relative paths to load files?\nUsing the file structure diagram under the Relative vs. absolute paths section above, what R code is needed to load the ‘data_shouldnt_usually_go_here.csv’ file from the ‘code_shouldnt_usually_go_here.qmd’?\n\n\n\n\n\n\nClick to show hint\n\n\n\n\n\nYou need to understand relative paths and use “../” to go ‘up’ directories.\n\n\n\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\ndat &lt;- read_csv(\"../../code/data_shouldnt_usually_go_here.csv\")\n\n\n\n\n\n\n\n4.9.5 Load and print nicely formatted table\nFollowing the same file structure as above, there is a file called “data_likert.csv” in the ‘raw’ data directory.\nWrite R code to:\n\nLoad that data file from this .qmd file, which is located in the ‘code’ directory.\nAssign it to an object called data_exercise.\nLoad the {kable} and {kableExtra} libraries.\nPrint data_exercise as nicely formatted table.\n\n\n\n\n\n\n\nClick to show hint\n\n\n\n\n\nSee the chapter on Fundamentals to refresh your knowledge on loading dependencies/libraries and object assignment.\nAdapt the code used in this chapter for the other steps.\n\n\n\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\ndata_exercise &lt;- read_csv(\"../data/raw/data_likert.csv\")\n\nlibrary(knitr)\nlibrary(kableExtra)\n\ndata_exercise %&gt;%\n  kable(align = \"r\") %&gt;%\n  kable_styling(full_width = FALSE)\n\n\n\n\n\n...1\n...2\n...3\n...4\n...5\n...6\n...7\ndate\ngroup\nsubject\nlikert_1\nlikert_2\n\n\n\n\n1\n1\n1\n1\n1\n1\n1\n23.06.2022\n1\n1\n1\n4\n\n\n2\n2\n2\n2\n2\n2\n2\n23.06.2022\n2\n2\n3\n3\n\n\n3\n3\n3\n3\n3\n3\n3\n23.06.2022\n2\n3\n2\n1\n\n\n4\n4\n4\n4\n4\n4\n4\n23.06.2022\n1\n4\n5\n5\n\n\n5\n5\n5\n5\n5\n5\n5\n23.06.2022\n1\n5\n3\n3\n\n\n6\n6\n6\n6\n6\n6\n6\n23.06.2022\n2\n6\n2\n1\n\n\n7\n7\n7\n7\n7\n7\n7\n23.06.2022\n1\n7\n2\n1\n\n\n8\n8\n8\n8\n8\n8\n8\n23.06.2022\n1\n8\n1\n3\n\n\n9\n9\n9\n9\n9\n9\n9\n23.06.2022\n1\n9\n2\n5\n\n\n10\n10\n10\n10\n10\n10\n10\n23.06.2022\n2\n10\n5\n2\n\n\n11\n11\n11\n11\n11\n11\n11\n23.06.2022\n1\n11\n1\nNA\n\n\n12\n12\n12\n12\n12\n12\n12\n23.06.2022\n2\n12\n3\nNA\n\n\n13\n13\n13\n13\n13\n13\n13\n23.06.2022\n2\n13\n2\nNA\n\n\n14\n14\n14\n14\n14\n14\n14\n23.06.2022\n1\n14\n5\nNA\n\n\n15\n15\n15\n15\n15\n15\n15\n23.06.2022\n1\n15\n3\nNA\n\n\n16\n16\n16\n16\n16\n16\n16\n23.06.2022\n2\n16\n2\nNA\n\n\n17\n17\n17\n17\n17\n17\n17\n23.06.2022\n1\n17\n2\nNA\n\n\n18\n18\n18\n18\n18\n18\n18\n23.06.2022\n1\n18\n1\nNA\n\n\n19\n19\n19\n19\n19\n19\n19\n23.06.2022\n1\n19\n2\nNA\n\n\n20\n20\n20\n20\n20\n20\n20\n23.06.2022\n2\n20\n5\nNA\n\n\n\n\n\n\n\n\n\n\n4.9.6 Check whether ‘data_likert.rds’ exists\nEarlier steps in this lesson saved a file called ‘data_likert.rds’ to the same directory as ‘data_csv.csv’.\nUse the functions list.dirs(), list.files(), and file.exists() to navigate the file structure, listing directories along the way, to write the file.exists() call that confirm that the file exists. It should return TRUE.\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\nlist.dirs(path = \"../\", # 'up' one directory level\n          full.names = FALSE, # abbreviated dir names\n          recursive = FALSE) # only the directories, not their contents\n\n\n [1] \"_book\"             \".git\"              \".quarto\"          \n [4] \".Rproj.user\"       \"chapters\"          \"data\"             \n [7] \"images\"            \"old\"               \"project_architype\"\n[10] \"resources\"         \"site_libs\"        \n\n\nCode\nlist.dirs(path = \"../data\", # 'up' one directory level, down one into 'data'\n          full.names = FALSE, # abbreviated dir names\n          recursive = FALSE) # only the directories, not their contents\n\n\n[1] \"processed\" \"raw\"      \n\n\nCode\nlist.files(path = \"../data/raw\", # 'up' one directory level, down one into 'data', down another into 'raw'\n           full.names = FALSE, # abbreviated dir names\n           pattern = \"\\\\.rds$\", # only return files ending in \".rds\"\n           recursive = FALSE) # only the directories, not their contents\n\n\n[1] \"data_likert.rds\"\n\n\nCode\nfile.exists(\"../data/raw/data_likert.rds\")\n\n\n[1] TRUE",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading, viewing, and saving data: {readr} and {readxl}</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html",
    "href": "chapters/the_pipe_and_renaming.html",
    "title": "5  The pipe and renaming: {dplyr}",
    "section": "",
    "text": "5.1 Exploring column names and rows\nAs in the last chapter, we load data using relative paths and read_csv() and view the first few rows with head().\nCode\nlibrary(readr) # for read_csv()\nlibrary(dplyr) # for %&gt;%\nlibrary(knitr) # for kable()\nlibrary(kableExtra) # for kable_extra()\n\ndat_demographics_raw &lt;- read_csv(file = \"../data/raw/data_demographics_raw_messy.csv\") \n\nhead(dat_demographics_raw) %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nsubject and session info columns\n...2\ntask structure columns\n...4\nresponse columns\n...6\n...7\n...8\n\n\n\n\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ndate\nSubject Code\nbuild\nblock code and trial number\nTrial Code\nKey response (use this!)\ncorrect\n0 ms onset RT\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\nUnfortunately, the ‘data_demographics_raw_messy.csv’ data set is, as its name suggests, somewhat messy. The column names are on the third row, not the first one.\nHow should you alter the above code to ignore the first two lines when reading the data in to R?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The pipe and renaming: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html#exploring-column-names-and-rows",
    "href": "chapters/the_pipe_and_renaming.html#exploring-column-names-and-rows",
    "title": "5  The pipe and renaming: {dplyr}",
    "section": "",
    "text": "Click to show answer\n\n\n\n\n\n\n\nCode\ndat_demographics_raw &lt;- read_csv(file = \"../data/raw/data_demographics_raw_messy.csv\", \n                                 skip = 2) # add skip = 2 to ignore the first two lines\n\nhead(dat_demographics_raw) %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nSubject Code\nbuild\nblock code and trial number\nTrial Code\nKey response (use this!)\ncorrect\n0 ms onset RT\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n\n\n\n\n\n\n\n5.1.1 Count rows and columns with nrow() and ncol()\nProcessing and cleaning any data set requires an understanding what it contains - as well as a thorough understanding of how the data was generated (e.g., the study’s design and specific implementation; what rows represent what measurement and in what way, etc.).\nA rudimentary but important step to understanding what a data set contains is to know how many rows and columns it contains.\nThis is useful to check at multiple steps of your data processing to make sure you have not done something wrong by gaining or losing columns or rows that you should not.\nNumber of rows:\n\n\nCode\nnrow(dat_demographics_raw)\n\n\n[1] 16\n\n\nNumber of columns:\n\n\nCode\nncol(dat_demographics_raw)\n\n\n[1] 8\n\n\n\n\n5.1.2 Viewing column names with colnames()\nHow would you know what variables are in a data frame? You can view the data frame, but it can also be useful to print them. Knowing what you have is one of the first steps to working with it.\n\n\nCode\ncolnames(dat_demographics_raw)\n\n\n[1] \"date\"                        \"Subject Code\"               \n[3] \"build\"                       \"block code and trial number\"\n[5] \"Trial Code\"                  \"Key response (use this!)\"   \n[7] \"correct\"                     \"0 ms onset RT\"              \n\n\nLater, when you’re used to using functions such as rename() and mutate(), you will often want a vector of column names that you can easily copy-paste into code, without all the extra white-space and including commas between them. For this, you can use dput():\n\n\nCode\ndput(colnames(dat_demographics_raw))\n\n\nc(\"date\", \"Subject Code\", \"build\", \"block code and trial number\", \n\"Trial Code\", \"Key response (use this!)\", \"correct\", \"0 ms onset RT\"\n)\n\n\nThis takes the output of colnames() and applies dput() to it. When your data processing calls muliple functions in a row, this could get complicated to read and write. It’s therefore time to introduce ‘the pipe’.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The pipe and renaming: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html#the-pipe",
    "href": "chapters/the_pipe_and_renaming.html#the-pipe",
    "title": "5  The pipe and renaming: {dplyr}",
    "section": "5.2 The pipe",
    "text": "5.2 The pipe\n\n5.2.1 What is the pipe?\nThe output of the function to the left of the pipe is used as the input to the function to the right of the pipe.\n[this function's output...] %&gt;%\n  [...becomes this function's input]\nFor example, the following code does the same thing with and without the pipe:\n\n\nCode\n# print all column names as a vector - without the pipe\ndput(colnames(dat_demographics_raw))\n\n\nc(\"date\", \"Subject Code\", \"build\", \"block code and trial number\", \n\"Trial Code\", \"Key response (use this!)\", \"correct\", \"0 ms onset RT\"\n)\n\n\nCode\n# print all column names as a vector - using the pipe\ndat_demographics_raw %&gt;%\n  colnames() %&gt;% \n  dput() \n\n\nc(\"date\", \"Subject Code\", \"build\", \"block code and trial number\", \n\"Trial Code\", \"Key response (use this!)\", \"correct\", \"0 ms onset RT\"\n)\n\n\n\n\n5.2.2 Why use the pipe?\nThe pipe allows us to write code that reads from top to bottom, following a series of steps, in the same way that humans would describe and conduct the steps. Without the pipe, code is written from the inside out in the way that R understands it but humans do not as easily.\nThe utility of the pipe becomes more obvious when there are many steps in the workflow.\nThe following example uses functions we have not learned yet. We’ll cover them in later chapters. For the moment, the point is to demonstrate the usage of the pipe.\nWithout the pipe:\n\n\nCode\nlibrary(dplyr) # for the pipe, rename, mutate, select, group_by, summarize\nlibrary(janitor) # for round_half_up\n\ndat &lt;- \n  mutate(\n    summarise(\n      group_by(\n        mutate(\n          rename(\n            readr::read_csv(file = \"../data/raw/data_amp_raw.csv\"),\n            unique_id = subject,\n            block = blockcode,\n            trial_type = trialcode,\n            rt = latency\n          ),\n          fast_trial = ifelse(rt &lt; 100, 1, 0)\n        ),\n        unique_id\n      ),\n      percent_fast_trials = mean(fast_trial) * 100\n    ),\n    percent_fast_trials = round_half_up(percent_fast_trials, digits = 2)\n  )\n\n# print the first few rows\nhead(dat, n = 10) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nunique_id\npercent_fast_trials\n\n\n\n\n4345805\n3.66\n\n\n13708908\n0.00\n\n\n14943693\n0.00\n\n\n32034696\n0.00\n\n\n47022865\n0.00\n\n\n59367911\n0.00\n\n\n72442795\n0.00\n\n\n75092407\n2.44\n\n\n83185292\n0.00\n\n\n85445170\n15.85\n\n\n\n\n\nNotice how the above code has to be written and read from the middle outwards: data is loaded, and what is loaded is used to rename() columns, and what the output is used to mutate() (create) a new column, whose output is used to summarize() across rows for each participant.\nThis becomes much more linear and human-readable when we use the pipe:\n\n\nCode\ndat &lt;- \n  # read data from csv\n  read_csv(file = \"../data/raw/data_amp_raw.csv\") %&gt;% # -&gt; pass the output onward to the next function\n  \n  # rename columns\n  rename(unique_id = subject,\n         block = blockcode,\n         trial_type = trialcode,\n         rt = latency) %&gt;% # -&gt; pass the output onward to the next function\n  \n  # create a new variable from existing ones\n  mutate(fast_trial = ifelse(rt &lt; 100, 1, 0)) %&gt;% # -&gt; pass the output onward to the next function\n  \n  # summarize across rows, clustered by participant\n  group_by(unique_id) %&gt;% # -&gt; pass the output onward to the next function\n  summarise(percent_fast_trials = mean(fast_trial)*100) |&gt;\n  # round the percents to two decimal places\n  mutate(percent_fast_trials = round_half_up(percent_fast_trials, digits = 2))\n\n# print the first few rows\nhead(dat, n = 10) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nunique_id\npercent_fast_trials\n\n\n\n\n4345805\n3.66\n\n\n13708908\n0.00\n\n\n14943693\n0.00\n\n\n32034696\n0.00\n\n\n47022865\n0.00\n\n\n59367911\n0.00\n\n\n72442795\n0.00\n\n\n75092407\n2.44\n\n\n83185292\n0.00\n\n\n85445170\n15.85",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The pipe and renaming: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html#implicit-arguments-the-pipe",
    "href": "chapters/the_pipe_and_renaming.html#implicit-arguments-the-pipe",
    "title": "5  The pipe and renaming: {dplyr}",
    "section": "5.3 Implicit arguments & the pipe",
    "text": "5.3 Implicit arguments & the pipe\nAs in other cases in R, arguments can be passed to functions ‘explicitly’ (by naming the argument) or ‘implicitly’ (without names).\nHow the pipe works can be slightly clearer if we use explicit arguments.\nThe pipe passes the output of the preceding function on to the next function as ‘.’:\n\n\nCode\ndat_demographics_raw %&gt;% # output passed forward as '.'\n  head(x = .) %&gt;% # output passed forward as '.'\n  kable(x = .) %&gt;% # -&gt; output passed forward as '.'\n  kable_classic(kable_input = .,\n                full_width = FALSE)\n\n\n\n\n\ndate\nSubject Code\nbuild\nblock code and trial number\nTrial Code\nKey response (use this!)\ncorrect\n0 ms onset RT\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n\n\n\nIf not passed explicitly, the input is passed to the next function’s first argument OR, if the funtion takes the ‘.data’ argument (i.e., most {tidyverse} functions) it is passed to ‘.data’:\n\n\nCode\ndat_demographics_raw %&gt;% # output passed forward to first argument\n  head() %&gt;% # output passed forward to first argument\n  kable() %&gt;% # -&gt; output passed forward to first argument\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nSubject Code\nbuild\nblock code and trial number\nTrial Code\nKey response (use this!)\ncorrect\n0 ms onset RT\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n\n\n\n\n5.3.1 The two pipes: %&gt;% vs. |&gt;\n%&gt;% is the original pipe created for the {magrittr} package and used throughout the tidyverse packages. It is slightly slower but also more flexible because it can pass to the ‘.data’ argument.\n|&gt; is a version of the pipe added more recently to base-R. It is slightly faster but less flexible. This speed only matters if you’re doing this with much larger data sets or very frequently (e.g., in Monte Carlo simulations).\nThe base R pipe (|&gt;) is less intelligent behind the scenes. It always supplies the input as the first argument and can’t handle passing to ‘.data’. If you want to pass its output explicitly, you use ‘_’ instead of ‘.’. However, in my experience, this works imperfectly and not all functions will accept it. Example of explicit passing with the base R pipe |&gt;:\n\n\nCode\ndat_demographics_raw |&gt; # output passed forward as '_'\n  head(x = _) |&gt; # output passed forward as '_'\n  kable(x = _) |&gt; # output passed forward as '_'\n  kable_classic(kable_input = _,\n                full_width = FALSE)\n\n\n\n\n\ndate\nSubject Code\nbuild\nblock code and trial number\nTrial Code\nKey response (use this!)\ncorrect\n0 ms onset RT\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n\n\n\nIf you’re not sure, it’s usually easier to use %&gt;%.\nI try to use %&gt;% throughout this book, but because I use |&gt; more often in my own code I might slip up.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The pipe and renaming: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html#renaming-columns",
    "href": "chapters/the_pipe_and_renaming.html#renaming-columns",
    "title": "5  The pipe and renaming: {dplyr}",
    "section": "5.4 Renaming columns",
    "text": "5.4 Renaming columns\n\n5.4.1 Why rename\nColumn names are easiest to work with when they follow four principles: when they’re clear and descriptive, follow a standard convention, are unique, and don’t break R syntax.\n\n5.4.1.1 Use clear and descriptive names\nVariable names should help explain what the variable contains. X3 tells the user a lot less about the variable than extroversion_sum_score.\nThis sounds obvious, but it’s harder than it sounds and it often isn’t done.\n\n\n\n5.4.1.2 Use a naming convention\nVarious naming conventions exist and are used for both objects (e.g., data frames) and functions.\n\nsnake_case: standard in {tidyverse} code, e.g., write_csv()\nlower.dot.case: often used in older functions in base-R, e.g., write.csv()\ncamelCase: often used in Python\n\nOn the one hand, as long as you’re consitent, it doesn’t matter which one you use.\nOn the other hand, snake_case is objectively the best answer and you should use it.\n\n\n5.4.1.3 Use unique names\nIf more than one column has the same name, you’ll have issues trying to work with those columns.\n\n\n5.4.1.4 Avoid characters that break R syntax\nThe following cause problems:\n\nColumn names that begin with a number, e.g., 1_to_7_depression.\nColumn names that contain spaces, e.g., `depression 1 to 7’.\nColumn names that contain characters other than letters and numbers, e.g., depression_1_to_7*.\nColumn names that are ‘reserved names’ in R, e.g., TRUE.\n\nFor example, the ‘dat_demographics_raw’ data frame contains a columns named correct and 0 ms onset RT.\nIf we want to print the rows of correct using base-R we can do this with $:\n\n\nCode\ndat_demographics_raw$correct\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nThis can also be done using the {dplyr} function pull() and the pipe:\n\n\nCode\ndat_demographics_raw %&gt;%\n  pull(correct)\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nThis can’t be done as easily for the column 0 ms onset RT because the number and spaces break the code and will throw an error:\n\n\nCode\n# base-R\ndat_demographics_raw$0 ms onset RT\n\n# dplyr\ndat_demographics_raw %&gt;%\n  pull(0 ms onset RT)\n\n\n\nError: unexpected numeric constant in “dat_demographics_raw$0” Error during wrapup: not that many frames on the stack Error: no more error handlers available (recursive errors?); invoking ‘abort’ restart\n\nYou can make it work by enclosing the column name in backticks (`) or quotes (“):\n\n\nCode\n# base-R\ndat_demographics_raw$\"0 ms onset RT\"\n\n\n [1] 1372  619 1372  619 3946 3724 3946 3724 2576 3050 2576 3050 4311 2793 6887\n[16] 6887\n\n\nCode\n# dplyr\ndat_demographics_raw %&gt;%\n  pull(\"0 ms onset RT\")\n\n\n [1] 1372  619 1372  619 3946 3724 3946 3724 2576 3050 2576 3050 4311 2793 6887\n[16] 6887\n\n\nHowever this becomes cumbersome and annoying. It’s much easier to rename the variable.\n\n\n\n5.4.2 Renaming with rename() & the pipe\nUse dplyr::rename() to change the name of one or more columns. It works like this:\n`df %&gt;% rename(new_name = old_name)`\nLet’s create a data frame called dat_demographics_renamed from dat_demographics_raw, which renames the 0 ms onset RT column to timely rt:\n\n\nCode\n# view old column names \ncolnames(dat_demographics_raw)\n\n\n[1] \"date\"                        \"Subject Code\"               \n[3] \"build\"                       \"block code and trial number\"\n[5] \"Trial Code\"                  \"Key response (use this!)\"   \n[7] \"correct\"                     \"0 ms onset RT\"              \n\n\nCode\ndat_demographics_renamed &lt;- dat_demographics_raw %&gt;%\n  rename(rt = \"0 ms onset RT\")\n\n# view new column names \ncolnames(dat_demographics_renamed)\n\n\n[1] \"date\"                        \"Subject Code\"               \n[3] \"build\"                       \"block code and trial number\"\n[5] \"Trial Code\"                  \"Key response (use this!)\"   \n[7] \"correct\"                     \"rt\"                         \n\n\nIf you want to rename multiple columns at once, you can do this in a single call of the rename() function:\n\n\nCode\ndat_demographics_renamed &lt;- dat_demographics_raw %&gt;%\n  rename(id = \"Subject Code\",\n         block_trial = \"block code and trial number\",\n         question = \"Trial Code\", \n         response = \"Key response (use this!)\",\n         rt = \"0 ms onset RT\")\n\n# view new column names and the first few rows\nhead(dat_demographics_renamed) %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The pipe and renaming: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html#automatic-renaming-with-janitorclean_names",
    "href": "chapters/the_pipe_and_renaming.html#automatic-renaming-with-janitorclean_names",
    "title": "5  The pipe and renaming: {dplyr}",
    "section": "5.5 Automatic renaming with janitor::clean_names()",
    "text": "5.5 Automatic renaming with janitor::clean_names()\nCleaning names is such a common task that there are functions that rename all columns in a dataset at once, such as janitor::clean_names().\nHowever, clean_names() can only rename to a standard naming convention and remove problematic characters, it can’t choose meaningful variable names.\n\n\nCode\nlibrary(janitor) # for clean_names()\n\ndat_demographics_renamed &lt;- dat_demographics_raw %&gt;%\n  clean_names()\n\ndat_demographics_renamed %&gt;%\n  head() %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nsubject_code\nbuild\nblock_code_and_trial_number\ntrial_code\nkey_response_use_this\ncorrect\nx0_ms_onset_rt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n\n\n\nIt’s still very useful as part of a tidy workflow:\n\n\nCode\n# code you might write to help you write the final varsion below\ndat_demographics_temp &lt;- dat_demographics_raw %&gt;%\n  clean_names()\n\ndat_demographics_temp %&gt;%\n  colnames() %&gt;%\n  dput()\n\n\nc(\"date\", \"subject_code\", \"build\", \"block_code_and_trial_number\", \n\"trial_code\", \"key_response_use_this\", \"correct\", \"x0_ms_onset_rt\"\n)\n\n\nCode\n# final working version\ndat_demographics_renamed &lt;- dat_demographics_raw %&gt;%\n  clean_names() %&gt;%\n  rename(id = subject_code, \n         block_trial = block_code_and_trial_number, \n         question = trial_code, \n         response = key_response_use_this, \n         rt = x0_ms_onset_rt)\n\ndat_demographics_renamed %&gt;%\n  head() %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The pipe and renaming: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html#exercises",
    "href": "chapters/the_pipe_and_renaming.html#exercises",
    "title": "5  The pipe and renaming: {dplyr}",
    "section": "5.6 Exercises",
    "text": "5.6 Exercises\n\n5.6.1 What four principles should column names follow?\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\nUse clear and descriptive names\nUse a naming convention such as snake_case\nUse unique names\nAvoid characters that break R syntax, such as spaces, non-alphanumeric characters, or starting column names with a number.\n\n\n\n\n\n\n5.6.2 Interactive exercises\nComplete the interactive rename() exercises here. This web app is written in the {shiny} package and allows you to write and run code in your web browser.\n\n\n5.6.3 Read .csv file and rename columns\nDownload the data and code for this e-Book (see the Introduction).\nIn your local version of this .qmd file:\n\nCreate a new data frame called dat_likert_renamed by reading the csv file from ‘../data/data_likert_messy.csv’.\nUse rename() to rename every column so that it conforms to the four principles above.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The pipe and renaming: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation_1.html",
    "href": "chapters/data_transformation_1.html",
    "title": "6  Data transformation I: {dplyr}",
    "section": "",
    "text": "6.1 Keeping or dropping columns with dplyr::select()\nThe next few chapters cover various {tidyverse} functions - sometimes called verbs - that are used for data transformation.\nThis chapter covers functions that are “non-aggregating”: they allow you to change which columns or rows are present in the dataset, to create new columns or split up existing ones, to change their contents, etc. rename(), which you learned in the previous chapter, is one of these functions.\nNot all columns in a dataset are useful to us. When processing data, we often wish to keep only some columns and drop others. We can do this with dplyr::select().\nWe’ll start where the last chapter ended, by loading dependencies, reading in the ‘data_demographics_raw_messy.csv’ dataset, and renaming the columns to make them easier to work with.\nCode\nlibrary(readr) # for read_csv()\nlibrary(janitor) # for clean_names()\nlibrary(dplyr) # for %&gt;%\nlibrary(knitr) # for kable()\nlibrary(kableExtra) # for kable_extra()\n\ndat_demographics_renamed &lt;- \n  read_csv(file = \"../data/raw/data_demographics_raw_messy.csv\",\n           skip = 2) %&gt;%\n  clean_names() %&gt;%\n  rename(id = subject_code, \n         block_trial = block_code_and_trial_number, \n         question = trial_code, \n         response = key_response_use_this, \n         rt = x0_ms_onset_rt)\n\ndat_demographics_renamed %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nOCD\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\nprolific ID\nad;oi98732paisdh\n1\n3724\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_2\nage\n21\n1\n2576\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n3050\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n2576\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\nprolific ID\n1023984cao982738\n1\n3050\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\nage\n999\n1\n4311\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_3\ngender\nMale\n1\n2793\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nGAD\n1\n6887\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\nprolific ID\n2982879q8w7r\n1\n6887\nIf our data processing goal is to extract and tidy responses on the demographics questionnaire, we only need some of these columns: id, question, and response. We can use select() and the pipe to retain only these.\nCode\ndat_demographics_selected &lt;- dat_demographics_renamed %&gt;%\n  select(id, \n         question, \n         response)\n\ndat_demographics_selected %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nid\nquestion\nresponse\n\n\n\n\n548957868\nage\n23\n\n\n548957868\ngender\nfemale\n\n\n548957868\npsychiatric diagnosis\nschizophrenia\n\n\n548957868\nprolific ID\nasldkjaao87809\n\n\n504546409\nage\n48\n\n\n504546409\ngender\nyes\n\n\n504546409\npsychiatric diagnosis\nOCD\n\n\n504546409\nprolific ID\nad;oi98732paisdh\n\n\n994692692\nage\n21\n\n\n994692692\ngender\nfemale\n\n\n994692692\npsychiatric diagnosis\nschizophrenia\n\n\n994692692\nprolific ID\n1023984cao982738\n\n\n246532124\nage\n999\n\n\n246532124\ngender\nMale\n\n\n246532124\npsychiatric diagnosis\nGAD\n\n\n246532124\nprolific ID\n2982879q8w7r\nWhat code would you write to select the ‘date’ and ‘correct’ columns?\nWhat code would you write to print all the columns present in ‘dat_demographics_renamed’ in a way you can easily paste into a select() call? This was covered in the previous chapter.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation I: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation_1.html#keeping-or-dropping-columns-with-dplyrselect",
    "href": "chapters/data_transformation_1.html#keeping-or-dropping-columns-with-dplyrselect",
    "title": "6  Data transformation I: {dplyr}",
    "section": "",
    "text": "Click to show answer\n\n\n\n\n\n\n\nCode\ndat_demographics_selected &lt;- dat_demographics_renamed %&gt;%\n  select(date, \n         correct)\n\n\n\n\n\n\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\ndat_demographics_renamed %&gt;%\n  colnames() %&gt;%\n  dput()\n\n\nc(\"date\", \"id\", \"build\", \"block_trial\", \"question\", \"response\", \n\"correct\", \"rt\")\n\n\n\n\n\n\n6.1.1 Positive vs. negative selections\nThe above example tells select() the columns to retain. You could instead tell it which ones to drop. This is a negative selection: you preface the column name with -.\n\n\nCode\ndat_demographics_selected &lt;- dat_demographics_renamed %&gt;%\n  select(-date, \n         -build, \n         -block_trial, \n         -correct, \n         -rt)\n\ndat_demographics_selected %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nid\nquestion\nresponse\n\n\n\n\n548957868\nage\n23\n\n\n548957868\ngender\nfemale\n\n\n548957868\npsychiatric diagnosis\nschizophrenia\n\n\n548957868\nprolific ID\nasldkjaao87809\n\n\n504546409\nage\n48\n\n\n504546409\ngender\nyes\n\n\n504546409\npsychiatric diagnosis\nOCD\n\n\n504546409\nprolific ID\nad;oi98732paisdh\n\n\n994692692\nage\n21\n\n\n994692692\ngender\nfemale\n\n\n994692692\npsychiatric diagnosis\nschizophrenia\n\n\n994692692\nprolific ID\n1023984cao982738\n\n\n246532124\nage\n999\n\n\n246532124\ngender\nMale\n\n\n246532124\npsychiatric diagnosis\nGAD\n\n\n246532124\nprolific ID\n2982879q8w7r\n\n\n\n\n\nIt’s tempting to think in terms of negative selections, i.e., getting rid of columns you don’t want. However, you should in general use positive selections and avoid negative ones. If the underlying data changes in some way, e.g., in a prior processing step, it can contain variables your negative selection doesn’t account for. For example, if ‘dat_demographics_renamed’ now included another column, “completed_study” (TRUE/FALSE), the positive selection would not include this variable as it wasn’t listed, but the negative selection would as it was not specifically excluded. This can produce code that is more ‘fragile’ to changes in the data.\nIn general, tell select what you do want, not what you don’t want.\nCheck your understanding of positive and negative selections: What would happen if you mix positive and negative selections?\n\nWhat columns will be present in the output when your run the code below?\n\n\n\nCode\ndat_demographics_selected &lt;- dat_demographics_renamed %&gt;%\n  select(id, \n         question, \n         response,\n         -correct)\n\ndat_demographics_selected %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\n\n\nWhy are those columns present and not others?\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\nOnce positive selections are present in the select call, the negative ones are redundant. You’ve already told select() what to include, which implies what not to include.\n\n\n\n\n\n6.1.2 {tidyselect} helper functions\nOften, we have large datasets with many columns. select() calls can be made simpler with the help of another {tidyverse} package, {tidyselect}.\nTo illustrate this, we’ll use a simulated dataset called ‘dat_many_columns’ that contains, you guessed it, many columns.\nLet’s start by printing the column names:\n\n\nCode\ndat_many_columns %&gt;%\n  colnames() %&gt;%\n  dput()\n\n\nc(\"id\", \"age\", \"gender\", \"condition\", \"depression_scale1_item1\", \n\"depression_scale1_item2\", \"depression_scale1_item3\", \"depression_scale1_item4\", \n\"depression_scale1_item5\", \"depression_scale1_item6\", \"depression_scale1_item7\", \n\"depression_scale1_item8\", \"depression_scale1_item9\", \"depression_scale1_item10\", \n\"depression_scale2_item1\", \"depression_scale2_item2\", \"depression_scale2_item3\", \n\"depression_scale2_item4\", \"depression_scale2_item5\", \"depression_scale2_item6\", \n\"depression_scale2_item7\", \"depression_scale3_item1\", \"depression_scale3_item2\", \n\"depression_scale3_item3\", \"depression_scale3_item4\", \"depression_scale3_item5\", \n\"depression_scale3_item6\", \"depression_scale3_item7\", \"depression_scale3_item8\", \n\"depression_scale3_item9\", \"depression_scale3_item10\", \"depression_scale3_item11\", \n\"depression_scale3_item12\", \"depression_scale3_item13\", \"depression_scale3_item14\", \n\"depression_scale3_item15\")\n\n\nExercise\nWrite code to:\n\nCreate a new data frame called ‘dat_fewer_columns’\nselect() all the columns beginning with “depression”, using only positive selections\nPrint the column names to confirm that these are the only ones present\n\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\ndat_fewer_columns &lt;- dat_many_columns %&gt;%\n  select(depression_scale1_item1, \n         depression_scale1_item2, \n         depression_scale1_item3, \n         depression_scale1_item4, \n         depression_scale1_item5, \n         depression_scale1_item6, \n         depression_scale1_item7, \n         depression_scale1_item8, \n         depression_scale1_item9, \n         depression_scale1_item10, \n         depression_scale2_item1, \n         depression_scale2_item2, \n         depression_scale2_item3, \n         depression_scale2_item4, \n         depression_scale2_item5, \n         depression_scale2_item6, \n         depression_scale2_item7, \n         depression_scale3_item1, \n         depression_scale3_item2, \n         depression_scale3_item3, \n         depression_scale3_item4, \n         depression_scale3_item5, \n         depression_scale3_item6, \n         depression_scale3_item7, \n         depression_scale3_item8, \n         depression_scale3_item9, \n         depression_scale3_item10, \n         depression_scale3_item11, \n         depression_scale3_item12, \n         depression_scale3_item13, \n         depression_scale3_item14, \n         depression_scale3_item15)\n\ndat_fewer_columns %&gt;%\n  colnames() %&gt;%\n  dput()\n\n\nc(\"depression_scale1_item1\", \"depression_scale1_item2\", \"depression_scale1_item3\", \n\"depression_scale1_item4\", \"depression_scale1_item5\", \"depression_scale1_item6\", \n\"depression_scale1_item7\", \"depression_scale1_item8\", \"depression_scale1_item9\", \n\"depression_scale1_item10\", \"depression_scale2_item1\", \"depression_scale2_item2\", \n\"depression_scale2_item3\", \"depression_scale2_item4\", \"depression_scale2_item5\", \n\"depression_scale2_item6\", \"depression_scale2_item7\", \"depression_scale3_item1\", \n\"depression_scale3_item2\", \"depression_scale3_item3\", \"depression_scale3_item4\", \n\"depression_scale3_item5\", \"depression_scale3_item6\", \"depression_scale3_item7\", \n\"depression_scale3_item8\", \"depression_scale3_item9\", \"depression_scale3_item10\", \n\"depression_scale3_item11\", \"depression_scale3_item12\", \"depression_scale3_item13\", \n\"depression_scale3_item14\", \"depression_scale3_item15\")\n\n\n\n\n\nThis can be done more easily with tidyselect::starts_with():\n\n\nCode\nlibrary(tidyselect)\n\ndat_fewer_columns &lt;- dat_many_columns %&gt;%\n  select(starts_with(\"depression\"))\n\ndat_fewer_columns %&gt;%\n  colnames() %&gt;%\n  dput()\n\n\nc(\"depression_scale1_item1\", \"depression_scale1_item2\", \"depression_scale1_item3\", \n\"depression_scale1_item4\", \"depression_scale1_item5\", \"depression_scale1_item6\", \n\"depression_scale1_item7\", \"depression_scale1_item8\", \"depression_scale1_item9\", \n\"depression_scale1_item10\", \"depression_scale2_item1\", \"depression_scale2_item2\", \n\"depression_scale2_item3\", \"depression_scale2_item4\", \"depression_scale2_item5\", \n\"depression_scale2_item6\", \"depression_scale2_item7\", \"depression_scale3_item1\", \n\"depression_scale3_item2\", \"depression_scale3_item3\", \"depression_scale3_item4\", \n\"depression_scale3_item5\", \"depression_scale3_item6\", \"depression_scale3_item7\", \n\"depression_scale3_item8\", \"depression_scale3_item9\", \"depression_scale3_item10\", \n\"depression_scale3_item11\", \"depression_scale3_item12\", \"depression_scale3_item13\", \n\"depression_scale3_item14\", \"depression_scale3_item15\")\n\n\nThere are many other {tidyselect} helper functions including:\n\nstarts_with() : Selects columns ending in a character string\nends_with() : Selects columns ending in a character string\ncontains() : Selects columns containing a character string, not necessarily at the start or end\nall_of() : Selects all of the column names in a vector e.g., all_of(c(\"a\", \"b\"))\nany_of() : Selects any of the column names in a vector that are present, silently dropping missing ones. This can be very useful when columns may or may not be present, but has the risk of creating silent errors.\nwhere() : Select columns that meet a criterion, e.g., where(is.numeric) selects only columns containing numeric data.\neverything() : Selects all columns. This will seem redundant right now, but will become useful later on when we cover pivot_ functions\n\nExercise\nWrite code to select all columns for scale 2 from the ‘dat_many_columns’ data frame.\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\ndat_fewer_columns &lt;- dat_many_columns %&gt;%\n  select(contains(\"scale2\"))\n\ndat_fewer_columns %&gt;%\n  colnames() %&gt;%\n  dput()\n\n\nc(\"depression_scale2_item1\", \"depression_scale2_item2\", \"depression_scale2_item3\", \n\"depression_scale2_item4\", \"depression_scale2_item5\", \"depression_scale2_item6\", \n\"depression_scale2_item7\")\n\n\n\n\n\nExercise\nWrite code to select from the ‘dat_many_columns’ data frame the “id”, “age” and “gender” columns AND all columns related to item3.\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\ndat_fewer_columns &lt;- dat_many_columns %&gt;%\n  select(id, age, gender, contains(\"item3\"))\n\ndat_fewer_columns %&gt;%\n  colnames() %&gt;%\n  dput()\n\n\nc(\"id\", \"age\", \"gender\", \"depression_scale1_item3\", \"depression_scale2_item3\", \n\"depression_scale3_item3\")\n\n\n\n\n\nExercise\nWrite code to select the “id”, “age” and “gender” columns AND all columns related to item1.\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\ndat_fewer_columns &lt;- dat_many_columns %&gt;%\n  select(id, age, gender, ends_with(\"item1\"))\n\ndat_fewer_columns %&gt;%\n  colnames() %&gt;%\n  dput()\n\n\nc(\"id\", \"age\", \"gender\", \"depression_scale1_item1\", \"depression_scale2_item1\", \n\"depression_scale3_item1\")\n\n\n\n\n\n\n\n6.1.3 Selection with set operations\nNegative selection using - is selection using a “set operation” or a set of logical rules that determine which column names are in the selected set. There are others:\n\nSet operations:\n\n- negative selection\nc() : combine selections\n! invert selection\n& must meet both selection rules\n| can meet either selection criteria\n\n\nFor example: select columns that refer to scale 3 AND items &gt;=10:\n\n\nCode\ndat_fewer_columns &lt;- dat_many_columns %&gt;%\n  select(id, age, gender, \n         # items containing scale3 AND item1 but NOT item 1\n         c(contains(\"scale3\") & contains(\"item1\") & !ends_with(\"item1\")))\n\ndat_fewer_columns %&gt;%\n  colnames() %&gt;%\n  dput()\n\n\nc(\"id\", \"age\", \"gender\", \"depression_scale3_item10\", \"depression_scale3_item11\", \n\"depression_scale3_item12\", \"depression_scale3_item13\", \"depression_scale3_item14\", \n\"depression_scale3_item15\")\n\n\nExercise\nTo practice {tidyselect} helpers and selection set operations, write code in a creative and unnecessarily complex way to select the columns “id”, “gender”, and “age”, and the items from scale 1 and scale 3 that whose items are &lt;= 10.\nNote: no solution provided here as many different ones are possible.\n\n\n6.1.4 Practicing select and the pipe in a longer chunk\nExercise\nThe first chunk in this chapter read in the ‘data_demographics_raw_messy.csv’ file and renamed columns.\n\nRewrite that chunk here - as much as possible from memory, without simply copy pasting.\nAdd another pipe and selecting the “id”, “question” and “response” columns.\nPrint a table of the resulting data frame using kable() and kable_class()\n\nNote: no solution provided here to reduce the temptation to peek or copy-paste.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation I: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation_1.html#moving-columns-with-dplyrrelocate",
    "href": "chapters/data_transformation_1.html#moving-columns-with-dplyrrelocate",
    "title": "6  Data transformation I: {dplyr}",
    "section": "6.2 Moving columns with dplyr::relocate()",
    "text": "6.2 Moving columns with dplyr::relocate()\nYou can reorder to columns within a data frame with relocate().\nUnlike rename(), select(), and other functions, only one column can be relocated with each relocate() call.\nYou can relocate columns before or after others, or to locations such as being the first or last column. This code moves the “response” column to be before the “question” column, and the “correct” column to be the last one.\n\n\nCode\ndat_demographics_renamed %&gt;%\n  relocate(response, .before = \"question\") %&gt;%\n  relocate(correct, .after = last_col()) %&gt;%\n  head() %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nresponse\nquestion\nrt\ncorrect\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\n23\nage\n1372\n1\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nfemale\ngender\n619\n1\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nschizophrenia\npsychiatric diagnosis\n1372\n1\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nasldkjaao87809\nprolific ID\n619\n1\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\n48\nage\n3946\n1\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\nyes\ngender\n3724\n1\n\n\n\n\n\nExercise\nWhat code is needed to relocate the columns of ‘dat_demographics_renamed’ so that they are in the order “id”, “question”, “response”, and then the remaining columns.\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\ndat_demographics_reordered &lt;- dat_demographics_renamed %&gt;%\n  relocate(id, .before = 1) %&gt;% \n  relocate(question, .after = \"id\") %&gt;%\n  relocate(response, .after = \"question\")\n\ndat_demographics_reordered %&gt;%\n  head() %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nid\nquestion\nresponse\ndate\nbuild\nblock_trial\ncorrect\nrt\n\n\n\n\n548957868\nage\n23\n23.06.2022\n06.06.2000\ndemographics_2\n1\n1372\n\n\n548957868\ngender\nfemale\n23.06.2022\n06.06.2000\ndemographics_3\n1\n619\n\n\n548957868\npsychiatric diagnosis\nschizophrenia\n23.06.2022\n06.06.2000\ndemographics_2\n1\n1372\n\n\n548957868\nprolific ID\nasldkjaao87809\n23.06.2022\n06.06.2000\ndemographics_3\n1\n619\n\n\n504546409\nage\n48\n23.06.2022\n06.06.2000\ndemographics_2\n1\n3946\n\n\n504546409\ngender\nyes\n23.06.2022\n06.06.2000\ndemographics_3\n1\n3724\n\n\n\n\n\n\n\n\nExercise\nAll three of the solutions below accomplish the goal of making the “id” column the first column:\n\n\nCode\n# move \"id\" to be the first column by placing it before \"date\"\ndat_demographics_renamed %&gt;%\n  relocate(id, .before = \"date\") %&gt;%\n  head() %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nid\ndate\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n548957868\n23.06.2022\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n548957868\n23.06.2022\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n548957868\n23.06.2022\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n548957868\n23.06.2022\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n504546409\n23.06.2022\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n504546409\n23.06.2022\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n\n\n\nCode\n# move \"date\" to be the second column by placing it after \"id\", producing the same result\ndat_demographics_renamed %&gt;%\n  relocate(date, .after = \"id\") %&gt;%\n  head() %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nid\ndate\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n548957868\n23.06.2022\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n548957868\n23.06.2022\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n548957868\n23.06.2022\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n548957868\n23.06.2022\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n504546409\n23.06.2022\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n504546409\n23.06.2022\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n\n\n\nCode\n# move \"id\" to be the 1st column by placing it before the first column by location, producing the same result\ndat_demographics_renamed %&gt;%\n  relocate(id, .before = 1) %&gt;%\n  head() %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nid\ndate\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n548957868\n23.06.2022\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n548957868\n23.06.2022\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n548957868\n23.06.2022\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n548957868\n23.06.2022\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n504546409\n23.06.2022\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n504546409\n23.06.2022\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n\n\n\nWhich of the above solutions is the least ‘fragile’ solution, i.e., that is robust to changes in the data or elsewhere in your data processing code?\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\nrelocate(id, .before = 1) does not rely on the name and location of another column and is therefore the least fragile solution.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation I: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation_1.html#renaming-relocating-and-selecting-all-in-one-with-select",
    "href": "chapters/data_transformation_1.html#renaming-relocating-and-selecting-all-in-one-with-select",
    "title": "6  Data transformation I: {dplyr}",
    "section": "6.3 Renaming, relocating, and selecting all-in-one with select()",
    "text": "6.3 Renaming, relocating, and selecting all-in-one with select()\nRenaming, relocating, and selecting columns are so common as a set of three tasks that you can do it all within select().\nWhatever order columns appear in select() they will be relocated to. You can rename variables inside select just as you do in rename() using new_name = old_name.\n\n\nCode\ndat_demographics_renamed %&gt;%\n  select(id, date, question, answer = response) %&gt;%\n  head() %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nid\ndate\nquestion\nanswer\n\n\n\n\n548957868\n23.06.2022\nage\n23\n\n\n548957868\n23.06.2022\ngender\nfemale\n\n\n548957868\n23.06.2022\npsychiatric diagnosis\nschizophrenia\n\n\n548957868\n23.06.2022\nprolific ID\nasldkjaao87809\n\n\n504546409\n23.06.2022\nage\n48\n\n\n504546409\n23.06.2022\ngender\nyes",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation I: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation_1.html#keeping-or-dropping-rows-with-dplyrfilter",
    "href": "chapters/data_transformation_1.html#keeping-or-dropping-rows-with-dplyrfilter",
    "title": "6  Data transformation I: {dplyr}",
    "section": "6.4 Keeping or dropping rows with dplyr::filter()",
    "text": "6.4 Keeping or dropping rows with dplyr::filter()\nNot all rows in a dataset are useful to us. When processing data, we often wish to keep only some rows and drop others. We can do this with dplyr::filter().\nIt is important to learn the difference between select() and filter(), it is initially confusing.\n\nselect() keeps or drops columns\nfilter() keeps or drops rows\n\nFor example, filter the ‘question’ column to contain only “age” items:\n\n\nCode\ndat_filtered_age &lt;- dat_demographics_renamed %&gt;%\n  filter(question == \"age\")\n\ndat_filtered_age %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_2\nage\n21\n1\n2576\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\nage\n999\n1\n4311\n\n\n\n\n\nExercise\nWrite code to:\n\nTake the ‘dat_demographics_renamed’ data frame.\nCreate two data frames called ‘dat_filtered_age’ and ‘dat_filtered_gender’.\nRetain only the relevant rows of ‘question’ for each.\nRename the ‘response’ columns to what variable it now contains.\nDrop the ‘question’ columns since they’re now irrelevant.\nPrint a table of each data frame.\n\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\ndat_filtered_age &lt;- dat_demographics_renamed %&gt;%\n  filter(question == \"age\") %&gt;%\n  rename(age = response) %&gt;%\n  select(-question)\n\ndat_filtered_age %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nage\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\n23\n1\n1372\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\n48\n1\n3946\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_2\n21\n1\n2576\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\n999\n1\n4311\n\n\n\n\n\nCode\ndat_filtered_gender &lt;- dat_demographics_renamed %&gt;%\n  filter(question == \"gender\") %&gt;%\n  rename(gender = response) %&gt;%\n  select(-question)\n\ndat_filtered_gender %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\ngender\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nfemale\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\nyes\n1\n3724\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\nfemale\n1\n3050\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_3\nMale\n1\n2793\n\n\n\n\n\n\n\n\n\n6.4.1 Filters with set operations\nYou can specify the logical test for filtering in many ways, including:\n\n== : ‘is exactly equal to this one value’\n!= : ’is not exactly equal to\n%in% : ‘is exactly equal to one of the following values’\n\nNote that equivalence is two equals signs (==) whereas setting arguments in functions is one (=).\n\n\nCode\n# '==' exactly equal to\ndat_filtered_gender %&gt;%\n  filter(gender == \"female\") %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\ngender\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nfemale\n1\n619\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\nfemale\n1\n3050\n\n\n\n\n\nCode\n# '!=' is not exactly equal to\ndat_filtered_gender %&gt;%\n  filter(gender == \"female\") %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\ngender\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nfemale\n1\n619\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\nfemale\n1\n3050\n\n\n\n\n\nCode\n# '%in%' is exactly equal to one of the following\ndat_filtered_gender %&gt;%\n  filter(gender %in% c(\"female\", \"male\")) %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\ngender\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nfemale\n1\n619\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\nfemale\n1\n3050\n\n\n\n\n\nWeirdly, there is no single function that provides the combination of %in% and !=, i.e., ‘is not exactly equal to any of the following values’. This can be achieved with the following, although it is not intuitive:\n\n\nCode\n# '!' and '%in%'\ndat_filtered_gender %&gt;%\n  filter(!gender %in% c(\"female\", \"male\")) %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\ngender\ncorrect\nrt\n\n\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\nyes\n1\n3724\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_3\nMale\n1\n2793\n\n\n\n\n\nYou can also combine multiple tests with various operators:\n\n& : AND, i.e., meeting both criterion.\n| : OR, i.e., meeting either criterion.\n\n\n\nCode\n# & criterion X and Y\ndat_demographics_renamed %&gt;%\n  filter(question == \"gender\" & response == \"female\")  %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n3050\n\n\n\n\n\nCode\n# | criterion X or Y\ndat_demographics_renamed %&gt;%\n  filter(question == \"gender\" | response == \"female\")  %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n3050\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_3\ngender\nMale\n1\n2793\n\n\n\n\n\nExercise\nWrite code to:\n\nTake the ‘dat_demographics_renamed’ data frame.\nCreate the data frame ‘dat_filtered_rt’.\nRetain only rows where where reaction time (‘re’) is more than 500 ms.\nPrint a table of each data frame.\n\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\ndat_filtered_rt &lt;- dat_demographics_renamed %&gt;%\n  filter(rt &gt; 500) \n\ndat_filtered_rt %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nOCD\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\nprolific ID\nad;oi98732paisdh\n1\n3724\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_2\nage\n21\n1\n2576\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n3050\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n2576\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\nprolific ID\n1023984cao982738\n1\n3050\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\nage\n999\n1\n4311\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_3\ngender\nMale\n1\n2793\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nGAD\n1\n6887\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\nprolific ID\n2982879q8w7r\n1\n6887\n\n\n\n\n\n\n\n\nExercise\nWrite code to:\n\nTake the ‘dat_demographics_renamed’ data frame.\nCreate the data frame ‘dat_filtered_rt’.\nRetain only rows where where both reaction time (‘rt’) is more than 500 ms and gender is either ‘male’, ‘female’, or ‘non-binary’.\nPrint a table of each data frame.\n\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\ndat_filtered_rt &lt;- dat_demographics_renamed %&gt;%\n  filter(rt &gt; 500 & question == 'gender' & response %in% c('male', 'female', 'non-binary')) \n\ndat_filtered_rt %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n3050\n\n\n\n\n\n\n\n\nExercise\nIn the above answer, why might it be a good idea to include question == 'gender'?\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\nBecause the requirement was “…and gender is either ‘male’, ‘female’, or ‘non-binary’”.\nIf participants responded to another question (e.g., ‘age’) with ‘male’, ‘female’, or ‘non-binary’, their rows would also be returned.\nBeing specific to the requirements makes your code less ‘brittle’ and more likely to catch weird cases in larger datasets.\n\n\n\n\n\n6.4.2 Positive vs. negative filters\nAs with select(), it is often better to define what you do want (== and %&gt;%) rather than what you do not want (!= and !+%in%). This is even more important with filter() as unexpected row values are much more common than unexpected column names.\nFor example, if you specify a negative filter dat %&gt;% filter(gender != \"non-binary)\" because you wish to filter to return only participants who identify as ‘male’ or ‘female’, you have in fact only excluded participants who specified ‘non-binary’. This code would also return participants with other response options such as ‘non binary’, ‘Non-Binary’, ‘NB’, etc.\nHowever, there can be cases where you specifically do not want some rows or want to retain anything other than a given value. Protecting participant privacy is one of them.\nSome rows of the ‘dat_demographics_renamed’ data frame contain “prolific ID” values, which could be linked back to the individual’s Prolific.com account where they completed the study, and therefore risk exposing identifying information. If this data was shared with other researchers or publicly, this could violate the informed consent agreement and/or local data privacy laws. (Note that the prolific IDs included in this data frame are made up.) This is discussed in more detail in the chapter on Data Privacy.\nIn this case, you would likely need to remove all rows referring to Prolific ID with a negative filter:\n\n\nCode\ndat_demographics_anonymized &lt;- dat_demographics_renamed %&gt;%\n  filter(question != \"prolific ID\")\n  \ndat_demographics_anonymized %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nOCD\n1\n3946\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_2\nage\n21\n1\n2576\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n3050\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n2576\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\nage\n999\n1\n4311\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_3\ngender\nMale\n1\n2793\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nGAD\n1\n6887\n\n\n\n\n\nNote that the original ‘data_demographics_raw_messy.csv’ data file we originally read in to R still contains the Prolific ID codes! Again, see the Data Privacy chapter for how you would deal with this more thoroughly in your own projects.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation I: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation_1.html#creating-and-modifying-columns-with-dplyrmutate",
    "href": "chapters/data_transformation_1.html#creating-and-modifying-columns-with-dplyrmutate",
    "title": "6  Data transformation I: {dplyr}",
    "section": "6.5 Creating and modifying columns with dplyr::mutate()",
    "text": "6.5 Creating and modifying columns with dplyr::mutate()\nmutate() is used to create new columns or to change the contents of existing ones.\nFor example, we can create the ‘rt_seconds’ column by dividing the ‘rt’ column, which is in milliseconds, by 1000.\n\n\nCode\ndat_demographics_mutated &lt;- dat_demographics_renamed %&gt;%\n  mutate(rt_seconds = rt/1000)\n\ndat_demographics_mutated %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\nrt_seconds\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n1.372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n0.619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n1.372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n0.619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n3.946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n3.724\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nOCD\n1\n3946\n3.946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\nprolific ID\nad;oi98732paisdh\n1\n3724\n3.724\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_2\nage\n21\n1\n2576\n2.576\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n3050\n3.050\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n2576\n2.576\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\nprolific ID\n1023984cao982738\n1\n3050\n3.050\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\nage\n999\n1\n4311\n4.311\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_3\ngender\nMale\n1\n2793\n2.793\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nGAD\n1\n6887\n6.887\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\nprolific ID\n2982879q8w7r\n1\n6887\n6.887\n\n\n\n\n\nWe can also alter existing columns through self-assignment, i.e., mutate()-ing a column based on itself. For example, modifying ‘rt’ to be in seconds by overwriting the existing ‘rt’ column:\n\n\nCode\ndat_demographics_mutated &lt;- dat_demographics_renamed %&gt;%\n  mutate(rt = rt/1000)\n\ndat_demographics_mutated %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1.372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n0.619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1.372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n0.619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3.946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3.724\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nOCD\n1\n3.946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\nprolific ID\nad;oi98732paisdh\n1\n3.724\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_2\nage\n21\n1\n2.576\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n3.050\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n2.576\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\nprolific ID\n1023984cao982738\n1\n3.050\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\nage\n999\n1\n4.311\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_3\ngender\nMale\n1\n2.793\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nGAD\n1\n6.887\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\nprolific ID\n2982879q8w7r\n1\n6.887\n\n\n\n\n\nWe can also change types, for example, converting the ‘correct’ column from numeric (0/1) to logical (TRUE/FALSE).\n\n\nCode\ndat_demographics_mutated &lt;- dat_demographics_renamed %&gt;%\n  mutate(correct = as.logical(correct))\n\ndat_demographics_mutated %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\nTRUE\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\nTRUE\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\nTRUE\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\nTRUE\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\nTRUE\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\nTRUE\n3724\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nOCD\nTRUE\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\nprolific ID\nad;oi98732paisdh\nTRUE\n3724\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_2\nage\n21\nTRUE\n2576\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\ngender\nfemale\nTRUE\n3050\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\nTRUE\n2576\n\n\n23.06.2022\n994692692\n06.06.2000\ndemographics_3\nprolific ID\n1023984cao982738\nTRUE\n3050\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\nage\n999\nTRUE\n4311\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_3\ngender\nMale\nTRUE\n2793\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nGAD\nTRUE\n6887\n\n\n23.06.2022\n246532124\n06.06.2000\ndemographics_2\nprolific ID\n2982879q8w7r\nTRUE\n6887\n\n\n\n\n\n\n6.5.1 Longer pipes\nA single mutate call can contain multiple mutates. The code from the last chunk could be written more simply like this:\n\n\nCode\ndat_demographics_mutated &lt;- dat_demographics_renamed %&gt;%\n  # select only columns of interest\n  select(id, question, response, rt, correct) %&gt;%\n  # filter only rows of interest\n  filter(question == \"age\") %&gt;%\n  # rename columns to make them more intuitive\n  rename(age = response) %&gt;%\n  # mutate variables\n  mutate(rt_ms = rt/1000,\n         correct = as.logical(correct)) %&gt;%\n  # select needed columns again\n  select(id, age, rt_ms, correct)\n\ndat_demographics_mutated %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nid\nage\nrt_ms\ncorrect\n\n\n\n\n548957868\n23\n1.372\nTRUE\n\n\n504546409\n48\n3.946\nTRUE\n\n\n994692692\n21\n2.576\nTRUE\n\n\n246532124\n999\n4.311\nTRUE\n\n\n\n\n\nExercise\nWrite code to:\n\nTake the ‘dat_demographics_renamed’.\nCreate a data frame named ‘dat_demographics_mutated’.\nRetain only the gender question rows.\nRename ‘response’ to ‘gender’.\nUse the stringr::str_to_lower() function to convert ‘gender’ to lower case strings’.\nRetain only the id and gender columns.\nPrint the data frame.\n\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\nlibrary(stringr)\n\ndat_demographics_mutated &lt;- dat_demographics_renamed %&gt;%\n  filter(question == 'gender') %&gt;%\n  rename(gender = response) %&gt;%\n  mutate(gender = stringr::str_to_lower(gender)) %&gt;%\n  select(id, gender)\n\ndat_demographics_mutated %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nid\ngender\n\n\n\n\n548957868\nfemale\n\n\n504546409\nyes\n\n\n994692692\nfemale\n\n\n246532124\nmale\n\n\n\n\n\n\n\n\n\n\n6.5.2 More complex mutates\nMost research reports (theses, articles, etc.) report the percentage of the sample that was male, female, etc. For example, the ‘dat_demographics_messy’ contains messy age and gender data for 500 participants.\nWe’ll use count() to show every unique response across participants. We’ll return to learn to use count() properly in the next chapter. For the moment, we’re more interested in the output than the code.\n\n\nCode\ndat_demographics_messy %&gt;%\n  # find unique values of 'gender' and the frequency of each\n  count(gender) %&gt;%\n  # arrange these unique cases by descending frequency\n  arrange(desc(n)) %&gt;%\n  # print table\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ngender\nn\n\n\n\n\nfemale\n297\n\n\nmale\n123\n\n\nnonbinary\n15\n\n\nFemale\n8\n\n\nFEMALE\n5\n\n\nfemail\n4\n\n\n25\n3\n\n\n27\n3\n\n\n30\n3\n\n\n43\n3\n\n\n45\n3\n\n\nfem ale\n3\n\n\nfemle\n3\n\n\nmalee\n3\n\n\n18\n2\n\n\n26\n2\n\n\n38\n2\n\n\n40\n2\n\n\nMalE\n2\n\n\nfemlae\n2\n\n\nmal\n2\n\n\n19\n1\n\n\n22\n1\n\n\n23\n1\n\n\n31\n1\n\n\n36\n1\n\n\n41\n1\n\n\n42\n1\n\n\nFeMale\n1\n\n\nma le\n1\n\n\nnon binary\n1\n\n\n\n\n\nNote how the data currently contains many misspellings and use of different cases that cause things like ‘female’ to appear as a different category to ‘Female’, etc.\n\n6.5.2.1 mutate() and working with character strings\nWorking with character strings using {stringr} and ‘regular expressions’ (regex) is a large separate topic in itself.\nFor the moment, know that you can:\n\nUse functions like str_to_lower() to convert all text to lower case (as in the above example).\nUse str_remove_all() to remove everything except letters (str_remove_all(x, \"[^A-Za-z]\")) or everything except numbers (str_remove_all(x, \"[^0-9\\\\.]\")).\n\nAbove, you used {stringr}’s str_to_lower() function to convert all letters to lower case. Let’s apply that here to quickly improve things:\n\n\nCode\ndat_demographics_messy %&gt;%\n  # convert to lower case\n  mutate(gender = str_to_lower(gender)) %&gt;%\n  # find unique values of 'gender' and the frequency of each\n  count(gender) %&gt;%\n  # arrange these unique cases by descending frequency\n  arrange(desc(n)) %&gt;%\n  # print table\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ngender\nn\n\n\n\n\nfemale\n311\n\n\nmale\n125\n\n\nnonbinary\n15\n\n\nfemail\n4\n\n\n25\n3\n\n\n27\n3\n\n\n30\n3\n\n\n43\n3\n\n\n45\n3\n\n\nfem ale\n3\n\n\nfemle\n3\n\n\nmalee\n3\n\n\n18\n2\n\n\n26\n2\n\n\n38\n2\n\n\n40\n2\n\n\nfemlae\n2\n\n\nmal\n2\n\n\n19\n1\n\n\n22\n1\n\n\n23\n1\n\n\n31\n1\n\n\n36\n1\n\n\n41\n1\n\n\n42\n1\n\n\nma le\n1\n\n\nnon binary\n1\n\n\n\n\n\nNext we’ll use str_remove_all(x, \"[^A-Za-z]\") to remove everything except letters:\n\n\nCode\ndat_demographics_messy %&gt;%\n  mutate(\n    # convert to lower case\n    gender = str_to_lower(gender),\n    # remove all non-letters\n    gender = str_remove_all(gender, \"[^A-Za-z]\")\n  ) %&gt;%\n  # find unique values of 'gender' and the frequency of each\n  count(gender) %&gt;%\n  # arrange these unique cases by descending frequency\n  arrange(desc(n)) %&gt;%\n  # print table\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ngender\nn\n\n\n\n\nfemale\n314\n\n\nmale\n126\n\n\n\n30\n\n\nnonbinary\n16\n\n\nfemail\n4\n\n\nfemle\n3\n\n\nmalee\n3\n\n\nfemlae\n2\n\n\nmal\n2\n\n\n\n\n\n\n\n6.5.2.2 mutate() and conditionals rules\n\n6.5.2.2.1 Using dplyr::if_else()\nIf we were being somewhat lazy, we could keep just the three most common self-reported responses to the gender, i.e. ‘male’, ‘female’ and ‘non-binary’, and change the other responses to NA.\nMany forms of data cleaning or ‘wrangling’ involve applying conditional rules like this to clean up irregular responses, i.e., “if gender is not ‘male’, ‘female’ or ‘non-binary’, then set it to NA”.\nThe simplest of these is dplyr::if_else(), which applies just one if-else. Note that there is a similar function in Base-R, ifelse(), but for technical reasons this function is much less safe and can cause weird errors. Try to always use if_else().\n\n\nCode\ndat_gender_tidier &lt;- dat_demographics_messy %&gt;%\n  # convert to lower case and remove non-letters\n  mutate(gender = str_to_lower(gender),\n         gender = str_remove_all(gender, \"[^A-Za-z]\")) %&gt;%\n  # tidy up cases\n  mutate(gender = if_else(condition = gender %in% c(\"female\", \"male\", \"nonbinary\"), # the logical test applied: is 'gender' one of the following\n                          true = gender, # what to do if the test is passed: keep the original gender response\n                          false = NA_character_)) # what to do if the test is failed: set it to NA\n\ndat_gender_tidier %&gt;%\n  count(gender) %&gt;%\n  arrange(desc(n)) %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ngender\nn\n\n\n\n\nfemale\n314\n\n\nmale\n126\n\n\nNA\n44\n\n\nnonbinary\n16\n\n\n\n\n\nThis somewhat quick and dirty solution gives us just four gender categories, ‘male’, ‘female’, ‘non-binary’ and missing (NA).\nOf course, these responses were (mostly) not really missing, we removed them to make the responses simpler. This isn’t very good practice, as we’re throwing away data.\n\n\n6.5.2.2.2 Using dplyr::case_when()\ncase_when() allows you to check against multiple logical tests. It works like this:\n\n\nCode\ndat %&gt;%\n  # create the variable variable_to_create based on:\n  mutate(variable_to_create = case_when(\n    # if logical_test_1 is met, set variable_to_create to value_1\n    logical_test_1 ~ value_1, \n    # if logical_test_2 is met, set variable_to_create to value_2\n    logical_test_2 ~ value_2, \n    # if logical_test_3 is met, set variable_to_create to value_3\n    logical_test_3 ~ value_3, \n    # 'if none of the above are met, set to the default value value_4'\n    TRUE ~ value_4\n  ))\n\n\nNote that the logical tests are checked in order, so you often have to consider the order in which they are listed and run.\nWe can apply it like this:\n\n\nCode\ndat_gender_tidier &lt;- dat_demographics_messy %&gt;%\n  # convert to lower case and remove non-letters\n  mutate(gender = str_to_lower(gender),\n         gender = str_remove_all(gender, \"[^A-Za-z]\")) %&gt;%\n  # tidy up cases\n  mutate(gender = case_when(gender %in% c(\"female\", \"male\", \"nonbinary\") ~ gender, \n                            gender %in% c(\"femail\", \"fem ale\", \"femle\", \"femlae\") ~ \"female\",\n                            gender %in% c(\"malee\", \"mal\", \"ma le\") ~ \"male\",\n                            gender %in% c(\"non binary\", \"nonbinary\") ~ \"non-binary\",\n                            gender == \"\" ~ NA_character_, # if an empty character string, change to NA_character_\n                            TRUE ~ gender)) # if none of the above apply, keep original value\n\ndat_gender_tidier %&gt;%\n  count(gender) %&gt;%\n  arrange(desc(n)) %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ngender\nn\n\n\n\n\nfemale\n323\n\n\nmale\n131\n\n\nNA\n30\n\n\nnonbinary\n16\n\n\n\n\n\nNote that the contents of the case_when() conditions have to be constructed iteratively. Use distinct() to inspect what cases are present, then write code to merge them as desired.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation I: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation_1.html#exercises",
    "href": "chapters/data_transformation_1.html#exercises",
    "title": "6  Data transformation I: {dplyr}",
    "section": "6.6 Exercises",
    "text": "6.6 Exercises\n\n6.6.1 select() vs. filter()\nWhat is the difference between select and filter?\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\nselect() is for columns, filter() is for rows.\n\n\n\n\n\n6.6.2 {tidyselect} helper functions\nName some helper functions from {tidyselect}.\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\nstarts_with()\nends_with()\ncontains()\nall_of()\nany_of()\nwhere()\neverything()\n\n\n\n\nExplain what each of them do.\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\nstarts_with() : Selects columns ending in a character string\nends_with() : Selects columns ending in a character string\ncontains() : Selects columns containing a character string, not necessarily at the start or end\nall_of() : Selects all of the column names in a vector e.g., all_of(c(\"a\", \"b\"))\nany_of() : Selects any of the column names in a vector that are present, silently dropping missing ones. This can be very useful when columns may or may not be present, but has the risk of creating silent errors.\nwhere() : Select columns that meet a criterion, e.g., where(is.numeric) selects only columns containing numeric data.\neverything() : Selects all columns.\n\n\n\n\n\n\n6.6.3 Positive vs. negative selections and filters\nExplain the difference between positive and negative selections in select() and filter() and how they are done in each.\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\nIn select(), positive selections mean keep these columns (e.g., select(mpg, cyl)), while negative selections mean drop these columns (e.g., select(-mpg, -cyl)).\nIn filter(), conditions act positively by default (e.g., filter(mpg &gt; 20) keeps rows with mpg &gt; 20). To “negate” a condition, you use ! or inequality operators (e.g., filter(!(mpg &gt; 20)) or filter(mpg &lt;= 20)).\n\n\n\n\n\n\n6.6.4 Set operators\nWhat set operators can be used with select() and how?\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\nselect() supports set operations on columns using tidyselect helpers:\n\n- : negative selection (drop columns)\n\nc() : combine multiple selections (union)\n\n! : invert a selection rule\n\n& : must meet both selection rules (intersection)\n\n| : can meet either selection rule (union)\n\nExample:\nselect(dat, contains(\"scale3\") & contains(\"item1\") & !ends_with(\"item1\"))\nWhat set operators can be used with filter() and how?\n::: {.callout-note collapse=“true” title=“Click to show answer”} With filter(), set operations are expressed with logical operators applied to rows: • & : keeps rows that satisfy all conditions (intersection) • | : keeps rows that satisfy any condition (union) • ! : excludes rows that meet a condition (negation/difference)\nExample:\n\n\nCode\ndat %&gt;%\n  filter(gender == \"female\" & age &gt; 30 & !is.na(income))\n\n\n\n\n\n\n\n6.6.5 Interactive exercises\nComplete the interactive exercises for:\n\nselect()\nrelocate()\nfilter()\nmutate()\ncase_when()\n\n\n\n6.6.6 Practice data transformation using multiple functions\nIn your local version of this .qmd file:\n\nUse the ‘dat_demographics_messy’ to create a new data frame called ‘dat_age_tidier’\nUse disinct() to understand what unique responses are present in the ‘age’ column.\nUse the other functions you learned in this chapter to clean the age column so that it contains only numbers.\nConvert the age variable to a numeric variable with as.numeric().\nPrint the unique responses present in the processed ‘age’ column as a table.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation I: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/reshaping_and_pivots.html",
    "href": "chapters/reshaping_and_pivots.html",
    "title": "7  Reshaping and pivots: {tidyr}",
    "section": "",
    "text": "7.1 Resources\nAdd alison horsts pics here\nHave students read Hadley’s chapter on tidy data. his examples and figures are nice, but the license he uses means i cant bring them into this book, and it seems like a waste to make alternatives.\nhttps://r4ds.had.co.nz/tidy-data.html#non-tidy-data\nTidy Data paper https://vita.had.co.nz/papers/tidy-data.pdf\nTODO\nBring gifs from here which illustrate pivots into this book",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reshaping and pivots: {tidyr}</span>"
    ]
  },
  {
    "objectID": "chapters/reshaping_and_pivots.html#dependencies",
    "href": "chapters/reshaping_and_pivots.html#dependencies",
    "title": "7  Reshaping and pivots: {tidyr}",
    "section": "7.2 Dependencies",
    "text": "7.2 Dependencies\n\n\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tibble)\n#install.packages(\"devtools\")\n#devtools::install_github(\"debruine/faux\")\nlibrary(faux)\nlibrary(janitor)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(psych)\nlibrary(readr)\nlibrary(knitr)\nlibrary(kableExtra)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reshaping and pivots: {tidyr}</span>"
    ]
  },
  {
    "objectID": "chapters/reshaping_and_pivots.html#example",
    "href": "chapters/reshaping_and_pivots.html#example",
    "title": "7  Reshaping and pivots: {tidyr}",
    "section": "7.3 Example",
    "text": "7.3 Example\n\n7.3.1 Simulate data in wide format\n\n\nCode\n# set seed for reproducibility\nset.seed(123)\n\n# generate data \ndata_wide &lt;- \n  faux::rnorm_multi(n = 100,\n                    vars = 5,\n                    mu = 3,\n                    sd = 1,\n                    r = 0.5,\n                    varnames = paste0(\"item_\", 1:5),\n                    empirical = FALSE) %&gt;%\n  rownames_to_column(var = \"id\")\n\n# recode responses less than 1 or more than 5 to those values, then round scores to whole numbers\n# note that {faux} has functions for doing this better\n\n\n# dat &lt;- data_wide |&gt;\n#   mutate(item_1 = round_half_up(item_1, digits = 0),\n#          item_1 = ifewlse\n\ndata_wide_likert &lt;- data_wide %&gt;%\n  mutate(across(starts_with(\"item_\"), ~ round_half_up(.x, digits = 0))) %&gt;%\n  mutate(across(starts_with(\"item_\"), ~ ifelse(.x &lt; 1, 1, ifelse(.x &gt; 5, 5, .x))))\n\n\n\n\n7.3.2 Cronbach’s alpha\nWide data like this is a) common and b) useful for calculating metrics like internal consistency.\n\n\nCode\nres_alpha &lt;- data_wide_likert %&gt;%\n  #select(-id) %&gt;%\n  select(starts_with(\"item_\")) %&gt;%\n  psych::alpha()\n\ncronbachs_alpha_estimate &lt;- res_alpha$total$raw_alpha |&gt;\n  round_half_up(digits = 2)\n\n\nCronbach’s \\(\\alpha\\) = 0.79\n\n\n7.3.3 Plot simulated data\n\n\nCode\nggplot(data_wide_likert, aes(x = item_1)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nCode\nggplot(data_wide_likert, aes(x = item_2)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nCode\nggplot(data_wide_likert, aes(x = item_3)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nCode\nggplot(data_wide_likert, aes(x = item_4)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nCode\nggplot(data_wide_likert, aes(x = item_5)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n\nThese plots repeat the mortal coding sin of repeating ourselves. If we reshaped the data to ‘long’ format we could use just one ggplot() call that includes facet_wrap().\n\n\n\n7.3.4 Reshape\nUsing pivot_longer().\n\n\nCode\n# positive selection\ndata_long &lt;- data_wide_likert %&gt;%\n  pivot_longer(cols = starts_with(\"item_\"),\n               names_to = \"item\",\n               values_to = \"response\")\n\n# positive selection using a different tidy select function\ndata_long &lt;- data_wide_likert %&gt;%\n  pivot_longer(cols = contains(\"item_\"),\n               names_to = \"item\",\n               values_to = \"response\")\n\n# negative selection\ndata_long &lt;- data_wide_likert %&gt;%\n  pivot_longer(cols = -id,\n               names_to = \"item\",\n               values_to = \"response\") |&gt;\n  mutate(item = stringr::str_remove(item, \"item_\"))\n\nggplot(data_long, aes(x = response)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw() +\n  facet_wrap(~ item)\n\n\n\n\n\n\n\n\n\n\nWhat other ways could you specify this pivot_longer call’s arguments?\nfacet_wrap() is to {ggplot} as group_by() is to {dplyr}\n\n\n7.3.4.1 Calculate sum scores\n\n\nCode\ntemp &lt;- data_wide_likert |&gt;\n  group_by(id) |&gt;\n  mutate(sum_score = item_1 + item_2 + item_3 + item_4 + item_5)\n  #mutate(sum_score = rowSums(item_1, item_2, item_3, item_4, item_5))\n\n\n\nrow math is much faster than column math in R!\n\n\n\nCode\nsum_scores &lt;- data_long %&gt;%\n  group_by(id) %&gt;%\n  summarise(sum_score = sum(response))\n\n\nggplot(sum_scores, aes(x = sum_score)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  scale_x_continuous(breaks = breaks_pretty(n = 10)) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.5 Convert this long data back to wide\nJust to know how to do it.\n\n\nCode\ndata_wide_again &lt;- data_long %&gt;%\n  pivot_wider(names_from = item,\n              values_from = response,\n              names_prefix = \"item_\")\n\n\n\n\n7.3.6 Combine item and sum scores in one data frame\n\n\nCode\ndata_item_and_sum_scores &lt;- data_wide_again %&gt;%\n  left_join(sum_scores, by = \"id\")\n\n# why joins are needed over bind_cols \n# wrong &lt;- bind_cols(data_wide_again, sum_scores |&gt; select(-id))",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reshaping and pivots: {tidyr}</span>"
    ]
  },
  {
    "objectID": "chapters/reshaping_and_pivots.html#new-facet-plot-with-items-and-sum-score",
    "href": "chapters/reshaping_and_pivots.html#new-facet-plot-with-items-and-sum-score",
    "title": "7  Reshaping and pivots: {tidyr}",
    "section": "7.4 New facet plot with items and sum score",
    "text": "7.4 New facet plot with items and sum score\n\n\nCode\ndata_long_with_sum_score &lt;- data_item_and_sum_scores %&gt;%\n  pivot_longer(cols = -id,\n               names_to = \"item\",\n               values_to = \"response\")\n\nggplot(data_long_with_sum_score, aes(x = response)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw() +\n  facet_wrap(~ item, scales = \"free\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reshaping and pivots: {tidyr}</span>"
    ]
  },
  {
    "objectID": "chapters/reshaping_and_pivots.html#practice",
    "href": "chapters/reshaping_and_pivots.html#practice",
    "title": "7  Reshaping and pivots: {tidyr}",
    "section": "7.5 Practice",
    "text": "7.5 Practice\nWrangle the demographics data included in this exercise more efficiently by reshaping it into wide format. Before, we used filter() to wrangle the age and gender data separately.\n\n\nCode\ndat &lt;- read_csv(\"../data/raw/data_demographics_raw.csv\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reshaping and pivots: {tidyr}</span>"
    ]
  },
  {
    "objectID": "chapters/binding_and_joining.html",
    "href": "chapters/binding_and_joining.html",
    "title": "8  Binding and joining: {dplyr}",
    "section": "",
    "text": "8.1 Dependencies\nCode\nlibrary(dplyr)\nlibrary(readr)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Binding and joining: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/binding_and_joining.html#bind_rows-and-bind_cols",
    "href": "chapters/binding_and_joining.html#bind_rows-and-bind_cols",
    "title": "8  Binding and joining: {dplyr}",
    "section": "8.2 bind_rows() and bind_cols()",
    "text": "8.2 bind_rows() and bind_cols()\nTODO",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Binding and joining: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/binding_and_joining.html#get-data",
    "href": "chapters/binding_and_joining.html#get-data",
    "title": "8  Binding and joining: {dplyr}",
    "section": "8.3 Get data",
    "text": "8.3 Get data\n\n\nCode\ndata_unique_id_subset &lt;- read_csv(\"../data/raw/data_unique_id_subset.csv\")\ndata_age_gender_subset &lt;- read_csv(\"../data/raw/data_age_gender_subset.csv\")\ndata_amp_summary_subset &lt;- read_csv(\"../data/raw/data_amp_summary_subset.csv\")\ndata_selfreport_summary_subset &lt;- read_csv(\"../data/raw/data_selfreport_summary_subset.csv\")\n\nnrow(data_unique_id_subset)\n\n\n[1] 92\n\n\nCode\nnrow(data_age_gender_subset)\n\n\n[1] 90\n\n\nCode\nnrow(data_amp_summary_subset)\n\n\n[1] 31\n\n\nCode\nnrow(data_selfreport_summary_subset)\n\n\n[1] 76",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Binding and joining: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/binding_and_joining.html#practicing-joins",
    "href": "chapters/binding_and_joining.html#practicing-joins",
    "title": "8  Binding and joining: {dplyr}",
    "section": "8.4 Practicing joins",
    "text": "8.4 Practicing joins\nUsing the data frames below and functions from the _join family, write code to do the following joins.\n\n8.4.1 Practice 1\ncreate ‘data_combined’ by joining data_amp_summary_subset and data_age_gender_subset so that unique_ids in either data frame are retained. which join is this? implement it.\n\n\nCode\n# data_combined &lt;- \n\n\n\n\n8.4.2 Practice 2\ncreate ‘data_self_reports_and_their_amp_data’ by joining data_selfreport_summary_subset and data_amp_summary_subset so that all participants have self-report data, + AMP data if available. which join is this? implement it.\n\n\nCode\n# data_self_reports_and_their_amp_data &lt;- \n\n\n\n\n8.4.3 Practice 3\ndo the opposite: create ‘data_amp_data_and_their_self_reports’ by joining data_amp_summary_subset and data_selfreport_summary_subset so that all participants have AMP data, + self-report data if available. which join is this? implement it.\n\n\nCode\n# data_amp_data_and_their_self_reports &lt;- \n\n\n\n\n8.4.4 Practice 4\ncreate data_combined_2 by joining ‘data_combined’ and data_selfreport_summary_subset only unique_ids already present in data_combined are retained. which join is this? implement it.\n\n\nCode\n# data_combined_2 &lt;- \n\n\n\n\n8.4.5 Practice 5\ncreate ‘data_missing_ids’ which should list the unique_ids are missing from data_unique_id_subset but are present in at least one of data_age_gender_subset, data_amp_summary_subset, and data_selfreport_summary_subset. This will require two different joins. Which? Implement them.\n\n\nCode\n# data_missing_ids &lt;-",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Binding and joining: {dplyr}</span>"
    ]
  },
  {
    "objectID": "chapters/structuring_projects.html",
    "href": "chapters/structuring_projects.html",
    "title": "9  Structuring projects: {psychdsish} and GitHub",
    "section": "",
    "text": "9.1 psych-DS\nI have contributed a very small amount to the debate around psych-DS, a data standard for psychological data. ‘Standards’ are specifications for both what must be done or not done, and what may be done to provide flexibility. By having a standard, and an (automated) method of checking compliance with it\nI really like the concept, but also still have to be convinced about some of the choices made in psych-DS. For the moment, I recommend partial compliance with psych-DS: there are high level principles that make for a very well structured project that I try to employ everywhere; but there are also other aspects of psych-DS that are (currently) high-effort-low-reward.\nNote that psych-DS specifies that the data dictionary/codebook must be a json file. I’m not yet convinced it is worth the effort of creating these for many users, as there are few R workflows that make use of them.\npsych-DS principles",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Structuring projects: {psychdsish} and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/structuring_projects.html#psych-ds",
    "href": "chapters/structuring_projects.html#psych-ds",
    "title": "9  Structuring projects: {psychdsish} and GitHub",
    "section": "",
    "text": "github_repository_name/\n├── .gitattributes\n├── .gitignore\n├── code/\n│   ├── analysis.html\n│   ├── analysis.qmd\n│   ├── processing_study_1.html\n│   ├── processing_study_2.html\n│   └── ...\n├── data/\n│   ├── processed/\n│   │   ├── study_1_processed_data.csv\n│   │   ├── study_1_processed_codebook.xlsx\n│   │   ├── study_2_processed_data.csv\n│   │   ├── study_2_processed_codebook.xlsx\n│   │   └── ...\n│   ├── raw/\n│   │   ├── study_1_raw_behavioraltask_data.csv\n│   │   ├── study_2_raw_behavioraltask_data.csv\n│   │   ├── study_1_raw_codebook.xlsx\n│   │   ├── study_2_raw_codebook.xlsx\n│   │   ├── study_1_raw_demographics_data.csv\n│   │   ├── study_2_raw_demographics_data.csv\n│   │   ├── study_1_raw_selfreports_data.csv\n│   │   ├── study_2_raw_selfreports_data.csv\n│   │   └── ...\n│   └── outputs/\n│       ├── plots/\n│       │   ├── plot_1_self_reports.png\n│       │   ├── plot_2_behavioral_task.png\n│       │   └── ...\n│       ├── fitted_models/\n│       │   ├── fit_model_1.rds\n│       │   ├── fit_model_2.rds\n│       │   └── ...\n│       ├── results/\n│       │   ├── cor_matrix_study_1.csv\n│       │   ├── cor_matrix_study_2.csv\n│       │   └── ...\n│       └── ...\n├── LICENSE\n├── methods/\n│   ├── study_1/\n│   │   ├── replication_instructions.docx\n│   │   ├── study_1_labjs.json\n│   │   ├── study_1_measures_and_procedure.docx\n│   │   └── ...\n│   └── study_2/\n│       ├── replication_instructions.docx\n│       ├── study_2_labjs.json\n│       ├── study_2_measures_and_procedure.docx\n│       └── ...\n├── preregistration/\n│   └── preregistration.docx\n├── readme.md\n├── reports/\n│   ├── preprint/\n│   │   ├── preprint.docx\n│   │   └── ...\n│   ├── presentations/\n│   │   ├── conference_presentation.pptx\n│   │   └── ...\n│   └── ...\n└── tools/\n    ├── project_creator.qmd\n    ├── project_validator.qmd\n    └── ...\n\n\n\nThe earliest form of data must be preserved\nOriginal data should never be modified\nDifferent versions of the data should be kept separate\nAll transformations should be documented",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Structuring projects: {psychdsish} and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/structuring_projects.html#sharing-code-and-data-making-preregistrations",
    "href": "chapters/structuring_projects.html#sharing-code-and-data-making-preregistrations",
    "title": "9  Structuring projects: {psychdsish} and GitHub",
    "section": "9.2 Sharing code and data, making preregistrations",
    "text": "9.2 Sharing code and data, making preregistrations\n\n9.2.1 GitHub\nhttps://ui-research.github.io/reproducibility-at-urban/git-overview.html",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Structuring projects: {psychdsish} and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/structuring_projects.html#osf",
    "href": "chapters/structuring_projects.html#osf",
    "title": "9  Structuring projects: {psychdsish} and GitHub",
    "section": "9.3 OSF",
    "text": "9.3 OSF\nLinking github repo to OSF",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Structuring projects: {psychdsish} and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/structuring_projects.html#licensing",
    "href": "chapters/structuring_projects.html#licensing",
    "title": "9  Structuring projects: {psychdsish} and GitHub",
    "section": "9.4 Licensing",
    "text": "9.4 Licensing",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Structuring projects: {psychdsish} and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html",
    "href": "chapters/visualization.html",
    "title": "10  Visualization: {ggplot2}",
    "section": "",
    "text": "11 Dependencies\nhttps://osf.io/preprints/psyarxiv/73ywp_v3\nCode\nlibrary(readr)\nlibrary(ggplot2)\n# install.packages(\"datasauRus\")\nlibrary(datasauRus) \nlibrary(scales)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(plotrix) \n\n# install.packages(\"devtools\")\n# devtools::install_github(\"matthewbjane/ThemePark\")\nlibrary(ThemePark)\nlibrary(patchwork)\nlibrary(janitor)\nlibrary(knitr)\nlibrary(kableExtra)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization: {ggplot2}</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#simple-plot-for-self-reports",
    "href": "chapters/visualization.html#simple-plot-for-self-reports",
    "title": "10  Visualization: {ggplot2}",
    "section": "14.1 Simple plot for self-reports",
    "text": "14.1 Simple plot for self-reports\n\n\nCode\nggplot(data = data_after_exclusions,\n       aes(x = mean_self_report)) +\n  geom_histogram(binwidth = 1)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization: {ggplot2}</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#slightly-better-plot-for-self-reports",
    "href": "chapters/visualization.html#slightly-better-plot-for-self-reports",
    "title": "10  Visualization: {ggplot2}",
    "section": "14.2 Slightly better plot for self-reports",
    "text": "14.2 Slightly better plot for self-reports\n\n\nCode\nggplot(data = data_after_exclusions,\n       aes(x = mean_self_report)) +\n  # more intelligent choices for the binwidth and boundary\n  geom_histogram(binwidth = 1, boundary = 0.5) +\n  # labeling of the axis points\n  scale_x_continuous(breaks = scales::breaks_pretty(n = 7),\n                     limits = c(0.5, 7.5)) +\n  scale_y_continuous(breaks = seq(0, 60, 10)) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization: {ggplot2}</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#exercise-plot-for-gender",
    "href": "chapters/visualization.html#exercise-plot-for-gender",
    "title": "10  Visualization: {ggplot2}",
    "section": "14.3 Exercise: Plot for gender",
    "text": "14.3 Exercise: Plot for gender\nCreate a similar plot for the gender variable in data_processed (ie before exclusions).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization: {ggplot2}</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#exercise-plot-for-amp",
    "href": "chapters/visualization.html#exercise-plot-for-amp",
    "title": "10  Visualization: {ggplot2}",
    "section": "14.4 Exercise: Plot for AMP",
    "text": "14.4 Exercise: Plot for AMP\nCreate a similar plot for the AMP scores in data_after_exclusions.\n\n\nCode\nmean_amp &lt;- data_after_exclusions |&gt;\n  summarize(mean_amp = mean(amp_score)) |&gt;\n  pull(mean_amp)\n\n\nplot_amp &lt;- \n  ggplot(data = data_after_exclusions,\n         aes(x = amp_score)) +\n  geom_histogram(binwidth = 0.1) +\n  scale_x_continuous(breaks = seq(0, 1, .10),\n                     name = \"AMP score\") +\n  scale_y_continuous(breaks = seq(0, 40, 5),\n                     name = \"Frequency\") +\n  geom_vline(xintercept = mean_amp, linetype = \"dotted\") +\n  theme_linedraw()\n\nplot_amp\n\n\n\n\n\n\n\n\n\nCode\nggsave(plot = plot_amp,\n       filename = \"plots/plot_amp.pdf\", \n       width = 6,\n       height = 5)\n\n\n\nExercise: How to add a dashed vertical line at the sample’s mean AMP score?",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization: {ggplot2}</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#simple-plot-for-self-reports-1",
    "href": "chapters/visualization.html#simple-plot-for-self-reports-1",
    "title": "10  Visualization: {ggplot2}",
    "section": "15.1 Simple plot for self-reports",
    "text": "15.1 Simple plot for self-reports\n\n\nCode\nggplot(data = data_after_exclusions,\n       aes(x = mean_self_report)) +\n  geom_density(adjust = 1, # the degree of smoothing can be adjusted here \n               color = \"#FF69B4\",\n               fill = \"darkblue\", \n               alpha = 0.3) +\n  # labeling of the axis points\n  scale_x_continuous(breaks = scales::breaks_pretty(n = 7),\n                     limits = c(1, 7)) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization: {ggplot2}</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#exercise-plot-for-amp-1",
    "href": "chapters/visualization.html#exercise-plot-for-amp-1",
    "title": "10  Visualization: {ggplot2}",
    "section": "15.2 Exercise: Plot for AMP",
    "text": "15.2 Exercise: Plot for AMP\nMake a similar density plot for the AMP.\n\nAdd a theme.\nMake the X axis breaks prettier.\nName both axis names more clearly.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization: {ggplot2}</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#simple-plot-for-amp",
    "href": "chapters/visualization.html#simple-plot-for-amp",
    "title": "10  Visualization: {ggplot2}",
    "section": "16.1 Simple plot for AMP",
    "text": "16.1 Simple plot for AMP\n\n\nCode\n# create the summary values to be plotted\nsummary_amp &lt;- data_after_exclusions %&gt;%\n  group_by(gender) %&gt;%\n  summarize(amp_mean = mean(amp_score),\n            amp_se = plotrix::std.error(amp_score))\n\n# plot these values\nggplot(data = summary_amp, \n       aes(x = gender, \n           y = amp_mean)) +\n  geom_col() +\n  # geom_bar(stat = \"identity\") + # NB geom_col is equivalent to geom_bar when stat == \"identity\n  geom_linerange(aes(ymin = amp_mean - amp_se, \n                     ymax = amp_mean + amp_se))",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization: {ggplot2}</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#slightly-better-plot-for-amp",
    "href": "chapters/visualization.html#slightly-better-plot-for-amp",
    "title": "10  Visualization: {ggplot2}",
    "section": "16.2 Slightly better plot for AMP",
    "text": "16.2 Slightly better plot for AMP\n\n\nCode\nggplot(data = summary_amp, \n       aes(x = gender, \n           y = amp_mean)) +\n  geom_col(fill = \"#0b6623\", # note that you can specify specific colors using hex codes or names\n           color = \"black\", \n           width = 0.6) +\n  geom_errorbar(aes(ymin = amp_mean - amp_se, \n                    ymax = amp_mean + amp_se), \n                width = 0.1, \n                color = \"black\") +\n  labs(title = \"Bar Plot of with Standard Errors\",\n       x = \"Gender\",\n       y = \"Mean AMP score\") +\n  theme_linedraw()",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization: {ggplot2}</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#exercise-plot-for-self-reports",
    "href": "chapters/visualization.html#exercise-plot-for-self-reports",
    "title": "10  Visualization: {ggplot2}",
    "section": "16.3 Exercise: Plot for self-reports",
    "text": "16.3 Exercise: Plot for self-reports\nMake a similar plot for the self-reports.\n\nUse coord_flip() to swap the X and Y axes.\n\n\nExercise: How to capitalize ‘Male’ and ‘Female’ by wrangling the data before plotting?",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization: {ggplot2}</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#exercise",
    "href": "chapters/visualization.html#exercise",
    "title": "10  Visualization: {ggplot2}",
    "section": "18.1 Exercise",
    "text": "18.1 Exercise\nCreate a plot that assesses the association between self report scores and AMP scores. By wrangling data_processed more prior to plotting, and using facet_grid(), compare a) men vs women and b) participants who are 30+ years old vs younger than 30.\nImprove the appearance of the plot, including its text, colors, theme, etc.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization: {ggplot2}</span>"
    ]
  },
  {
    "objectID": "chapters/reporting.html",
    "href": "chapters/reporting.html",
    "title": "11  Reporting: {easystats}",
    "section": "",
    "text": "11.1 Dependencies\nCode\nlibrary(dplyr)\nlibrary(readr)\nlibrary(report) # part of {easystats}\nlibrary(see) # part of {easystats}\nlibrary(parameters) # part of {easystats}\nlibrary(correlation) # part of {easystats}\nlibrary(effectsize) # part of {easystats}\nlibrary(performance) # part of {easystats}\nlibrary(janitor)\nlibrary(lme4)\nlibrary(knitr)\nlibrary(kableExtra)",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reporting: {easystats}</span>"
    ]
  },
  {
    "objectID": "chapters/reporting.html#inference-tests",
    "href": "chapters/reporting.html#inference-tests",
    "title": "11  Reporting: {easystats}",
    "section": "11.2 Inference tests",
    "text": "11.2 Inference tests\n\n11.2.1 Regressions\n\n\nCode\n# fit model\nmodel &lt;- lm(wt ~ 1 + am + mpg, data = mtcars)\n\n# report - text output (nb omits intercept!)\nreport(model)\n\n\nWe fitted a linear model (estimated using OLS) to predict wt with am and mpg\n(formula: wt ~ 1 + am + mpg). The model explains a statistically significant\nand substantial proportion of variance (R2 = 0.80, F(2, 29) = 57.66, p &lt; .001,\nadj. R2 = 0.79). The model's intercept, corresponding to am = 0 and mpg = 0, is\nat 5.74 (95% CI [5.11, 6.36], t(29) = 18.64, p &lt; .001). Within this model:\n\n  - The effect of am is statistically significant and negative (beta = -0.53, 95%\nCI [-0.94, -0.11], t(29) = -2.58, p = 0.015; Std. beta = -0.27, 95% CI [-0.48,\n-0.06])\n  - The effect of mpg is statistically significant and negative (beta = -0.11,\n95% CI [-0.15, -0.08], t(29) = -6.79, p &lt; .001; Std. beta = -0.71, 95% CI\n[-0.92, -0.49])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nCode\n# each parameter (including intercept)\nreport_parameters(model)\n\n\n  - The intercept is statistically significant and positive (beta = 5.74, 95% CI [5.11, 6.36], t(29) = 18.64, p &lt; .001; Std. beta = 1.10e-16, 95% CI [-0.17, 0.17])\n  - The effect of am is statistically significant and negative (beta = -0.53, 95% CI [-0.94, -0.11], t(29) = -2.58, p = 0.015; Std. beta = -0.27, 95% CI [-0.48, -0.06])\n  - The effect of mpg is statistically significant and negative (beta = -0.11, 95% CI [-0.15, -0.08], t(29) = -6.79, p &lt; .001; Std. beta = -0.71, 95% CI [-0.92, -0.49])\n\n\nCode\n# just parameters in text format\nreport_statistics(model)\n\n\nbeta = 5.74, 95% CI [5.11, 6.36], t(29) = 18.64, p &lt; .001; Std. beta = 1.10e-16, 95% CI [-0.17, 0.17]\nbeta = -0.53, 95% CI [-0.94, -0.11], t(29) = -2.58, p = 0.015; Std. beta = -0.27, 95% CI [-0.48, -0.06]\nbeta = -0.11, 95% CI [-0.15, -0.08], t(29) = -6.79, p &lt; .001; Std. beta = -0.71, 95% CI [-0.92, -0.49]\n\n\nCode\n# just parameters in table format\nparameters(model)\n\n\nParameter   | Coefficient |   SE |         95% CI | t(29) |      p\n------------------------------------------------------------------\n(Intercept) |        5.74 | 0.31 | [ 5.11,  6.36] | 18.64 | &lt; .001\nam          |       -0.53 | 0.20 | [-0.94, -0.11] | -2.58 | 0.015 \nmpg         |       -0.11 | 0.02 | [-0.15, -0.08] | -6.79 | &lt; .001\n\n\nCode\n# just parameters in table html format \nparameters(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\n\n\n\n\n(Intercept)\n5.74\n0.31\n0.95\n5.11\n6.36\n18.64\n29\np &lt; .001\n\n\nam\n-0.53\n0.20\n0.95\n-0.94\n-0.11\n-2.58\n29\np = 0.015\n\n\nmpg\n-0.11\n0.02\n0.95\n-0.15\n-0.08\n-6.79\n29\np &lt; .001\n\n\n\n\n\nCode\n# what if i just want some of these cols?\nparameters(model) |&gt;\n  as.data.frame() |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  select(r = Coefficient, ci_lower = CI_low, ci_upper = CI_high, p) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2)\n\n\n      r ci_lower ci_upper         p\n1  5.74     5.11     6.36  p &lt; .001\n2 -0.53    -0.94    -0.11 p = 0.015\n3 -0.11    -0.15    -0.08  p &lt; .001\n\n\nCode\n# table in markdown format\nreport_table(model)\n\n\nParameter   | Coefficient |         95% CI | t(29) |      p | Std. Coef.\n------------------------------------------------------------------------\n(Intercept) |        5.74 | [ 5.11,  6.36] | 18.64 | &lt; .001 |   1.10e-16\nam          |       -0.53 | [-0.94, -0.11] | -2.58 | 0.015  |      -0.27\nmpg         |       -0.11 | [-0.15, -0.08] | -6.79 | &lt; .001 |      -0.71\n            |             |                |       |        |           \nAIC         |             |                |       |        |           \nAICc        |             |                |       |        |           \nBIC         |             |                |       |        |           \nR2          |             |                |       |        |           \nR2 (adj.)   |             |                |       |        |           \nSigma       |             |                |       |        |           \n\nParameter   | Std. Coef. 95% CI |   Fit\n---------------------------------------\n(Intercept) |    [-0.17,  0.17] |      \nam          |    [-0.48, -0.06] |      \nmpg         |    [-0.92, -0.49] |      \n            |                   |      \nAIC         |                   | 45.05\nAICc        |                   | 46.53\nBIC         |                   | 50.91\nR2          |                   |  0.80\nR2 (adj.)   |                   |  0.79\nSigma       |                   |  0.45\n\n\nCode\n# table in html format - needs to be rounded manually\nreport_table(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\n\nParameter\nCoefficient\nCI\nCI_low\nCI_high\nt\ndf_error\np\nStd_Coefficient\nStd_Coefficient_CI_low\nStd_Coefficient_CI_high\nFit\n\n\n\n\n1\n(Intercept)\n5.74\n0.95\n5.11\n6.36\n18.64\n29\np &lt; .001\n0.00\n-0.17\n0.17\nNA\n\n\n2\nam\n-0.53\n0.95\n-0.94\n-0.11\n-2.58\n29\np = 0.015\n-0.27\n-0.48\n-0.06\nNA\n\n\n3\nmpg\n-0.11\n0.95\n-0.15\n-0.08\n-6.79\n29\np &lt; .001\n-0.71\n-0.92\n-0.49\nNA\n\n\n4\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\n\n\n5\nAIC\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n45.05\n\n\n6\nAICc\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n46.53\n\n\n7\nBIC\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n50.91\n\n\n8\nR2\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n0.80\n\n\n9\nR2 (adj.)\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n0.79\n\n\n11\nSigma\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n0.45\n\n\n\n\n\nCode\n# plot\nparameters(model) |&gt;\n  plot() \n\n\n\n\n\n\n\n\n\n\n\n11.2.2 Correlations\n\n11.2.2.1 Single correlation tests\n\n\nCode\n# fit model\nmodel &lt;- cor.test(mtcars$mpg, mtcars$wt)\n\n# report - text output \nreport(model)\n\n\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Pearson's product-moment correlation between mtcars$mpg and mtcars$wt is\nnegative, statistically significant, and very large (r = -0.87, 95% CI [-0.93,\n-0.74], t(30) = -9.56, p &lt; .001)\n\n\nCode\n# table in html format - needs to be rounded manually\nreport_table(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nAlternative\n\n\n\n\nmtcars$mpg\nmtcars$wt\n-0.87\n0.95\n-0.93\n-0.74\n-9.56\n30\np &lt; .001\nPearson's product-moment correlation\ntwo.sided\n\n\n\n\n\n\n\n11.2.2.2 Many\n\n\nCode\nresults &lt;- correlation(iris)\n\nresults\n\n\n# Correlation Matrix (pearson-method)\n\nParameter1   |   Parameter2 |     r |         95% CI | t(148) |         p\n-------------------------------------------------------------------------\nSepal.Length |  Sepal.Width | -0.12 | [-0.27,  0.04] |  -1.44 | 0.152    \nSepal.Length | Petal.Length |  0.87 | [ 0.83,  0.91] |  21.65 | &lt; .001***\nSepal.Length |  Petal.Width |  0.82 | [ 0.76,  0.86] |  17.30 | &lt; .001***\nSepal.Width  | Petal.Length | -0.43 | [-0.55, -0.29] |  -5.77 | &lt; .001***\nSepal.Width  |  Petal.Width | -0.37 | [-0.50, -0.22] |  -4.79 | &lt; .001***\nPetal.Length |  Petal.Width |  0.96 | [ 0.95,  0.97] |  43.39 | &lt; .001***\n\np-value adjustment method: Holm (1979)\nObservations: 150\n\n\nCode\nresults %&gt;%\n  summary(redundant = TRUE) %&gt;%\n  plot()\n\n\n\n\n\n\n\n\n\n\n\n11.2.2.3 By group\n\n\nCode\niris %&gt;%\n  select(Species, Sepal.Length, Sepal.Width, Petal.Width) %&gt;%\n  group_by(Species) %&gt;%\n  correlation()\n\n\n# Correlation Matrix (pearson-method)\n\nGroup      |   Parameter1 |  Parameter2 |    r |        95% CI | t(48) |         p\n----------------------------------------------------------------------------------\nsetosa     | Sepal.Length | Sepal.Width | 0.74 | [ 0.59, 0.85] |  7.68 | &lt; .001***\nsetosa     | Sepal.Length | Petal.Width | 0.28 | [ 0.00, 0.52] |  2.01 | 0.101    \nsetosa     |  Sepal.Width | Petal.Width | 0.23 | [-0.05, 0.48] |  1.66 | 0.104    \nversicolor | Sepal.Length | Sepal.Width | 0.53 | [ 0.29, 0.70] |  4.28 | &lt; .001***\nversicolor | Sepal.Length | Petal.Width | 0.55 | [ 0.32, 0.72] |  4.52 | &lt; .001***\nversicolor |  Sepal.Width | Petal.Width | 0.66 | [ 0.47, 0.80] |  6.15 | &lt; .001***\nvirginica  | Sepal.Length | Sepal.Width | 0.46 | [ 0.20, 0.65] |  3.56 | 0.002**  \nvirginica  | Sepal.Length | Petal.Width | 0.28 | [ 0.00, 0.52] |  2.03 | 0.048*   \nvirginica  |  Sepal.Width | Petal.Width | 0.54 | [ 0.31, 0.71] |  4.42 | &lt; .001***\n\np-value adjustment method: Holm (1979)\nObservations: 50\n\n\n\n\n\n11.2.3 t-tests\nNB Cohen’s d is approximated - better to calculate it separately and accurately.\n\n\nCode\n# fit model\nmodel &lt;- t.test(mpg ~ am, data = mtcars)\n\n# report - text output \nreport(model)\n\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference of mpg by am (mean in group\n0 = 17.15, mean in group 1 = 24.39) suggests that the effect is negative,\nstatistically significant, and large (difference = -7.24, 95% CI [-11.28,\n-3.21], t(18.33) = -3.77, p = 0.001; Cohen's d = -1.76, 95% CI [-2.82, -0.67])\n\n\nCode\n# table in html format - needs to be rounded manually\nreport_table(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nParameter\nGroup\nMean_Group1\nMean_Group2\nDifference\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nAlternative\nd\nd_CI_low\nd_CI_high\n\n\n\n\nmpg\nam\n17.15\n24.39\n-7.24\n0.95\n-11.28\n-3.21\n-3.77\n18.33\np = 0.001\nWelch Two Sample t-test\ntwo.sided\n-1.76\n-2.82\n-0.67\n\n\n\n\n\nCode\n# estimate Cohen's d directly from data\ncohens_d(mpg ~ am, data = mtcars)\n\n\nCohen's d |         95% CI\n--------------------------\n-1.48     | [-2.27, -0.67]\n\n- Estimated using pooled SD.\n\n\n\n\n11.2.4 Multilevel/hierarchical/mixed models\n\n\nCode\n# fit model\nmodel &lt;- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)\n\n# parameters in text format \nreport(model)\n\n\nWe fitted a linear mixed model (estimated using REML and nloptwrap optimizer)\nto predict Reaction with Days (formula: Reaction ~ Days). The model included\nDays as random effects (formula: ~Days | Subject). The model's total\nexplanatory power is substantial (conditional R2 = 0.80) and the part related\nto the fixed effects alone (marginal R2) is of 0.28. The model's intercept,\ncorresponding to Days = 0, is at 251.41 (95% CI [237.94, 264.87], t(174) =\n36.84, p &lt; .001). Within this model:\n\n  - The effect of Days is statistically significant and positive (beta = 10.47,\n95% CI [7.42, 13.52], t(174) = 6.77, p &lt; .001; Std. beta = 0.54, 95% CI [0.38,\n0.69])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nCode\n# parameters in table format\nparameters(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\nEffects\nGroup\n\n\n\n\n(Intercept)\n251.41\n6.82\n0.95\n237.94\n264.87\n36.84\n174\np &lt; .001\nfixed\n\n\n\nDays\n10.47\n1.55\n0.95\n7.42\n13.52\n6.77\n174\np &lt; .001\nfixed\n\n\n\nSD (Intercept)\n24.74\nNA\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\n\n\nSD (Days)\n5.92\nNA\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\n\n\nCor (Intercept~Days)\n0.07\nNA\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\n\n\nSD (Observations)\n25.59\nNA\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nResidual\n\n\n\n\n\nCode\n# table in html format - needs to be rounded manually\nreport_table(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\n\nParameter\nCoefficient\nCI\nCI_low\nCI_high\nt\ndf_error\np\nEffects\nGroup\nStd_Coefficient\nStd_Coefficient_CI_low\nStd_Coefficient_CI_high\nFit\n\n\n\n\n1\n(Intercept)\n251.41\n0.95\n237.94\n264.87\n36.84\n174\np &lt; .001\nfixed\n\n0.00\n-0.32\n0.32\nNA\n\n\n2\nDays\n10.47\n0.95\n7.42\n13.52\n6.77\n174\np &lt; .001\nfixed\n\n0.54\n0.38\n0.69\nNA\n\n\n3\nNA\n24.74\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\nNA\nNA\nNA\nNA\n\n\n4\nNA\n5.92\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\nNA\nNA\nNA\nNA\n\n\n5\nNA\n0.07\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\nNA\nNA\nNA\nNA\n\n\n6\nNA\n25.59\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nResidual\nNA\nNA\nNA\nNA\n\n\n7\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n8\nAIC\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n1755.63\n\n\n9\nAICc\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n1756.11\n\n\n10\nBIC\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n1774.79\n\n\n11\nR2 (conditional)\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n0.80\n\n\n12\nR2 (marginal)\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n0.28\n\n\n15\nSigma\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n25.59\n\n\n\n\n\nCode\n# plot\nparameters(model) |&gt;\n  plot() \n\n\n\n\n\n\n\n\n\nCode\n# check assumptions of random effects\nresult &lt;- check_normality(model, effects = \"random\")\nplot(result)\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n11.2.5 ANOVAs\n\n\nCode\n# fit model\nmodel &lt;- aov(mpg ~ factor(gear) + factor(carb), data = mtcars)\n\n# commonly used effect size: partial eta squared\neta_squared(model)\n\n\n# Effect Size for ANOVA (Type I)\n\nParameter    | Eta2 (partial) |       95% CI\n--------------------------------------------\nfactor(gear) |           0.69 | [0.49, 1.00]\nfactor(carb) |           0.66 | [0.41, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\nCode\n# better effect size: partialomega squared\nomega_squared(model)\n\n\n# Effect Size for ANOVA (Type I)\n\nParameter    | Omega2 (partial) |       95% CI\n----------------------------------------------\nfactor(gear) |             0.62 | [0.38, 1.00]\nfactor(carb) |             0.57 | [0.26, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reporting: {easystats}</span>"
    ]
  },
  {
    "objectID": "chapters/reporting.html#summary-statistics",
    "href": "chapters/reporting.html#summary-statistics",
    "title": "11  Reporting: {easystats}",
    "section": "11.3 Summary statistics",
    "text": "11.3 Summary statistics\n\n\nCode\n# all columns\niris |&gt;\n  group_by(Species) |&gt;\n  report_table() \n\n\nGroup      |     Variable | n_Obs | Mean |   SD | Median |  MAD |  Min |  Max\n-----------------------------------------------------------------------------\nsetosa     | Sepal.Length |    50 | 5.01 | 0.35 |   5.00 | 0.30 | 4.30 | 5.80\nsetosa     |  Sepal.Width |    50 | 3.43 | 0.38 |   3.40 | 0.37 | 2.30 | 4.40\nsetosa     | Petal.Length |    50 | 1.46 | 0.17 |   1.50 | 0.15 | 1.00 | 1.90\nsetosa     |  Petal.Width |    50 | 0.25 | 0.11 |   0.20 | 0.00 | 0.10 | 0.60\nversicolor | Sepal.Length |    50 | 5.94 | 0.52 |   5.90 | 0.52 | 4.90 | 7.00\nversicolor |  Sepal.Width |    50 | 2.77 | 0.31 |   2.80 | 0.30 | 2.00 | 3.40\nversicolor | Petal.Length |    50 | 4.26 | 0.47 |   4.35 | 0.52 | 3.00 | 5.10\nversicolor |  Petal.Width |    50 | 1.33 | 0.20 |   1.30 | 0.22 | 1.00 | 1.80\nvirginica  | Sepal.Length |    50 | 6.59 | 0.64 |   6.50 | 0.59 | 4.90 | 7.90\nvirginica  |  Sepal.Width |    50 | 2.97 | 0.32 |   3.00 | 0.30 | 2.20 | 3.80\nvirginica  | Petal.Length |    50 | 5.55 | 0.55 |   5.55 | 0.67 | 4.50 | 6.90\nvirginica  |  Petal.Width |    50 | 2.03 | 0.27 |   2.00 | 0.30 | 1.40 | 2.50\n\nGroup      | Skewness | Kurtosis | n_Missing\n--------------------------------------------\nsetosa     |     0.12 |    -0.25 |         0\nsetosa     |     0.04 |     0.95 |         0\nsetosa     |     0.11 |     1.02 |         0\nsetosa     |     1.25 |     1.72 |         0\nversicolor |     0.11 |    -0.53 |         0\nversicolor |    -0.36 |    -0.37 |         0\nversicolor |    -0.61 |     0.05 |         0\nversicolor |    -0.03 |    -0.41 |         0\nvirginica  |     0.12 |     0.03 |         0\nvirginica  |     0.37 |     0.71 |         0\nvirginica  |     0.55 |    -0.15 |         0\nvirginica  |    -0.13 |    -0.60 |         0\n\n\nCode\n# all columns - html output with rounding\niris |&gt;\n  group_by(Species) |&gt;\n  report_table() |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nGroup\nVariable\nn_Obs\nMean\nSD\nMedian\nMAD\nMin\nMax\nSkewness\nKurtosis\nn_Missing\n\n\n\n\nsetosa\nSepal.Length\n50\n5.01\n0.35\n5.00\n0.30\n4.3\n5.8\n0.12\n-0.25\n0\n\n\nsetosa\nSepal.Width\n50\n3.43\n0.38\n3.40\n0.37\n2.3\n4.4\n0.04\n0.95\n0\n\n\nsetosa\nPetal.Length\n50\n1.46\n0.17\n1.50\n0.15\n1.0\n1.9\n0.11\n1.02\n0\n\n\nsetosa\nPetal.Width\n50\n0.25\n0.11\n0.20\n0.00\n0.1\n0.6\n1.25\n1.72\n0\n\n\nversicolor\nSepal.Length\n50\n5.94\n0.52\n5.90\n0.52\n4.9\n7.0\n0.11\n-0.53\n0\n\n\nversicolor\nSepal.Width\n50\n2.77\n0.31\n2.80\n0.30\n2.0\n3.4\n-0.36\n-0.37\n0\n\n\nversicolor\nPetal.Length\n50\n4.26\n0.47\n4.35\n0.52\n3.0\n5.1\n-0.61\n0.05\n0\n\n\nversicolor\nPetal.Width\n50\n1.33\n0.20\n1.30\n0.22\n1.0\n1.8\n-0.03\n-0.41\n0\n\n\nvirginica\nSepal.Length\n50\n6.59\n0.64\n6.50\n0.59\n4.9\n7.9\n0.12\n0.03\n0\n\n\nvirginica\nSepal.Width\n50\n2.97\n0.32\n3.00\n0.30\n2.2\n3.8\n0.37\n0.71\n0\n\n\nvirginica\nPetal.Length\n50\n5.55\n0.55\n5.55\n0.67\n4.5\n6.9\n0.55\n-0.15\n0\n\n\nvirginica\nPetal.Width\n50\n2.03\n0.27\n2.00\n0.30\n1.4\n2.5\n-0.13\n-0.60\n0\n\n\n\n\n\nCode\n# subset of columns\niris |&gt;\n  group_by(Species) |&gt;\n  report_table() |&gt;\n  select(Group, Variable, n_Obs, Mean, SD) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nGroup\nVariable\nn_Obs\nMean\nSD\n\n\n\n\nsetosa\nSepal.Length\n50\n5.01\n0.35\n\n\nsetosa\nSepal.Width\n50\n3.43\n0.38\n\n\nsetosa\nPetal.Length\n50\n1.46\n0.17\n\n\nsetosa\nPetal.Width\n50\n0.25\n0.11\n\n\nversicolor\nSepal.Length\n50\n5.94\n0.52\n\n\nversicolor\nSepal.Width\n50\n2.77\n0.31\n\n\nversicolor\nPetal.Length\n50\n4.26\n0.47\n\n\nversicolor\nPetal.Width\n50\n1.33\n0.20\n\n\nvirginica\nSepal.Length\n50\n6.59\n0.64\n\n\nvirginica\nSepal.Width\n50\n2.97\n0.32\n\n\nvirginica\nPetal.Length\n50\n5.55\n0.55\n\n\nvirginica\nPetal.Width\n50\n2.03\n0.27",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reporting: {easystats}</span>"
    ]
  },
  {
    "objectID": "chapters/reporting.html#assumption-checks",
    "href": "chapters/reporting.html#assumption-checks",
    "title": "11  Reporting: {easystats}",
    "section": "11.4 Assumption checks",
    "text": "11.4 Assumption checks\nBeware that checking assumptions can lead to as many bad practices as it does good ones! (e.g., poorly justified post hoc outlier exclusion)\n\n11.4.1 Multiple checks at once\n\n\nCode\n# fit model\nmodel &lt;- lm(wt ~ 1 + am + mpg, data = mtcars)\n\n# check multiple model assumptions\ncheck_model(model)\n\n\n\n\n\n\n\n\n\n\n\n11.4.2 Normality of distribution of residuals\n\n\nCode\nres_normality &lt;- check_normality(model)\n\nres_normality\n\n\nWarning: Non-normality of residuals detected (p = 0.013).\n\n\nCode\nplot(res_normality, type = \"qq\")\n\n\n\n\n\n\n\n\n\nCode\nplot(res_normality, type = \"density\")\n\n\n\n\n\n\n\n\n\n\n\n11.4.3 Multicolinearity\n\n\nCode\nres_collinearity &lt;- check_collinearity(model)\n\nres_collinearity\n\n\n# Check for Multicollinearity\n\nLow Correlation\n\n Term  VIF   VIF 95% CI adj. VIF Tolerance Tolerance 95% CI\n   am 1.56 [1.19, 2.68]     1.25      0.64     [0.37, 0.84]\n  mpg 1.56 [1.19, 2.68]     1.25      0.64     [0.37, 0.84]\n\n\nCode\nplot(res_collinearity)\n\n\n\n\n\n\n\n\n\n\n\n11.4.4 Outliers\n\n\nCode\nres_outliers &lt;- check_outliers(model, method = \"cook\") # \"all\" requires other dependencies and can take some time to run  \n#res_outliers &lt;- check_outliers(model, method = \"all\") # \"all\" requires other dependencies and can take some time to run  \n\nres_outliers\n\n\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.808).\n- For variable: (Whole model)\n\n\nCode\nplot(res_outliers)\n\n\n\n\n\n\n\n\n\n\n\n11.4.5 Heteroscedasticity\n\n\nCode\nres_het &lt;- check_heteroscedasticity(model)\n\nres_het\n\n\nOK: Error variance appears to be homoscedastic (p = 0.053).\n\n\nCode\nplot(res_het)",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reporting: {easystats}</span>"
    ]
  },
  {
    "objectID": "chapters/privacy.html",
    "href": "chapters/privacy.html",
    "title": "12  Data privacy and anonymity",
    "section": "",
    "text": "12.1 Data privacy laws, ethical responsibilties, and ‘Private Data’\nTODO\n&lt;Prolific.com&gt; is a website that many researchers use to collect data online and where the public go to be paid to complete studies in psychology and other fields. Prolific ID codes are needed to identify which accounts participated and should be paid. However, Prolific IDs can also contain a lot of Personal Data (in the legal and data privacy sense of the phrase), and are essential to remove from dataset before sharing them (e.g., making them public or sharing with other researchers).\nOther forms of Personal Data which we all have legal responsibilities to remove before sharing data include, but are not limited to: names, addresses, telephone numbers, email addresses, and other personally identifying information. Note that the rows referring to “psychiatric diagnosis” certainly appear to be sensitive information, but they might not be if the other data is suitably anonymized. Note that data de-anonymization/re-identification is for more possible than most researchers appreciate (e.g., knowing your age, gender, diagnosis, and region might allow a third party to link your data to your identity). This course is not on data privacy laws, compliance, or de-anonymization/re-identification risks, which are complex topics, it is only on the code methods you might use to make your project compliant and safe for participants.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Data privacy and anonymity</span>"
    ]
  },
  {
    "objectID": "chapters/privacy.html#negative-filters-for-private-data",
    "href": "chapters/privacy.html#negative-filters-for-private-data",
    "title": "12  Data privacy and anonymity",
    "section": "12.2 Negative filters for Private Data",
    "text": "12.2 Negative filters for Private Data\nTODO",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Data privacy and anonymity</span>"
    ]
  },
  {
    "objectID": "chapters/privacy.html#saving-anonymized-data-to-disk",
    "href": "chapters/privacy.html#saving-anonymized-data-to-disk",
    "title": "12  Data privacy and anonymity",
    "section": "12.3 saving anonymized data to disk",
    "text": "12.3 saving anonymized data to disk\nTODO",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Data privacy and anonymity</span>"
    ]
  },
  {
    "objectID": "chapters/privacy.html#excluding-raw-unanonymized-data-from-subsequent-sharing-e.g.-on-github-via-gitignore-or-directory-seperation-acknowledgement-of-encryption-requirements.",
    "href": "chapters/privacy.html#excluding-raw-unanonymized-data-from-subsequent-sharing-e.g.-on-github-via-gitignore-or-directory-seperation-acknowledgement-of-encryption-requirements.",
    "title": "12  Data privacy and anonymity",
    "section": "12.4 Excluding raw unanonymized data from subsequent sharing, e.g., on github via gitignore or directory seperation; acknowledgement of encryption requirements.",
    "text": "12.4 Excluding raw unanonymized data from subsequent sharing, e.g., on github via gitignore or directory seperation; acknowledgement of encryption requirements.\nTODO\nPurging git histories that contain sensitive information if it was accidentally committed.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Data privacy and anonymity</span>"
    ]
  },
  {
    "objectID": "chapters/license.html",
    "href": "chapters/license.html",
    "title": "13  License and citation",
    "section": "",
    "text": "© Ian Hussey (2025)\nText and figures are licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) license.\nCode is licensed under the MIT License.\nYou are free to copy, share, adapt, and reuse the contents of this book — text, figures, and code — for any purpose, including commercial use, provided you cite it.\nSuggested citation:\nHussey, I. (2025) Reproducible data processing and visualization in R and tidyverse. https://github.com/ianhussey/reproducible-data-processing-and-visualization-in-r",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>License and citation</span>"
    ]
  }
]