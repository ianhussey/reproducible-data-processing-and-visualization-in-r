[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reproducible Data Processing and Visualization",
    "section": "",
    "text": "Introduction\nThis Open Source eBook provides materials for the semester-long Master’s seminar course “Reproducible Data Processing and Visualization in R” that I deliver at the University of Bern’s Institute of Psychology.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-book",
    "href": "index.html#how-to-use-this-book",
    "title": "Reproducible Data Processing and Visualization",
    "section": "How to use this book",
    "text": "How to use this book\nThis book is made up of individual Quarto (.qmd) workbooks. Many of the exercises are easiest to complete in your own local copy of these .qmd files.\nI suggest that you download the .zip file of all the .qmd files and their supporting data and cheatsheets and use the eBook as a reference book. If the the .zip file does not contain the most recent versions, please contact me and I’ll updated it. If you’re impatient, you can also download the most recent versions from GitHub, along with the other files that create this eBook.\nYou can also copy and paste the code for any chapter directly from the website. Click the “&lt;/&gt; Code” button on the top right of each page to see the full .qmd file’s code. You can copy and paste this into a .qmd file. However, it’s probably easier to download all the .qmd files and data as mentioned above.\nLearning to code is a practice skill. Almost anyone can become competent in writing reproducible code for data processing and visualization with practice. More than anything else, completing this course requires that you practice in your own time, using not only the examples provided but also ones you create yourself. Take real data sets from your own studies, or the thousands available on the Open Science Framework (osf.io), or create simulated data sets, and practice.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#other-learning-resources",
    "href": "index.html#other-learning-resources",
    "title": "Reproducible Data Processing and Visualization",
    "section": "Other learning resources",
    "text": "Other learning resources\nThere are many excellent Open Source resources to learn R and {tidyverse} for data processing and visualization. Readers are encouraged to seek them out to support the materials already provided in this book. I can particularly recommend the following ones:\n\nLisa DeBruine et al.’s (2021) Open Source textbook Data Skills for Reproducible Research\n\nSection on {dplyr}\nSection on {tidyr}\n\nAllison Horst’s interactive web app for learning {dplyr}\nHadley Wickham’s Open Source textbook R For Data Science (aka R4DS)\n\nSection on data transformation\n\nGarrick Aden-Buie’s tidyexplain gifs for understanding how {tidyr}’s pivot functions work\ndatasciencebox.org\n\nInteractive tutorials that very useful for practicing processing and visualization skills once you’ve already learned the functions (i.e., don’t start here)\n\nPractice the functions ggplot\nPractice the functions ggplot, pipe, mutate\nPractice the functions ggplot, pipe, select, arrange, summarize, count, filter\nPractice the functions count, arrange, summarize\n\nRecorded presentations on many relevant topics",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/setup.html",
    "href": "chapters/setup.html",
    "title": "1  Installation and setup",
    "section": "",
    "text": "1.1 Install the base R language and the RStudio IDE\nYou should install the base R language and the RStudio IDE from here.\nThere are detailed steps available for Windows and Mac here.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installation and setup</span>"
    ]
  },
  {
    "objectID": "chapters/setup.html#rstudio-settings-and-options",
    "href": "chapters/setup.html#rstudio-settings-and-options",
    "title": "1  Installation and setup",
    "section": "1.2 RStudio settings and options",
    "text": "1.2 RStudio settings and options\n\n1.2.1 Important settings to change for reproducibility\nFor reproducibility, please ensure RStudio’s settings never save the objects in your environment to disk on exist or load them again when opening RStudio. Open the Tools&gt;Global Options menu, go to General, and untick the following box and set save to ‘Never’.\n\n\n\n1.2.2 RStudio themes\nRStudio can be skinned with different themes, including dark themes that may be easier on your eyes or are, at least, objectively cooler.\nThe objectively coolest theme of them all is Synthwave85, which can be installed by running the following line of code in RStudio’s console: rstudioapi::addTheme(\"https://raw.githubusercontent.com/jnolis/synthwave85/master/Synthwave85.rstheme\", TRUE, TRUE, FALSE)\nTo change themes, click the ‘Tools’ drop down menu, then ‘Global Options’, then ‘Appearance’, then ‘RStudio Theme’.\n\n\n\n1.2.3 RStudio fonts\nCertain monospaced fonts provide the advantage of rendering common R characters or functions more nicely.\nThis is the same code displayed using Monaco, a built-in font:\n\nAnd using JetBrainsMono, which supports rendering the base-R pipe (|&gt;) and non-equivalence symbols as single characters\n\nIf you prefer the latter, you can download JetBrainsMono from here and install on your computer. Restart RStudio, then change the font by clicking the ‘Tools’ drop down menu, then ‘Global Options’, then ‘Appearance’, then ‘Editor font’.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installation and setup</span>"
    ]
  },
  {
    "objectID": "chapters/setup.html#install-slack-and-github",
    "href": "chapters/setup.html#install-slack-and-github",
    "title": "1  Installation and setup",
    "section": "1.3 Install Slack and GitHub",
    "text": "1.3 Install Slack and GitHub\nIf you are reading this book as part of a course with me at the University of Bern, please:\n\nInstall the Slack app. You can download it for Windows here or for Mac here.\nI will send an invitation to the course’s Slack workspace to all students enrolled in the course. Please check your @students.unibe.ch email address.\nInstall the GitHub desktop app. You can download here.\nMake an account yourself on https://github.com and log into it on the GitHub desktop app. University of Bern does provide you access to a branded GitHub account, but you’ll lose access to it after you finish your studies, so it’s better to make your own private account.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installation and setup</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html",
    "href": "chapters/fundamentals.html",
    "title": "2  Fundamentals",
    "section": "",
    "text": "2.1 What’s the difference between Base R, RStudio IDE, and tidyverse?\nThis is an understandable point of confusion, so let’s clarify:\nThere is a long-standing debate about whether base R (alone) or R+{tidyverse} is better. Thankfully, I can resolve this question for you immediately: R+{tidyverse} is better. All hail the One True Language, {tidyverse}.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#whats-the-difference-between-base-r-rstudio-ide-and-tidyverse",
    "href": "chapters/fundamentals.html#whats-the-difference-between-base-r-rstudio-ide-and-tidyverse",
    "title": "2  Fundamentals",
    "section": "",
    "text": "Base R is the coding language that we learn in this course.\nRStudio IDE (Integrated Development Environment) is the application we use to write R code in. There are others but RStudio is the best option, although this could change in future.\n{tidyverse} is a set of R packages that enhance base R’s utility and usability, built around the concept of Tidy Data. We’ll learn about Tidy Data in another chapter. {tidyverse} arguably changes how we write R code so fundamentally that some people argue that R+{tidyverse} should be conceptualized as a meaningfully different language with different conventions and workflows.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#rstudio-ide-basics",
    "href": "chapters/fundamentals.html#rstudio-ide-basics",
    "title": "2  Fundamentals",
    "section": "2.2 RStudio IDE basics",
    "text": "2.2 RStudio IDE basics\nGet familiar with the different parts of the RStudio IDE user interface with this cheatsheet, which you can also download as a pdf here.\n\n\n2.2.1 Source versus Visual editor\nYou can view a .qmd file’s raw code in the ‘Source’ viewer. The button for this appears on the top left above the code in RStudio.\nScreenshot of Source editor mode:\n\nYou can also view the a live preview of the rendered file, including tables, plots, math, etc., using ‘Visual’ editor mode, although there will some simplifications compared to when you render a .html file. We’ll cover rendering in a later chapter.\nScreenshot of Visual editor mode:\n\n\n\n2.2.2 Keyboard shortcuts\nOnce you have learned about some of the concepts mentioned below in later chapters, it can be useful to come back to these cheatsheets to learn the keyboard shortcuts for them.\n\n\n\n2.2.3 Particularly useful shortcuts\nWindows\n\nInsert Chunk: Ctrl + Alt + I\nInsert Pipe (|&gt;): shift + Ctrl + M\nMulti-line typing: Alt + Mouse click-and-highlight multiple lines, then type\nMove cursor by word instead of by character: Alt + arrows\nHighlight words: Shift + alt + arrows\nFix Indentation: Mouse click-and-highlight multiple lines + Ctrl + I\nComment out (#) multiple Lines: Mouse click-and-highlight multiple lines, then Shift + Ctrl + C\n\nMac\n\nInsert Chunk: Cmd + Alt + I\nInsert Pipe (|&gt;): shift + Cmd + M\nMulti-line typing: Alt + Mouse click-and-highlight multiple lines, then type\nMove cursor by word instead of by character: Option + arrows\nHighlight words: Shift + option + arrows\nFix Indentation: Mouse click-and-highlight multiple lines + Cmd + I\nComment out (#) multiple Lines: Mouse click-and-highlight multiple lines, then Shift + Cmd + C\n\nYou can also change or set up additional keyboard shortcuts in the “Tools&gt;Modify keyboard shortcuts” drop down menu. For example, I have modified the shortcut to switch between Source viewer vs. Visual viewer to be “Cmd + `”.\nOf the above, multi-line typing is the one that reliably gets an audiable ‘whoa’ from audiences. It’s easier to see than explain:\n\nWhen you get a bit more experienced with RStudio, I highly recommend you check out this blog post on shortcuts to know about more advanced features such as Function/Variable Extraction, Renaming in Scope, Code Snippets, and advanced search and find-and-replace.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#dependencies",
    "href": "chapters/fundamentals.html#dependencies",
    "title": "2  Fundamentals",
    "section": "2.3 Dependencies",
    "text": "2.3 Dependencies\nInstall libraries from CRAN with install.packages(). This only needs to be done once, not on every run of the script.\n\n\nCode\ninstall.packages(tidyverse)\n\n\nIn-development libraries are sometimes not on CRAN and can be installed directly from GitHub with devtools::install_github().\n\n\nCode\ninstall.packages(devtools)\ndevtools::install_github(\"ianhussey/tides\") # username/repository\n\n\nNecessary packages (aka dependencies) can be loaded with library(). For tidiness, these should usually all be loaded at the start of your script. Some chapters in this book load libraries only when they’re used, to clearly introduce which packages provide which functions.\n\n\nCode\nlibrary(tidyverse) # umbrella package that loads dplyr/tidyr/ggplot2 and others",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#accessing-the-help-menu",
    "href": "chapters/fundamentals.html#accessing-the-help-menu",
    "title": "2  Fundamentals",
    "section": "2.4 Accessing the help menu",
    "text": "2.4 Accessing the help menu\nFor any function in a loaded package, simply type ? before the function’s name to bring up the help menu. This helps you understand the function’s purpose, its arguments, and outputs.\n\n\nCode\n?select\n\n\nIf you scroll to the bottom of a function’s help page, you’ll find an ‘Index’ hyperlink. Clicking this brings you to a list of all the package’s functions. Once you get nerdy, this can be a very useful way to discover and learn all a package’s functions.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#namespace-collisons-a-common-source-of-errors",
    "href": "chapters/fundamentals.html#namespace-collisons-a-common-source-of-errors",
    "title": "2  Fundamentals",
    "section": "2.5 Namespace collisons: a common source of errors",
    "text": "2.5 Namespace collisons: a common source of errors\nSome common packages have identically named functions with different syntax. For example, if you load both {dplyr} and {MASS}, use of the function select() can refer to either dplyr::select() or MASS::select(), and your code might not run if the other package is loaded.\nYou can see if you have two identically named functions loaded by opening the help menu and seeing if more than one entry appears (e.g. with ?select()).\nAvoid this by loading only the packages you need. Debug errors by thinking about these common namespace collisions:\n\n\n\n\n\n\n\n\n\nFunction\ntidyverse Source\nConflicting Package(s)\nNotes\n\n\n\n\nfilter\ndplyr\nstats\nstats::filter() is for signal processing (time series)\n\n\nlag\ndplyr\nstats\nDifferent semantics: dplyr::lag() is simpler\n\n\nselect\ndplyr\nMASS\nMASS::select() is for stepwise regression\n\n\nslice\ndplyr\nIRanges / S4Vectors\nCommon in Bioconductor workflows\n\n\nrename\ndplyr\nMASS\nMASS::rename() is deprecated, but may still load\n\n\nsummarise\ndplyr\nHmisc\nHmisc::summarize() differs in behavior\n\n\nintersect\ndplyr\nbase\ndplyr re-exports base::intersect()\n\n\nunion\ndplyr\nbase\ndplyr re-exports base::union()\n\n\nsetdiff\ndplyr\nbase\ndplyr re-exports base::setdiff()\n\n\ncount\ndplyr\nplyr\nDifferent behavior/output in plyr::count()\n\n\ndesc\ndplyr\nIRanges\nConflicts with IRanges sorting\n\n\nmutate\ndplyr\nplyr\nConflicts common when plyr is loaded\n\n\narrange\ndplyr\nplyr\nSubtle differences; dplyr preferred\n\n\n\nSolve this issue either by specifying which package should be used each time you use the function (e.g., dplyr::select() instead of select()) or by specifying below your library() calls which version is preferred:\n\n\nCode\nlibrary(conflicted)\nconflict_prefer(name = \"select\", winner = \"dplyr\")\n\n\n[conflicted] Will prefer dplyr::select over any other package.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#assignment-of-objects",
    "href": "chapters/fundamentals.html#assignment-of-objects",
    "title": "2  Fundamentals",
    "section": "2.6 Assignment of objects",
    "text": "2.6 Assignment of objects\nAssignment of objects is done via &lt;- by convention.\n\n\nCode\n# set the variable x to be the number 5\nx &lt;- 5\n\n# print the contents of x\nx\n\n\n[1] 5\n\n\nTechnically you can also use =, but it’s best to avoid it.\n\n\nCode\n# set the variable y to be the string \"hello\"\ny = \"hello\"\n\n# print the contents of y\ny\n\n\n[1] \"hello\"\n\n\nIt’s somewhat less well known, but you can also do “right-assignment” (-&gt;) instead of the much more common left assignment (&lt;-).\n\n\nCode\n# set the variable y to be the string \"really? yes.\"\n\"really? yes.\" -&gt; z\n\n# print the contents of z\nz\n\n\n[1] \"really? yes.\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#rounding-round-probably-doesnt-do-what-you-think",
    "href": "chapters/fundamentals.html#rounding-round-probably-doesnt-do-what-you-think",
    "title": "2  Fundamentals",
    "section": "2.7 Rounding: round() probably doesn’t do what you think",
    "text": "2.7 Rounding: round() probably doesn’t do what you think\nDid you know that R doesn’t use the rounding method most of us are taught in school, where .5 is rounded up to the next integer? Instead it uses “banker’s rounding”, which is better when you round a very large number of numbers, but worse for reporting the results of specific analyses.\nThis is easier to show than explain. The round() function rounds each of the numbers passed to it. What do you expect the output to be?\n\n\nCode\nround(c(0.5, \n        1.5, \n        2.5, \n        3.5, \n        4.5, \n        5.5))\n\n\n\n\n\n\n\n\nClick to show result\n\n\n\n\n\n\n[1] 0 2 2 4 4 6\n\nWhy is this? Because R’s round() function uses “banker’s rounding, which rounds 5s based on whether the preceding digit is odd or even. This is a good thing in many contexts like accounting, but it’s usually not what we want or expect when rounding specific statistical results for inclusion in a report or manuscript.\n\n\n\nIn most of your R scripts, you should probably instead use janitor::round_half_up() instead, which produces the round-5-upwards behavior you were probably taught in school.\n\n\nCode\nlibrary(janitor)\n\njanitor::round_half_up(c(0.5, \n                         1.5, \n                         2.5, \n                         3.5, \n                         4.5, \n                         5.5))\n\n\n[1] 1 2 3 4 5 6\n\n\nAnother great option is roundwork::round_up(), which is a package that my PhD student Lukas Jung wrote before joining our research group.\n\n\nCode\nlibrary(roundwork) \n\nroundwork::round_up(c(0.5, \n                      1.5, \n                      2.5, \n                      3.5, \n                      4.5, \n                      5.5))\n\n\n[1] 1 2 3 4 5 6",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#exercises",
    "href": "chapters/fundamentals.html#exercises",
    "title": "2  Fundamentals",
    "section": "2.8 Exercises",
    "text": "2.8 Exercises\n\n2.8.1 Fix indentation / white space\nEdit your local copy of this .qmd file to make the following changes. If you’re reading this as an eBook on the website, create a new .R file in RStudio on your computer (‘File&gt;New File&gt;R script’). Copy and paste the code below into that file.\nWe will cover the functions used in the code in later chapters - you don’t need to understand it yet. Notice that the indentation or ‘white space’ is somewhat chaotic.\nFix this with a keyboard shortcut: with your mouse, highlight the code and press Ctrl + I (Windows) or Cmd + I (Mac) to fix the indentation. Notice how much easier it is to read.\nYou can undo this with Ctrl + z (Windows) or Cmd + z (Mac) if you want to see it before/after again.\n\n\nCode\n# create table\ndat_processed_long %&gt;%\n  # summarize mean and SD by subscale\ndplyr::group_by(subscale) %&gt;%\n  dplyr::summarize(n = dplyr::n(),\nm = mean(score, na.rm = TRUE),\n               sd = sd(score, na.rm = TRUE)) %&gt;%\n  # round estimates \n  dplyr::mutate(m = janitor::round_half_up(m, digits = 2),\n  sd = janitor::round_half_up(sd, digits = 2)) %&gt;%\n# print nicer table\nknitr::kable(align = 'r') |&gt;\n  kableExtra::kable_styling()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html",
    "href": "chapters/reproducible_reports.html",
    "title": "3  Reproducible reports",
    "section": "",
    "text": "3.1 Literate programming\nLiterate programming is the idea that code and text should be written in the same document to produce a narrative with reproducible results. It is therefore very suited to writing scientific reports and manuscripts.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#literate-programming",
    "href": "chapters/reproducible_reports.html#literate-programming",
    "title": "3  Reproducible reports",
    "section": "",
    "text": "3.1.1 In line code\nCode can be written in ‘in line’ in the text as follows: 2. In the RMarkdown document, you have hover over the in line code and press enter or return to run the code.\n\n\n3.1.2 Code chunks\nFor any code that isn’t extremely short, you should write it in code chunks.\nThese are written as follows: three backticks followed by “{r}” specifies that it is a chunk of R code, then the code, then three more backticks to end the chunk. Note that backticks are not apostrophes! (` vs ’).\nYou can also insert a code chunk with Ctrl + Alt + I (Windows) or Cmd + Alt + I (Mac).\nOutput appears below chunks. You can run all code in a chunk by clicking the right-arrow button to the right of the chunk: \nYou can also run all previous chunks in a document not including the current chunk by clicking the downward arrow button to the right of the chunk: \nFor example:\n\n\nCode\n2+2\n\n\n[1] 4",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#rendering-and-reproducibilty",
    "href": "chapters/reproducible_reports.html#rendering-and-reproducibilty",
    "title": "3  Reproducible reports",
    "section": "3.2 Rendering and reproducibilty",
    "text": "3.2 Rendering and reproducibilty\nQuarto (.qmd) and RMarkdown (.Rmd) files can produce .html files that can be viewed in any web browser. This has two key functions:\n\nIt allows you to make more attractive outputs with tables, plots, and results.\nIt can greatly increase reproducibility. Each time you ‘render’ a .html file from a .qmd/.Rmd, the code is run in a new R session in the background. The .html file is only created if all the code runs. This is extremely useful for ensuring that your code does indeed run, that you have all necessary packages loaded, etc. Note however that it does not ensure that your code is error free, that there are not unnecessary packages loaded, etc.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#markdown-formatting-and-levels-of-heading",
    "href": "chapters/reproducible_reports.html#markdown-formatting-and-levels-of-heading",
    "title": "3  Reproducible reports",
    "section": "3.3 Markdown formatting and levels of heading",
    "text": "3.3 Markdown formatting and levels of heading\nQuarto (.qmd) and RMarkdown files (.Rmd) allow you to use markdown formatting. This is a very simple way to do basic formatting, such as headings, emphasis, bullet points and lists.\nMarkdown formatting can be used as follows.\nDon’t forget the space after the #, or spaces between lines to separate sections of different types!\n# Level 1 heading\n\n## Level 2 heading\n\n### Level 3 heading\n\nNormal text.\n\n*italic text*\n\n**bold text**\n\n- bullet points\n- bullet points\n\n1. numbered list\n2. numbered list\n\nDisplay an image in visual editor/on rendering:\n![](../images/r_meme.png)\nEach of the above are rendered as follows in the .html file once rendered:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#level-1-heading",
    "href": "chapters/reproducible_reports.html#level-1-heading",
    "title": "3  Reproducible reports",
    "section": "3.4 Level 1 heading",
    "text": "3.4 Level 1 heading\n\n3.4.1 Level 2 heading\n\n3.4.1.1 Level 3 heading\nNormal text.\nitalic text\nbold text\n\nbullet points\nbullet points\n\n\nnumbered list\nnumbered list\n\nDisplay an image in visual editor/on rendering:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#table-of-contents-and-outline",
    "href": "chapters/reproducible_reports.html#table-of-contents-and-outline",
    "title": "3  Reproducible reports",
    "section": "3.5 Table of contents and outline",
    "text": "3.5 Table of contents and outline\nLevels of heading are extremely useful for structuring your report.\n\nThey automatically appear as headings in the “Outline” section in RStudio, therefore allowing you to navigate your document easily. When you have a .qmd or .Rmd file open in RStudio, click the ‘Outline’ button to the top-right of the source file window, where this text appears, to see all the headings in your file. Click any of them to go to that heading in the document.\nWhen the file is rendered (.qmd) or knited (.Rmd) to a .html file, the levels of heading will appear as clickable links in the table of contents (assuming that your YAML header at the top of your file has toc: true, as this file does).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#math-typesetting-via-latex",
    "href": "chapters/reproducible_reports.html#math-typesetting-via-latex",
    "title": "3  Reproducible reports",
    "section": "3.6 Math typesetting via LaTeX",
    "text": "3.6 Math typesetting via LaTeX\nYou can include math in line with LaTeX code placed between dollar signs: e.g., “$\\eta_{p}^{2}$ = 0.03” produces “\\(\\eta_{p}^{2}\\) = 0.03”.\nYou can also write longer chunks of LaTeX, for example to specify that the mean (\\(\\bar{x}\\)) is the sum of all elements of the vector \\(x\\) divided by number of elements in the vector (\\(n\\)).\nThis code:\n$$\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i.\n$$\nProduces this math:\n\\[\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#reading-processing-and-writing-data",
    "href": "chapters/reproducible_reports.html#reading-processing-and-writing-data",
    "title": "3  Reproducible reports",
    "section": "3.7 Reading, processing, and writing data",
    "text": "3.7 Reading, processing, and writing data\nRaw data can be read in from .csv, .xlsx, SPSS .sav, and many other types of files. Raw data can be processed and tidied into analyzable data and saved to disk.\nWe will cover these functions in later chapters. For the moment, the point to appreciate is that clear, reproducible workflows are easy to write in R+tidyverse.\nRead the comments and code below to see if you can understand the general flow of what is being done, even without knowing these functions yet.\n\n\nCode\n# dependencies\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\n\n# load raw data\ndat_raw &lt;- readr::read_csv(\"../data/raw/data_raw_bfi.csv\")\n\n# process data\ndat_processed &lt;- dat_raw %&gt;%\n  # rename variable to make it clearer\n  dplyr::rename(race_iat = IAT_score) %&gt;%\n  # exclude participants with missing data or who did not meet performance criteria\n  dplyr::filter(complete_individual_differences_data == TRUE & exclude_iat == FALSE) %&gt;%\n  # calculate sum scores for the BFI personality subscales\n  dplyr::rowwise() %&gt;%\n  dplyr::mutate(openness = mean(c_across(starts_with(\"bfi_o\"))),\n                conscientiousness = mean(c_across(starts_with(\"bfi_c\"))),\n                extroversion = mean(c_across(starts_with(\"bfi_e\"))),\n                agreeableness = mean(c_across(starts_with(\"bfi_a\"))),\n                neuroticism = mean(c_across(starts_with(\"bfi_n\")))) %&gt;%\n  dplyr::ungroup() %&gt;%\n  # retain only the columns needed\n  dplyr::select(race_iat, openness, conscientiousness, extroversion, agreeableness, neuroticism)\n\n# create a directory to save processed data to \ndir.create(\"../data/processed\")\n\n# save data\nreadr::write_csv(dat_processed, \"../data/processed/data_processed_bfi_race_iat.csv\")\n\n# reshape to long format for tables and plots\ndat_processed_long &lt;- dat_processed %&gt;%\n  tidyr::pivot_longer(cols = c(openness, conscientiousness, extroversion, agreeableness, neuroticism),\n                      names_to = \"subscale\",\n                      values_to = \"score\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#tables",
    "href": "chapters/reproducible_reports.html#tables",
    "title": "3  Reproducible reports",
    "section": "3.8 Tables",
    "text": "3.8 Tables\nSummary statistics such as sample sizes, means and Standard Deviations can be calculated, rounded, and presented in tables.\nAgain, we will cover these functions in later chapters. For the moment, simply notice that this is quite simple to do. As before, tead the comments and code below to see if you can understand the general flow of what is being done, even without knowing these functions yet.\n\n\nCode\n# dependencies\nlibrary(janitor)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# table\ndat_processed_long %&gt;%\n  # summarize mean and SD by subscale\n  dplyr::group_by(subscale) %&gt;%\n  dplyr::summarize(n = dplyr::n(),\n                   m = mean(score, na.rm = TRUE),\n                   sd = sd(score, na.rm = TRUE)) %&gt;%\n  # round estimates \n  dplyr::mutate(m = janitor::round_half_up(m, digits = 2),\n                sd = janitor::round_half_up(sd, digits = 2)) %&gt;%\n  # print nicer table\n  knitr::kable(align = 'r') |&gt;\n  kableExtra::kable_styling()\n\n\n\n\n\nsubscale\nn\nm\nsd\n\n\n\n\nagreeableness\n167\n4.00\n0.38\n\n\nconscientiousness\n167\n4.24\n0.48\n\n\nextroversion\n167\n4.18\n0.49\n\n\nneuroticism\n167\n3.91\n0.50\n\n\nopenness\n167\n4.37\n0.48",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#plots",
    "href": "chapters/reproducible_reports.html#plots",
    "title": "3  Reproducible reports",
    "section": "3.9 Plots",
    "text": "3.9 Plots\nPlots can be made in {ggplot2}, e.g., scatter plots of the association between personality subscales and implicit racial bias.\nAs before, read the comments and code below to see if you can understand the general flow of what is being done, even without knowing these functions yet.\n\n\nCode\n# dependencies\nlibrary(ggplot2)\n\n# plot\nggplot(dat_processed_long, aes(score, race_iat)) +\n  geom_point(alpha = 0.7) +\n  facet_wrap(~ subscale) +\n  theme_linedraw() +\n  ylab(\"Implicit racial bias\") +\n  xlab(\"Personality subscale score\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#analyses",
    "href": "chapters/reproducible_reports.html#analyses",
    "title": "3  Reproducible reports",
    "section": "3.10 Analyses",
    "text": "3.10 Analyses\nAnalyses can be run, and even their results extracted an interpreted, with the help of R packages such as {report} and {parameters} from the easystats cluster of packages.\n\n\nCode\n# dependencies\nlibrary(report)\n\n# fit correlation test\nres &lt;- cor.test(formula = ~ race_iat + extroversion, \n                data = dat_processed, \n                use = \"pairwise.complete.obs\")\n\n# create standard report of results\nreport::report_text(res)\n\n\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Pearson's product-moment correlation between race_iat and extroversion is\nnegative, statistically not significant, and small (r = -0.18, 95% CI [-0.39,\n0.05], t(73) = -1.52, p = 0.132)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#exercises",
    "href": "chapters/reproducible_reports.html#exercises",
    "title": "3  Reproducible reports",
    "section": "3.11 Exercises",
    "text": "3.11 Exercises\nEdit your local copy of this .qmd file to make the following changes.\n\n3.11.1 Insert a new chunk and write code to install the following packages\nUse the install.packages() function to install the packages {tidyverse}, {janitor}, {knitr}, {kableExtra}, and {report}. Remember to exclude the “{}” and use quotation marks around the package names. Run the code to install these packages.\n\n\n3.11.2 Inserting a new chunk below this heading\nEither type it yourself using backticks or use the keyboard shortcut: Ctrl + Alt + I (Windows) or Cmd + Alt + I (Mac). Enter some code inside the chunk, e.g., “10 - 5”. Run the code in the chunk by clicking the green right-arrow: \n\n\n3.11.3 Add authorship\nAdd the following text to the YAML header on line 3, just under ‘title’: author: \"yourname\", and replace ‘yourname’ with your name. Click ‘render’ to create a reproducible report as a .html from this .qmd file. It will now list you as the author.\n\n\n3.11.4 Add date\nAdd the following text to the YAML header on line 4: date: today. Now when you render again, it will list today’s date so that you know when the report was created.\n\n\n3.11.5 Make the plot more colorful\nChange the ‘aesthetics’ call from aes(score, race_iat) to aes(score, race_iat, color = subscale). Run all previous chunks to reload and reprocess the data using this button:  Then, run the plot chunk again using this one to view your more colorful plot:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html",
    "href": "chapters/loading_data.html",
    "title": "5  Loading, viewing, and saving data",
    "section": "",
    "text": "5.1 Using .csv files rather than Excel .xlsx files\nWhile Microsoft Excel’s .xlsx files provide many features, in the context of reproducible data processing and analysis they often introduce more risks than benefits.\nExcel allows the user to write formula to process and analyze data. However, Excel formula are less reproducible than R code as they are not always visible to the user and it is easy to make copy paste and cell location errors.\nThis isn’t merely speculation:",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Loading, viewing, and saving data</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#using-.csv-files-rather-than-excel-.xlsx-files",
    "href": "chapters/loading_data.html#using-.csv-files-rather-than-excel-.xlsx-files",
    "title": "5  Loading, viewing, and saving data",
    "section": "",
    "text": "5.1.1 Case study 1: Reinhard & Rogoff (2010)\nIn the immediate aftermath of the 2008 Financial Crisis, an article by then-Harvard Professor and previously Chief Economist of the International Monetary Fund, Kenneth Rogoff, was heavily referenced by economists as part of the rationale to dramatically cut state spending (Reinhart & Rogoff (2010)). Countries including my own, Ireland, the U.K. and others adopted radical austerity policies and slashed funding to education and healthcare, from which we have not yet fully recovered from. Thomas Herndon, then a first year PhD student, found serious errors in Reinhart and Rogoff’s Excel formula (Herndon et al. (2014)). When corrected, the results indicated that austerity policies were harmful rather than helpful. Global economic history was changed by this data processing error.\n\nFor coverage of this fascinating and horrifying story:\n\nWikipedia page\nCommentary by Paul Krugman, Nobel Laureat, in the New York Times\nThe Guardian\nThe London Economic Review)\n\n\n\n5.1.2 Case study 2: Excel corrupts the genomics literature\nExcel’s automatic data conversion ‘feature’ turns certain text strings that also happen to refer to identifiers for genes (e.g., SEPT2, MARCH1) into dates or numbers. When genetics data is opened in Excel, automatically converted, and then saved, these silent changes propagated into data analyses. Ziemann et al. (2016) estimated that ~20% of papers with Excel gene lists contained such errors, demonstrating field-wide contamination of results and reproducibility risks (see coverage in Science News). Subsequent audits showed the problem persisted years later, despite awareness of the problem and guidance on how to prevent it, underscoring how Excel can corrupt bioinformatics workflows (see Abeysooriya et al., 2021).\n\n\n5.1.3 Other reasons to avoid Excel\nOther less extreme but nonetheless good reasons not to use Excel and .xlsx files also exist. Use colors (in cells or text) to carry information (e.g., “cells in red represent the outcome variables”), which can’t be easily read into R. Generally, colorful .xlsx files are a statistician’s nightmare.\nSo, we’ll use .csv files and avoid manually altering data outside of reproducible R workflows.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Loading, viewing, and saving data</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#loading-.csv-files",
    "href": "chapters/loading_data.html#loading-.csv-files",
    "title": "5  Loading, viewing, and saving data",
    "section": "5.2 Loading .csv files",
    "text": "5.2 Loading .csv files\n\n5.2.1 read.csv() and readr::read_csv()\nBase R’s read.csv() has a slightly better version in the {readr} package, readr::read_csv(), which is more explicit about how it parses column types. This can become useful in more complex data sets. I recommend you use read_csv() and will use it throughout this book.\n\n\n5.2.2 Relative vs. absolute paths: Avoid using setwd()!\nWhere to load data from?\nWhen we write .R scripts, we often use setwd() to define where files should be loaded from and saved to. The problem with setwd() is that it hard-codes file paths that are usually specific to the computer and user. For example, if I write an .R script that includes setwd(\"C:/Users/IanHussey/Documents/R_course/\"), before loading some data using read_csv(). If I email you this script and data file, it script won’t work on your machine unless your folders are identically named; you have to change the file path in setwd(). This lowers the reproducibility of the code, as it can’t be run trivially by other people on other computers.\nThis is because setwd() uses ‘absolute’ paths that point to a specific location in a directory structure. One of the very useful features of RMarkdown (.Rmd) and Quarto (.qmd) files is that they instead use ‘relative’ paths, which specify where a file or directory is in relation to the .Rmd or .qmd script. That is, the working directory is by definition wherever the .Rmd or .qmd file is, without being specified.\nIf I have a directory - located anywhere on my hard drive - called ‘R_course’ that contains the folders ‘code’ and ‘data’, and the ‘data’ directory itself contains the directories ‘processed’ and ‘raw’. Imagine the files within these directories are as follows:\nR_course/\n├── code/\n│   ├── analysis.qmd\n│   ├── data_shouldnt_usually_go_here.csv\n│   └── processing.qmd\n└── data/\n    ├── processed/\n    │   └── data_likert.csv\n    └── raw/\n        ├── data_demographics_raw.csv\n        ├── data_selfreports_raw.csv\n        ├── code_shouldnt_usually_go_here.qmd\n        └── data_behavioraltask_raw.csv\nBecause .qmd files use ‘relative’ paths, to load the ‘data_shouldnt_usually_go_here.csv’ file I only need to do the following, without any setwd() call:\n\n\nCode\ndat &lt;- read_csv(\"data_shouldnt_usually_go_here.csv\")\n\n\nOf course, code and data should be clearly separated within a project so ‘data_shouldnt_usually_go_here.csv’ should not usually go in that directory, as the name suggests.\nIf I instead wanted to load ‘data_likert.csv’, I would do this as follows. This data file actually exists in this project, so the code will run assuming you have the data files in the correct location relative to this .qmd script.\n\n\nCode\nlibrary(readr)\n\ndat_likert &lt;- read_csv(\"../data/raw/data_likert.csv\")\n\n\nThis is parsed as follows: ../ tells RStudio to go ‘up’ one directory level from ‘analysis.qmd’ to the ‘R_course’ folder that contains it. data/ then tells it to go ‘down’ one level into the ‘data’ folder inside ‘R_course’. Likewise, processed/ then tells it to go ‘down’ another level into the ‘processed’ folder, before loading the ‘data_likert.csv’ file.\nNote that ../ can be stacked to go ‘up’ multiple directory levels, e.g., ../../.\nAs long as you send move the entire ‘R_course’ folder and preserve the relative location between the code and the data, the .qmd file’s read_csv() call will still work. It doesn’t matter whether you the ‘R_course’ directory to somewhere else on your hard drive, or create a .zip file and email it to someone else, or distribute it via GitHub, or whether they’re using Windows or Mac.\nAlso note that because the directory ‘R_course’ is never specified in the read_csv() call, it can be called anything else and still work. The same goes for the name of the script which calls read_csv() - in this case, the script you’re reading is called ‘loading_data.qmd’ and the code still works.\nFYI, you can also use relative paths in regular .R files using the {here} library.\n\n\n5.2.3 Understanding directory structures with list.files(), list.dirs(), file.exists() and dir.exists()\nWhen trying to write relative paths to load or save data, it often takes me a few attempts to get it right. I go back and forth looking at the files and directories themselves in File Explorer (Widows) or Finder (Mac) and adjusting the R code.\nYou can also explore directory and file structures directly in R to make this easier using list.files() to list files and list.dirs() to list directories.\nList the files in the same folder as this .qmd file:\n\n\nCode\nlist.files() \n\n\n [1] \"data_transformation.qmd\"   \"fundamentals.qmd\"         \n [3] \"joins.qmd\"                 \"license.qmd\"              \n [5] \"loading_data_files\"        \"loading_data.qmd\"         \n [7] \"loading_data.rmarkdown\"    \"plots\"                    \n [9] \"reporting.qmd\"             \"reproducible_reports.qmd\" \n[11] \"reshaping_and_pivots.qmd\"  \"setup.qmd\"                \n[13] \"structuring_projects.html\" \"structuring_projects.qmd\" \n[15] \"the_linear_model.qmd\"      \"the_pipe_and_renaming.qmd\"\n[17] \"visualization.qmd\"        \n\n\nGo ‘up’ one directory and list the directories present:\n\n\nCode\nlist.dirs(path = \"../\", # 'up' one directory level\n          full.names = FALSE, # abbreviated dir names\n          recursive = FALSE) # only the directories, not their contents\n\n\n[1] \"_book\"       \".git\"        \".quarto\"     \".Rproj.user\" \"chapters\"   \n[6] \"data\"        \"images\"      \"resources\"   \"site_libs\"  \n\n\nFrom the above we can see that the ‘data’ folder is up one directory level from the current .qmd file. Let’s confirm this with dir.exists() to check the directory does indeed exist:\n\n\nCode\ndir.exists(\"../data\")\n\n\n[1] TRUE\n\n\nOk, we’re getting close. So what’s in the ‘../data’ directory?\n\n\nCode\nlist.dirs(path = \"../data\", # 'up' one directory level, then 'down' into 'data'\n          full.names = FALSE, # abbreviated dir names\n          recursive = FALSE) # only the directories, not their contents\n\n\n[1] \"processed\" \"raw\"      \n\n\nIt contains the folders ‘processed’ and ‘raw’. What’s in the ‘raw’ directory?\n\n\nCode\nlist.files(\"../data/raw\") \n\n\n [1] \"data_age_gender_subset.csv\"         \"data_amp_raw.csv\"                  \n [3] \"data_amp_summary_subset.csv\"        \"data_demographics_raw_messy.csv\"   \n [5] \"data_demographics_raw.csv\"          \"data_likert_messy.csv\"             \n [7] \"data_likert.csv\"                    \"data_likert.rds\"                   \n [9] \"data_likert.xlsx\"                   \"data_raw_bfi.csv\"                  \n[11] \"data_selfreport_raw.csv\"            \"data_selfreport_summary_subset.csv\"\n[13] \"data_unique_id_subset.csv\"         \n\n\nIf we were looking to find and load the ‘data_likert.csv’ file, we know its directory path and that it exists. As already used above:\n\n\nCode\ndat_likert &lt;- read_csv(\"../data/raw/data_likert.csv\")\n\n\n\n\n5.2.4 Creating new directories with dir.create()\nSometimes, you might want to save files to a directory does not yet exist.\nOn the one hand, you could just open File Explorer (Windows) or Finder (Mac) and create a new directory manually (e.g., File&gt;New folder).\nHowever, we want our R code to be highly reproducible. Requiring manual steps like the above often breaks the code on other people’s machines.\nInstead, you can create folders directly from R using dir.create(). For example, if your analysis script is located at R_course/code/analysis.qmd, and you want to save plots that you create to a ‘plots’ directory within ‘code’, you can include this line in your ‘analysis.qmd’ file:\n\n\nCode\ndir.create(\"plots\")\n\n\n\n\n5.2.5 Other file and directory functions\nYou can also rename, copy, delete, and move files and directories with functions such as file.rename(), file.copy(), file.remove(), file.move(). Use the help menu to discover and understand these and other functions.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Loading, viewing, and saving data</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#viewing-data-frames",
    "href": "chapters/loading_data.html#viewing-data-frames",
    "title": "5  Loading, viewing, and saving data",
    "section": "5.3 Viewing data frames",
    "text": "5.3 Viewing data frames\n\n5.3.1 In your environment\nData frames (and other objects) that have already been loaded into your R environment will appear under the ‘files’ tab in RStudio.\nYou can view them by clicking on them in the ‘Environment’ tab in RStudio, running View(object) (where ‘object’ is your object’s name, e.g. View(dat_likert)), or clicking the object’s name in the Source window where code appears with Cmd+click (on Mac) or Ctrl+click (on Windows).\n\n\n5.3.2 Printing data frames below chunks\nTo print a data frame below the code chunk, you can;\nRun the object name:\n\n\nCode\ndat_likert\n\n\n# A tibble: 20 × 7\n    ...1  ...2 date       group subject likert_1 likert_2\n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1     1     1 23.06.2022     1       1        1        4\n 2     2     2 23.06.2022     2       2        3        3\n 3     3     3 23.06.2022     2       3        2        1\n 4     4     4 23.06.2022     1       4        5        5\n 5     5     5 23.06.2022     1       5        3        3\n 6     6     6 23.06.2022     2       6        2        1\n 7     7     7 23.06.2022     1       7        2        1\n 8     8     8 23.06.2022     1       8        1        3\n 9     9     9 23.06.2022     1       9        2        5\n10    10    10 23.06.2022     2      10        5        2\n11    11    11 23.06.2022     1      11        1       NA\n12    12    12 23.06.2022     2      12        3       NA\n13    13    13 23.06.2022     2      13        2       NA\n14    14    14 23.06.2022     1      14        5       NA\n15    15    15 23.06.2022     1      15        3       NA\n16    16    16 23.06.2022     2      16        2       NA\n17    17    17 23.06.2022     1      17        2       NA\n18    18    18 23.06.2022     1      18        1       NA\n19    19    19 23.06.2022     1      19        2       NA\n20    20    20 23.06.2022     2      20        5       NA\n\n\nUse print():\n\n\nCode\nprint(dat_likert)\n\n\n# A tibble: 20 × 7\n    ...1  ...2 date       group subject likert_1 likert_2\n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1     1     1 23.06.2022     1       1        1        4\n 2     2     2 23.06.2022     2       2        3        3\n 3     3     3 23.06.2022     2       3        2        1\n 4     4     4 23.06.2022     1       4        5        5\n 5     5     5 23.06.2022     1       5        3        3\n 6     6     6 23.06.2022     2       6        2        1\n 7     7     7 23.06.2022     1       7        2        1\n 8     8     8 23.06.2022     1       8        1        3\n 9     9     9 23.06.2022     1       9        2        5\n10    10    10 23.06.2022     2      10        5        2\n11    11    11 23.06.2022     1      11        1       NA\n12    12    12 23.06.2022     2      12        3       NA\n13    13    13 23.06.2022     2      13        2       NA\n14    14    14 23.06.2022     1      14        5       NA\n15    15    15 23.06.2022     1      15        3       NA\n16    16    16 23.06.2022     2      16        2       NA\n17    17    17 23.06.2022     1      17        2       NA\n18    18    18 23.06.2022     1      18        1       NA\n19    19    19 23.06.2022     1      19        2       NA\n20    20    20 23.06.2022     2      20        5       NA\n\n\n\n\n5.3.3 Printing nicer tables\nPrinting data frames by calling their name or using print() don’t produce very attractive tables. You can improve this using a combination of the {knitr} and {kableExtra} packages.\nNote that this code uses the ‘pipe’ (%&gt;%), which we cover in more detail in a later chapter. You don’t need to understand how it works yet, just the output that it creates.\n\n\nCode\nlibrary(knitr)\nlibrary(kableExtra)\n\ndat_likert %&gt;%\n  knitr::kable(align = \"r\") %&gt;%\n  kableExtra::kable_styling(full_width = FALSE)\n\n\n\n\n\n...1\n...2\ndate\ngroup\nsubject\nlikert_1\nlikert_2\n\n\n\n\n1\n1\n23.06.2022\n1\n1\n1\n4\n\n\n2\n2\n23.06.2022\n2\n2\n3\n3\n\n\n3\n3\n23.06.2022\n2\n3\n2\n1\n\n\n4\n4\n23.06.2022\n1\n4\n5\n5\n\n\n5\n5\n23.06.2022\n1\n5\n3\n3\n\n\n6\n6\n23.06.2022\n2\n6\n2\n1\n\n\n7\n7\n23.06.2022\n1\n7\n2\n1\n\n\n8\n8\n23.06.2022\n1\n8\n1\n3\n\n\n9\n9\n23.06.2022\n1\n9\n2\n5\n\n\n10\n10\n23.06.2022\n2\n10\n5\n2\n\n\n11\n11\n23.06.2022\n1\n11\n1\nNA\n\n\n12\n12\n23.06.2022\n2\n12\n3\nNA\n\n\n13\n13\n23.06.2022\n2\n13\n2\nNA\n\n\n14\n14\n23.06.2022\n1\n14\n5\nNA\n\n\n15\n15\n23.06.2022\n1\n15\n3\nNA\n\n\n16\n16\n23.06.2022\n2\n16\n2\nNA\n\n\n17\n17\n23.06.2022\n1\n17\n2\nNA\n\n\n18\n18\n23.06.2022\n1\n18\n1\nNA\n\n\n19\n19\n23.06.2022\n1\n19\n2\nNA\n\n\n20\n20\n23.06.2022\n2\n20\n5\nNA",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Loading, viewing, and saving data</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#saving-.csv-files",
    "href": "chapters/loading_data.html#saving-.csv-files",
    "title": "5  Loading, viewing, and saving data",
    "section": "5.4 Saving .csv files",
    "text": "5.4 Saving .csv files\nWriting .csv files to disk is as easy as loading them.\n\n\nCode\nwrite.csv(x = dat_likert, # the data frame to save\n          file = \"../data/raw/data_likert.csv\") # the file to save it to",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Loading, viewing, and saving data</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#loading-.xlsx-files",
    "href": "chapters/loading_data.html#loading-.xlsx-files",
    "title": "5  Loading, viewing, and saving data",
    "section": "5.5 Loading .xlsx files",
    "text": "5.5 Loading .xlsx files\nWhile .csv files are a good default file format to use for most projects, Excel, SPSS, and other file formats can also be loaded.\nThere are several packages available to load Excel files in particular. Any of them are fine except library(xlsx) which requires you to install rJava, which often causes compatibility issues. library(readxl) is a safer bet. Because excel files can contain multiple sheets, the source can be specified with the sheet argument.\n\n\nCode\nlibrary(readxl)\n\ndat_likert_1 &lt;- readxl::read_excel(path = \"../data/raw/data_likert.xlsx\", \n                                   sheet = \"data1\")\n\n\n\n5.5.1 Skipping rows when loading\nSometimes extra rows etc. make a data file harder to read into R. For example, the column names in ‘data_likert.xlsx’ are on the fourth row, causing a mess when you load the file.\nYou can view column names, types and the first few rows of data with head():\n\n\nCode\nhead(dat_likert_1)\n\n\n# A tibble: 6 × 5\n  `Date created: 02/04/2024` ...2  ...3    ...4     ...5    \n  &lt;chr&gt;                      &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;   \n1 subset: sample 1           &lt;NA&gt;  &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;    \n2 &lt;NA&gt;                       &lt;NA&gt;  &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;    \n3 date                       group subject likert_1 likert_2\n4 44735                      1     1       1        4       \n5 44735                      2     2       3        3       \n6 44735                      2     3       2        1       \n\n\nWith a few exceptions (e.g., removing identifying information before making data public), you should not manually modify raw data.\nIt might be tempting to open the .csv file in excel and manually delete those rows - don’t!\nHandle with with code, not by deleting the information in those rows. When using read_csv() or readxl::read_excel() this can be done using the skip argument.\n\n\nCode\ndat_likert_1 &lt;- readxl::read_excel(path = \"../data/raw/data_likert.xlsx\", \n                                   sheet = \"data1\", \n                                   skip = 3)\n\ndat_likert_1\n\n\n# A tibble: 5 × 5\n  date                group subject likert_1 likert_2\n  &lt;dttm&gt;              &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 2022-06-23 00:00:00     1       1        1        4\n2 2022-06-23 00:00:00     2       2        3        3\n3 2022-06-23 00:00:00     2       3        2        1\n4 2022-06-23 00:00:00     1       4        5        5\n5 2022-06-23 00:00:00     1       5        3        3",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Loading, viewing, and saving data</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#combining-multiple-data-sets",
    "href": "chapters/loading_data.html#combining-multiple-data-sets",
    "title": "5  Loading, viewing, and saving data",
    "section": "5.6 Combining multiple data sets",
    "text": "5.6 Combining multiple data sets\nYou can combine multiple data sets with (nearly) the same structure using dplyr::bind_rows(). In this case, ‘data_likert.xlsx’ have mostly the same columns, with sheet 1 also having the ‘likert_2’ column. Missing columns are filled with NA when using dplyr::bind_rows(). This has its advantages over base R’s rbind() which requires that column names must match between the objects.\n\n\nCode\nlibrary(dplyr)\n\ndat_likert_1 &lt;- readxl::read_excel(\"../data/raw/data_likert.xlsx\", sheet = \"data1\", skip = 3)\ndat_likert_2 &lt;- readxl::read_excel(\"../data/raw/data_likert.xlsx\", sheet = \"data2\", skip = 3)\n\ndat_likert &lt;- dplyr::bind_rows(dat_likert_1,\n                               dat_likert_2)\n\ndat_likert\n\n\n# A tibble: 10 × 5\n   date                group subject likert_1 likert_2\n   &lt;dttm&gt;              &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 2022-06-23 00:00:00     1       1        1        4\n 2 2022-06-23 00:00:00     2       2        3        3\n 3 2022-06-23 00:00:00     2       3        2        1\n 4 2022-06-23 00:00:00     1       4        5        5\n 5 2022-06-23 00:00:00     1       5        3        3\n 6 2022-06-23 00:00:00     1       6        1       NA\n 7 2022-06-23 00:00:00     2       7        3       NA\n 8 2022-06-23 00:00:00     2       8        2       NA\n 9 2022-06-23 00:00:00     1       9        5       NA\n10 2022-06-23 00:00:00     1      10        3       NA",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Loading, viewing, and saving data</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#loading-and-writing-.rda-files",
    "href": "chapters/loading_data.html#loading-and-writing-.rda-files",
    "title": "5  Loading, viewing, and saving data",
    "section": "5.7 Loading and writing .rda files",
    "text": "5.7 Loading and writing .rda files\nR objects can also be saved and loaded as .rda files. This can be very useful if you want to a) compress the data to make it smaller (using the compress = \"gz\" argument) or b) to preserve things like column types and factor levels. However, it does slightly reduce the interoperability of the data as not everyone else uses R.\n\n\nCode\nlibrary(readr)\n\n# write\nreadr::write_rds(x = dat_likert, \n                 file = \"../data/raw/data_likert.rds\",\n                 compress = \"gz\")\n\n# read\ndat_likert &lt;- readr::read_rds(file = \"../data/raw/data_likert.rds\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Loading, viewing, and saving data</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#loading-multiple-data-files-at-once",
    "href": "chapters/loading_data.html#loading-multiple-data-files-at-once",
    "title": "5  Loading, viewing, and saving data",
    "section": "5.8 Loading multiple data files at once",
    "text": "5.8 Loading multiple data files at once\nSome psychology software such as PsychoPy often saves each participant’s data as a separate .csv file. FYI you can write code to find all files of a given type (e.g., .csv) in a folder, read them all in, and bind all the data together as a single data frame. Note that this code uses some functions from the {purrr} package not explained here. It’s included here so that you know that it can be done quite easily.\n\n\nCode\nlibrary(purrr)\n\n# list all the files in a directory\nfile_names &lt;- list.files(path = \"../data/raw/individual_files\", \n                         pattern = \"\\\\.csv$\", \n                         full.names = TRUE)\n\n# use (or 'map') the read_csv function onto each of the file names \ndata_combined &lt;- purrr::map_dfr(.x = file_names, .f = read_csv)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Loading, viewing, and saving data</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#exercises",
    "href": "chapters/loading_data.html#exercises",
    "title": "5  Loading, viewing, and saving data",
    "section": "5.9 Exercises",
    "text": "5.9 Exercises\nCheck your learning with the following questions. Exercises involving running code should be run in your local copy of the .qmd files (see the Introduction to get a copy of them).\n\n5.9.1 How can you run all all the code chunks in this file with a single click?\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\nClicking the green down arrow button in the last chunk.\nSee the chapter on Reproducible Reports to refresh your knowledge.\n\n\n\nDo this in order to load all the objects into your environment so that you can complete the next exercise.\n\n\n5.9.2 What are three ways to view the contents of an object?\nDo all three ways for the dat_likert object.\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\nClicking the object’s name the ‘Environment’ tab in RStudio\nRunning View(object) (where ‘object’ is your object’s name)\nClicking the object’s name in the Source window (where code appears) with Cmd+click (on Mac) or Ctrl+click (on Windows)\n\n\n\n\n\n\n5.9.3 How would you know what arguments readxl::read_excel() takes?\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\nBy consulting the help menu with /Users/Ian-Hussey/Library/R/arm64/4.5/library/readxl/help/read_excel.\nSee the chapter on Fundamentals to refresh your knowledge.\n\n\n\n\n\n5.9.4 How to use relative paths to load files?\nUsing the file structure diagram under the Relative vs. absolute paths section above, what R code is needed to load the ‘data_shouldnt_usually_go_here.csv’ file from the ‘code_shouldnt_usually_go_here.qmd’?\n\n\n\n\n\n\nClick to show hint\n\n\n\n\n\nYou need to understand relative paths and use “../” to go ‘up’ directories.\n\n\n\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\ndat &lt;- read_csv(\"../../code/data_shouldnt_usually_go_here.csv\")\n\n\n\n\n\n\n\n5.9.5 Load and print nicely formatted table\nFollowing the same file structure as above, there is a file called “data_likert.csv” in the ‘raw’ data directory.\nWrite R code to:\n\nLoad that data file from this .qmd file, which is located in the ‘code’ directory.\nAssign it to an object called data_exercise.\nLoad the {kable} and {kableExtra} libraries.\nPrint data_exercise as nicely formatted table.\n\n\n\n\n\n\n\nClick to show hint\n\n\n\n\n\nSee the chapter on Fundamentals to refresh your knowledge on loading dependencies/libraries and object assignment.\nAdapt the code used in this chapter for the other steps.\n\n\n\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\ndata_exercise &lt;- read_csv(\"../data/raw/data_likert.csv\")\n\nlibrary(knitr)\nlibrary(kableExtra)\n\ndata_exercise %&gt;%\n  kable(align = \"r\") %&gt;%\n  kable_styling(full_width = FALSE)\n\n\n\n\n\n...1\n...2\n...3\ndate\ngroup\nsubject\nlikert_1\nlikert_2\n\n\n\n\n1\n1\n1\n23.06.2022\n1\n1\n1\n4\n\n\n2\n2\n2\n23.06.2022\n2\n2\n3\n3\n\n\n3\n3\n3\n23.06.2022\n2\n3\n2\n1\n\n\n4\n4\n4\n23.06.2022\n1\n4\n5\n5\n\n\n5\n5\n5\n23.06.2022\n1\n5\n3\n3\n\n\n6\n6\n6\n23.06.2022\n2\n6\n2\n1\n\n\n7\n7\n7\n23.06.2022\n1\n7\n2\n1\n\n\n8\n8\n8\n23.06.2022\n1\n8\n1\n3\n\n\n9\n9\n9\n23.06.2022\n1\n9\n2\n5\n\n\n10\n10\n10\n23.06.2022\n2\n10\n5\n2\n\n\n11\n11\n11\n23.06.2022\n1\n11\n1\nNA\n\n\n12\n12\n12\n23.06.2022\n2\n12\n3\nNA\n\n\n13\n13\n13\n23.06.2022\n2\n13\n2\nNA\n\n\n14\n14\n14\n23.06.2022\n1\n14\n5\nNA\n\n\n15\n15\n15\n23.06.2022\n1\n15\n3\nNA\n\n\n16\n16\n16\n23.06.2022\n2\n16\n2\nNA\n\n\n17\n17\n17\n23.06.2022\n1\n17\n2\nNA\n\n\n18\n18\n18\n23.06.2022\n1\n18\n1\nNA\n\n\n19\n19\n19\n23.06.2022\n1\n19\n2\nNA\n\n\n20\n20\n20\n23.06.2022\n2\n20\n5\nNA\n\n\n\n\n\n\n\n\n\n\n5.9.6 Check whether ‘data_likert.rds’ exists\nEarlier steps in this lesson saved a file called ‘data_likert.rds’ to the same directory as ‘data_csv.csv’.\nUse the functions list.dirs(), list.files(), and file.exists() to navigate the file structure, listing directories along the way, to write the file.exists() call that confirm that the file exists. It should return TRUE.\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\n\nCode\nlist.dirs(path = \"../\", # 'up' one directory level\n          full.names = FALSE, # abbreviated dir names\n          recursive = FALSE) # only the directories, not their contents\n\n\n[1] \"_book\"       \".git\"        \".quarto\"     \".Rproj.user\" \"chapters\"   \n[6] \"data\"        \"images\"      \"resources\"   \"site_libs\"  \n\n\nCode\nlist.dirs(path = \"../data\", # 'up' one directory level, down one into 'data'\n          full.names = FALSE, # abbreviated dir names\n          recursive = FALSE) # only the directories, not their contents\n\n\n[1] \"processed\" \"raw\"      \n\n\nCode\nlist.files(path = \"../data/raw\", # 'up' one directory level, down one into 'data', down another into 'raw'\n           full.names = FALSE, # abbreviated dir names\n           pattern = \"\\\\.rds$\", # only return files ending in \".rds\"\n           recursive = FALSE) # only the directories, not their contents\n\n\n[1] \"data_likert.rds\"\n\n\nCode\nfile.exists(\"../data/raw/data_likert.rds\")\n\n\n[1] TRUE",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Loading, viewing, and saving data</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html",
    "href": "chapters/the_pipe_and_renaming.html",
    "title": "6  The pipe and renaming",
    "section": "",
    "text": "6.1 Exploring column names and rows\nAs in the last chapter, we load data using relative paths and read_csv() and view the first few rows with head().\nCode\nlibrary(readr) # for read_csv()\nlibrary(dplyr) # for %&gt;%\nlibrary(knitr) # for kable()\nlibrary(kableExtra) # for kable_extra()\n\ndat_demographics_raw &lt;- read_csv(file = \"../data/raw/data_demographics_raw_messy.csv\") \n\nhead(dat_demographics_raw) %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nsubject and session info columns\n...2\ntask structure columns\n...4\nresponse columns\n...6\n...7\n...8\n\n\n\n\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ndate\nSubject Code\nbuild\nblock code and trial number\nTrial Code\nKey response (use this!)\ncorrect\n0 ms onset RT\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\nUnfortunately, the ‘data_demographics_raw_messy.csv’ data set is, as its name suggests, somewhat messy. The column names are on the third row, not the first one.\nHow should you alter the above code to ignore the first two lines when reading the data in to R?",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The pipe and renaming</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html#exploring-data",
    "href": "chapters/the_pipe_and_renaming.html#exploring-data",
    "title": "5  The pipe and renaming",
    "section": "",
    "text": "Click to show answer\n\n\n\n\n\n\n\nCode\ndat_demographics_raw &lt;- read_csv(file = \"../data/raw/data_demographics_raw_messy.csv\", \n                                 skip = 2) # add skip = 2 to ignore the first two lines\n\nhead(dat_demographics_raw) %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nSubject Code\nbuild\nblock code and trial number\nTrial Code\nKey response (use this!)\ncorrect\n0 ms onset RT\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n\n\n\n\n\n\n\n5.1.1 Count rows and columns with nrow() and ncol()\nProcessing and cleaning any data set requires an understanding what it contains - as well as a thorough understanding of how the data was generated (e.g., the study’s design and specific implementation; what rows represent what measurement and in what way, etc.).\nA rudimentary but important step to understanding what a data set contains is to know how many rows and columns it contains.\nThis is useful to check at multiple steps of your data processing to make sure you have not done something wrong by gaining or losing columns or rows that you should not.\nNumber of rows:\n\n\nCode\nnrow(dat_demographics_raw)\n\n\n[1] 16\n\n\nNumber of columns:\n\n\nCode\nncol(dat_demographics_raw)\n\n\n[1] 8\n\n\n\n\n5.1.2 Viewing column names, types and the first few rows of data with head()\n\n\nCode\nhead(dat_demographics_raw) \n\n\n# A tibble: 6 × 8\n  date       `Subject Code` build      block code and trial numbe…¹ `Trial Code`\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;                        &lt;chr&gt;       \n1 23.06.2022      548957868 06.06.2000 demographics_2               age         \n2 23.06.2022      548957868 06.06.2000 demographics_3               gender      \n3 23.06.2022      548957868 06.06.2000 demographics_2               psychiatric…\n4 23.06.2022      548957868 06.06.2000 demographics_3               prolific ID \n5 23.06.2022      504546409 06.06.2000 demographics_2               age         \n6 23.06.2022      504546409 06.06.2000 demographics_3               gender      \n# ℹ abbreviated name: ¹​`block code and trial number`\n# ℹ 3 more variables: `Key response (use this!)` &lt;chr&gt;, correct &lt;dbl&gt;,\n#   `0 ms onset RT` &lt;dbl&gt;\n\n\n\n\n5.1.3 Viewing column names with colnames()\nHow would you know what variables are in a data frame? You can view the data frame, but it can also be useful to print them. Knowing what you have is one of the first steps to working with it.\n\n\nCode\ncolnames(dat_demographics_raw)\n\n\n[1] \"date\"                        \"Subject Code\"               \n[3] \"build\"                       \"block code and trial number\"\n[5] \"Trial Code\"                  \"Key response (use this!)\"   \n[7] \"correct\"                     \"0 ms onset RT\"              \n\n\nLater, when you’re used to using functions such as rename() and mutate(), you will often want a vector of column names that you can easily copy-paste into code, without all the extra white-space and including commas between them. For this, you can use dput():\n\n\nCode\ndput(colnames(dat_demographics_raw))\n\n\nc(\"date\", \"Subject Code\", \"build\", \"block code and trial number\", \n\"Trial Code\", \"Key response (use this!)\", \"correct\", \"0 ms onset RT\"\n)\n\n\nThis takes the output of colnames() and applies dput() to it. When your data processing calls muliple functions in a row, this could get complicated to read and write. It’s therefore time to introduce ‘the pipe’.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The pipe and renaming</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html#the-pipe",
    "href": "chapters/the_pipe_and_renaming.html#the-pipe",
    "title": "6  The pipe and renaming",
    "section": "6.2 The pipe",
    "text": "6.2 The pipe\n\n6.2.1 What is the pipe?\nThe output of the function to the left of the pipe is used as the input to the function to the right of the pipe.\n[this function's output...] %&gt;%\n  [...becomes this function's input]\nFor example, the following code does the same thing with and without the pipe:\n\n\nCode\n# print all column names as a vector - without the pipe\ndput(colnames(dat_demographics_raw))\n\n\nc(\"date\", \"Subject Code\", \"build\", \"block code and trial number\", \n\"Trial Code\", \"Key response (use this!)\", \"correct\", \"0 ms onset RT\"\n)\n\n\nCode\n# print all column names as a vector - using the pipe\ndat_demographics_raw %&gt;%\n  colnames() %&gt;% \n  dput() \n\n\nc(\"date\", \"Subject Code\", \"build\", \"block code and trial number\", \n\"Trial Code\", \"Key response (use this!)\", \"correct\", \"0 ms onset RT\"\n)\n\n\n\n\n6.2.2 Why use the pipe?\nThe pipe allows us to write code that reads from top to bottom, following a series of steps, in the same way that humans would describe and conduct the steps. Without the pipe, code is written from the inside out in the way that R understands it but humans do not as easily.\nThe utility of the pipe becomes more obvious when there are many steps in the workflow.\nThe following example uses functions we have not learned yet. We’ll cover them in later chapters. For the moment, the point is to demonstrate the usage of the pipe.\nWithout the pipe:\n\n\nCode\nlibrary(dplyr) # for the pipe, rename, mutate, select, group_by, summarize\nlibrary(janitor) # for round_half_up\n\ndat &lt;- \n  mutate(\n    summarise(\n      group_by(\n        mutate(\n          rename(\n            readr::read_csv(file = \"../data/raw/data_amp_raw.csv\"),\n            unique_id = subject,\n            block = blockcode,\n            trial_type = trialcode,\n            rt = latency\n          ),\n          fast_trial = ifelse(rt &lt; 100, 1, 0)\n        ),\n        unique_id\n      ),\n      percent_fast_trials = mean(fast_trial) * 100\n    ),\n    percent_fast_trials = round_half_up(percent_fast_trials, digits = 2)\n  )\n\n# print the first few rows\nhead(dat, n = 10) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nunique_id\npercent_fast_trials\n\n\n\n\n4345805\n3.66\n\n\n13708908\n0.00\n\n\n14943693\n0.00\n\n\n32034696\n0.00\n\n\n47022865\n0.00\n\n\n59367911\n0.00\n\n\n72442795\n0.00\n\n\n75092407\n2.44\n\n\n83185292\n0.00\n\n\n85445170\n15.85\n\n\n\n\n\nNotice how the above code has to be written and read from the middle outwards: data is loaded, and what is loaded is used to rename() columns, and what the output is used to mutate() (create) a new column, whose output is used to summarize() across rows for each participant.\nThis becomes much more linear and human-readable when we use the pipe:\n\n\nCode\ndat &lt;- \n  # read data from csv\n  read_csv(file = \"../data/raw/data_amp_raw.csv\") %&gt;% # -&gt; pass the output onward to the next function\n  \n  # rename columns\n  rename(unique_id = subject,\n         block = blockcode,\n         trial_type = trialcode,\n         rt = latency) %&gt;% # -&gt; pass the output onward to the next function\n  \n  # create a new variable from existing ones\n  mutate(fast_trial = ifelse(rt &lt; 100, 1, 0)) %&gt;% # -&gt; pass the output onward to the next function\n  \n  # summarize across rows, clustered by participant\n  group_by(unique_id) %&gt;% # -&gt; pass the output onward to the next function\n  summarise(percent_fast_trials = mean(fast_trial)*100) |&gt;\n  # round the percents to two decimal places\n  mutate(percent_fast_trials = round_half_up(percent_fast_trials, digits = 2))\n\n# print the first few rows\nhead(dat, n = 10) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nunique_id\npercent_fast_trials\n\n\n\n\n4345805\n3.66\n\n\n13708908\n0.00\n\n\n14943693\n0.00\n\n\n32034696\n0.00\n\n\n47022865\n0.00\n\n\n59367911\n0.00\n\n\n72442795\n0.00\n\n\n75092407\n2.44\n\n\n83185292\n0.00\n\n\n85445170\n15.85",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The pipe and renaming</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html#implicit-arguments-the-pipe",
    "href": "chapters/the_pipe_and_renaming.html#implicit-arguments-the-pipe",
    "title": "6  The pipe and renaming",
    "section": "6.3 Implicit arguments & the pipe",
    "text": "6.3 Implicit arguments & the pipe\nAs in other cases in R, arguments can be passed to functions ‘explicitly’ (by naming the argument) or ‘implicitly’ (without names).\nHow the pipe works can be slightly clearer if we use explicit arguments.\nThe pipe passes the output of the preceding function on to the next function as ‘.’:\n\n\nCode\ndat_demographics_raw %&gt;% # output passed forward as '.'\n  head(x = .) %&gt;% # output passed forward as '.'\n  kable(x = .) %&gt;% # -&gt; output passed forward as '.'\n  kable_classic(kable_input = .,\n                full_width = FALSE)\n\n\n\n\n\ndate\nSubject Code\nbuild\nblock code and trial number\nTrial Code\nKey response (use this!)\ncorrect\n0 ms onset RT\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n\n\n\nIf not passed explicitly, the input is passed to the next function’s first argument OR, if the funtion takes the ‘.data’ argument (i.e., most {tidyverse} functions) it is passed to ‘.data’:\n\n\nCode\ndat_demographics_raw %&gt;% # output passed forward to first argument\n  head() %&gt;% # output passed forward to first argument\n  kable() %&gt;% # -&gt; output passed forward to first argument\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nSubject Code\nbuild\nblock code and trial number\nTrial Code\nKey response (use this!)\ncorrect\n0 ms onset RT\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n\n\n\n\n6.3.1 The two pipes: %&gt;% vs. |&gt;\n%&gt;% is the original pipe created for the {magrittr} package and used throughout the tidyverse packages. It is slightly slower but also more flexible because it can pass to the ‘.data’ argument.\n|&gt; is a version of the pipe added more recently to base-R. It is slightly faster but less flexible. This speed only matters if you’re doing this with much larger data sets or very frequently (e.g., in Monte Carlo simulations).\nThe base R pipe (|&gt;) is less intelligent behind the scenes. It always supplies the input as the first argument and can’t handle passing to ‘.data’. If you want to pass its output explicitly, you use ‘_’ instead of ‘.’. However, in my experience, this works imperfectly and not all functions will accept it. Example of explicit passing with the base R pipe |&gt;:\n\n\nCode\ndat_demographics_raw |&gt; # output passed forward as '_'\n  head(x = _) |&gt; # output passed forward as '_'\n  kable(x = _) |&gt; # output passed forward as '_'\n  kable_classic(kable_input = _,\n                full_width = FALSE)\n\n\n\n\n\ndate\nSubject Code\nbuild\nblock code and trial number\nTrial Code\nKey response (use this!)\ncorrect\n0 ms onset RT\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n\n\n\nIf you’re not sure, it’s usually easier to use %&gt;%.\nI try to use %&gt;% throughout this book, but because I use |&gt; more often in my own code I might slip up.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The pipe and renaming</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html#renaming-columns",
    "href": "chapters/the_pipe_and_renaming.html#renaming-columns",
    "title": "6  The pipe and renaming",
    "section": "6.4 Renaming columns",
    "text": "6.4 Renaming columns\n\n6.4.1 Why rename\nColumn names are easiest to work with when they follow four principles: when they’re clear and descriptive, follow a standard convention, are unique, and don’t break R syntax.\n\n6.4.1.1 Use clear and descriptive names\nVariable names should help explain what the variable contains. X3 tells the user a lot less about the variable than extroversion_sum_score.\nThis sounds obvious, but it’s harder than it sounds and it often isn’t done.\n\n\n\n6.4.1.2 Use a naming convention\nVarious naming conventions exist and are used for both objects (e.g., data frames) and functions.\n\nsnake_case: standard in {tidyverse} code, e.g., write_csv()\nlower.dot.case: often used in older functions in base-R, e.g., write.csv()\ncamelCase: often used in Python\n\nOn the one hand, as long as you’re consitent, it doesn’t matter which one you use.\nOn the other hand, snake_case is objectively the best answer and you should use it.\n\n\n6.4.1.3 Use unique names\nIf more than one column has the same name, you’ll have issues trying to work with those columns.\n\n\n6.4.1.4 Avoid characters that break R syntax\nThe following cause problems:\n\nColumn names that begin with a number, e.g., 1_to_7_depression.\nColumn names that contain spaces, e.g., `depression 1 to 7’.\nColumn names that contain characters other than letters and numbers, e.g., depression_1_to_7*.\nColumn names that are ‘reserved names’ in R, e.g., TRUE.\n\nFor example, the ‘dat_demographics_raw’ data frame contains a columns named correct and 0 ms onset RT.\nIf we want to print the rows of correct using base-R we can do this with $:\n\n\nCode\ndat_demographics_raw$correct\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nThis can also be done using the {dplyr} function pull() and the pipe:\n\n\nCode\ndat_demographics_raw %&gt;%\n  pull(correct)\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nThis can’t be done as easily for the column 0 ms onset RT because the number and spaces break the code and will throw an error:\n\n\nCode\n# base-R\ndat_demographics_raw$0 ms onset RT\n\n# dplyr\ndat_demographics_raw %&gt;%\n  pull(0 ms onset RT)\n\n\n\nError: unexpected numeric constant in “dat_demographics_raw$0” Error during wrapup: not that many frames on the stack Error: no more error handlers available (recursive errors?); invoking ‘abort’ restart\n\nYou can make it work by enclosing the column name in backticks (`) or quotes (“):\n\n\nCode\n# base-R\ndat_demographics_raw$\"0 ms onset RT\"\n\n\n [1] 1372  619 1372  619 3946 3724 3946 3724 2576 3050 2576 3050 4311 2793 6887\n[16] 6887\n\n\nCode\n# dplyr\ndat_demographics_raw %&gt;%\n  pull(\"0 ms onset RT\")\n\n\n [1] 1372  619 1372  619 3946 3724 3946 3724 2576 3050 2576 3050 4311 2793 6887\n[16] 6887\n\n\nHowever this becomes cumbersome and annoying. It’s much easier to rename the variable.\n\n\n\n6.4.2 Renaming with rename() & the pipe\nUse dplyr::rename() to change the name of one or more columns. It works like this:\n`df %&gt;% rename(new_name = old_name)`\nLet’s create a data frame called dat_demographics_renamed from dat_demographics_raw, which renames the 0 ms onset RT column to timely rt:\n\n\nCode\n# view old column names \ncolnames(dat_demographics_raw)\n\n\n[1] \"date\"                        \"Subject Code\"               \n[3] \"build\"                       \"block code and trial number\"\n[5] \"Trial Code\"                  \"Key response (use this!)\"   \n[7] \"correct\"                     \"0 ms onset RT\"              \n\n\nCode\ndat_demographics_renamed &lt;- dat_demographics_raw %&gt;%\n  rename(rt = \"0 ms onset RT\")\n\n# view new column names \ncolnames(dat_demographics_renamed)\n\n\n[1] \"date\"                        \"Subject Code\"               \n[3] \"build\"                       \"block code and trial number\"\n[5] \"Trial Code\"                  \"Key response (use this!)\"   \n[7] \"correct\"                     \"rt\"                         \n\n\nIf you want to rename multiple columns at once, you can do this in a single call of the rename() function:\n\n\nCode\ndat_demographics_renamed &lt;- dat_demographics_raw %&gt;%\n  rename(id = \"Subject Code\",\n         block_trial = \"block code and trial number\",\n         question = \"Trial Code\", \n         response = \"Key response (use this!)\",\n         rt = \"0 ms onset RT\")\n\n# view new column names and the first few rows\nhead(dat_demographics_renamed) %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The pipe and renaming</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html#automatically-cleaning-names-with-clean_names",
    "href": "chapters/the_pipe_and_renaming.html#automatically-cleaning-names-with-clean_names",
    "title": "5  The pipe (%>% and |>) and renaming columns",
    "section": "5.5 Automatically cleaning names with clean_names()",
    "text": "5.5 Automatically cleaning names with clean_names()\nTODO why; mention that across() solutions will come in later chapters\n\n\nCode\nlibrary(janitor) # for clean_names()\n\ndat_demographics_raw_clean &lt;- dat_demographics_raw %&gt;%\n  clean_names()\n\ndat_demographics_raw_clean %&gt;%\n  head() %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nsubject_code\nbuild\nblock_code_and_trial_number\ntrial_code\nkey_response_use_this\ncorrect\nx0_ms_onset_rt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The pipe (`%>%` and `|>`) and renaming columns</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html#exercises",
    "href": "chapters/the_pipe_and_renaming.html#exercises",
    "title": "6  The pipe and renaming",
    "section": "6.6 Exercises",
    "text": "6.6 Exercises\n\n6.6.1 What four principles should column names follow?\n\n\n\n\n\n\nClick to show answer\n\n\n\n\n\n\nUse clear and descriptive names\nUse a naming convention such as snake_case\nUse unique names\nAvoid characters that break R syntax, such as spaces, non-alphanumeric characters, or starting column names with a number.\n\n\n\n\n\n\n6.6.2 Interactive exercises\nComplete the interactive rename() exercises here. This web app is written in the {shiny} package and allows you to write and run code in your web browser.\n\n\n6.6.3 Read .csv file and rename columns\nDownload the data and code for this e-Book (see the Introduction).\nIn your local version of this .qmd file:\n\nCreate a new data frame called dat_likert_renamed by reading the csv file from ‘../data/data_likert_messy.csv’.\nUse rename() to rename every column so that it conforms to the four principles above.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The pipe and renaming</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html",
    "href": "chapters/data_transformation.html",
    "title": "6  Data transformation",
    "section": "",
    "text": "6.1 TODO",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#todo",
    "href": "chapters/data_transformation.html#todo",
    "title": "6  Data transformation",
    "section": "",
    "text": "add a broken qualtrics file example where the text responses don’t match the number responses\nThis chapter needs to be broken down into more chapters to have it map onto lessons better?\nadd across(), separate()\nadd notes Tidy Data\nadd section on forcats and stringr (passing reference to regex) and maybe lubridate at least in passing\nswap current examples for the toy ones, make a larger assignment using the real and messy data sets\nadd later chapter on purrr",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#dependencies-and-data",
    "href": "chapters/data_transformation.html#dependencies-and-data",
    "title": "6  Data transformation",
    "section": "6.2 Dependencies and data",
    "text": "6.2 Dependencies and data\n[[This data comes from a real study on implicit and self-reported evaluations. The implementation of the procedure produced three data files: one for the demographics data, one for the self-reported evaluations, and one for the implicit measure (the ‘Affect Misattribution Procedure’). This script uses each of these to learn and practice functions from the readr, dplyr, and tidyr libraries that are commonly used for data wrangling. In doing so, we will learn how to do many of the steps involved in data processing for a given experiment.]]\n\n\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(janitor) # for clean_names() and round_half_up()\nlibrary(roundwork) # for round_up()\nlibrary(stringr)\nlibrary(knitr) # for kable()\nlibrary(kableExtra) # for kable_classic()\n\n# demographics data\ndata_demographics_raw &lt;- read_csv(file = \"../data/raw/data_demographics_raw.csv\") \n\n# self report measure data\ndata_selfreport_raw &lt;- read_csv(file = \"../data/raw/data_selfreport_raw.csv\") \n\n# affect attribution procedure data\ndata_amp_raw &lt;- read_csv(file = \"../data/raw/data_amp_raw.csv\")\n\n# clean column names\ndata_demographics_clean_names &lt;- data_demographics_raw %&gt;%\n  clean_names() \n\ndata_selfreport_clean_names &lt;- data_selfreport_raw %&gt;%\n  clean_names() \n\ndata_amp_clean_names &lt;- data_amp_raw %&gt;%\n  clean_names()",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#renaming-columns",
    "href": "chapters/data_transformation.html#renaming-columns",
    "title": "6  Data transformation",
    "section": "6.3 Renaming columns",
    "text": "6.3 Renaming columns\nOften variable names are not intuitive. An early step in any data wrangling is to make them more intuitive.\nRename the self reports and AMP data too.\n\n\nCode\ndata_demographics_renamed &lt;- data_demographics_clean_names %&gt;%\n  rename(unique_id = subject,\n         item = trialcode,\n         rt_ms = latency) \n\ndata_selfreport_renamed &lt;- data_selfreport_clean_names %&gt;%\n  rename(unique_id = subject,\n         item = trialcode,\n         rt_ms = latency) \n\ndata_amp_renamed &lt;- data_amp_clean_names %&gt;%\n  rename(unique_id = subject,\n         block_type = blockcode,\n         trial_type = trialcode,\n         trial_id = blocknum_and_trialnum,\n         rt_ms = latency)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#selecting-columns",
    "href": "chapters/data_transformation.html#selecting-columns",
    "title": "6  Data transformation",
    "section": "6.4 Selecting columns",
    "text": "6.4 Selecting columns\nNot all variables are useful to you. An early step in any data wrangling is to drop the columns that you don’t need.\nSelect the self reports and AMP data too.\n\n\nCode\ndata_demographics_selected_columns &lt;- data_demographics_renamed %&gt;%\n  select(unique_id, item, response)\n\ndata_selfreport_selected_columns &lt;- data_selfreport_renamed %&gt;%\n  select(unique_id, item, response, rt_ms)\n\ndata_amp_selected_columns &lt;- data_amp_renamed %&gt;%\n  select(unique_id, \n         # methods variables\n         block_type,\n         trial_type,\n         trial_id,\n         # responses \n         rt_ms, \n         correct)\n\n\n\n6.4.1 More flexible selecting\n\n\nCode\ndat &lt;- data.frame(\n  var_1_1 = rnorm(n = 100),\n  var_1_2 = rnorm(n = 100),\n  var_1_3 = rnorm(n = 100),\n  var_1_4 = rnorm(n = 100),\n  var_1_5 = rnorm(n = 100),\n  var_2_1 = rnorm(n = 100),\n  var_2_2 = rnorm(n = 100),\n  var_2_3 = rnorm(n = 100),\n  var_2_4 = rnorm(n = 100),\n  var_2_5 = rnorm(n = 100)\n)\n\ndat |&gt;\n  select(starts_with(\"var_1\")) \n\n\n         var_1_1      var_1_2     var_1_3      var_1_4     var_1_5\n1    1.095442902  0.366423272 -1.78488201  1.055068821 -0.77649495\n2    0.779676484 -0.549384439 -0.65978409 -0.061740629  1.00021851\n3   -0.337104610  1.325813109 -0.70924751  0.793660086 -0.34115075\n4   -1.610260864  0.605105954 -0.85660631 -0.397584952 -0.48698161\n5   -1.458857854  1.085196960  0.18943063  0.207311213  0.11346815\n6   -0.596405767 -0.277215257  0.16651390  0.926534914  0.72932900\n7   -0.609204412 -0.165135663 -0.46245122  0.227123205 -0.87624471\n8   -0.029987790  1.302921712 -0.84145758 -0.957935258  0.47878028\n9   -0.964839350  0.275599632  0.64066559 -0.909252112 -1.37987881\n10   1.976726508 -1.218981253  1.02202034  0.323641928  0.05473175\n11   1.415279530 -1.758368687  0.01440304  0.414018879  0.85771473\n12   0.191985821  0.850464855  0.05962837 -0.188892956  0.43802285\n13  -1.584973841  1.069805357 -0.96758794 -0.453954494 -0.18440600\n14  -0.948715009 -0.818320182  1.39705579 -0.550353040  1.46504722\n15   1.191186932 -0.381435272 -0.72988255 -0.183559183  1.84640505\n16   0.135308193 -0.165767861  0.50901385 -0.625069934 -0.08570638\n17   1.313470972  0.138430187 -1.17508810  0.568921366 -0.22264983\n18   0.949078698 -0.583493490 -1.76108776  2.686186943  0.87859459\n19  -0.131063030 -0.315667231 -0.16762945 -1.450904437 -1.03984266\n20  -1.520289441 -0.280510288 -1.31792077 -0.013708123  0.20079596\n21   0.288551666  0.470760305  1.70639721 -0.706325949  0.55078743\n22   1.891627087 -1.222451003  0.29000456  0.476856074  0.56685044\n23  -1.821891553 -0.860418498  0.54185375  0.451101625 -0.17079650\n24   1.502477397 -2.333225167 -0.66364002 -1.046766775  0.38055706\n25   0.230353098  1.212100419  0.83267836 -2.168843513 -1.28000122\n26   0.440982081 -2.170288445 -0.55255228  2.020639074 -1.31051484\n27  -0.774485150  1.651270537 -0.07154614 -0.223647449  0.10986797\n28  -0.782579275 -1.150467326 -0.41637031  0.579720348 -0.39576783\n29   0.171250053  1.399209913 -0.41719488 -0.036670140 -0.50305399\n30   1.546784254 -1.164923296  1.04647838  1.115334735  0.42357044\n31  -2.279434097  1.376531624  1.39675513 -0.436325346  0.45079433\n32  -1.169901007  0.703597140 -0.27124307 -0.145782755 -0.84588016\n33  -0.639876747 -0.906908330 -0.44734450 -0.356460112 -1.08380717\n34   0.432507289 -0.285776095  0.97273970  0.859321858  0.91188556\n35  -0.366996466  0.046989784  1.40137499 -2.523031200 -0.01734269\n36  -2.131279164  0.565728408  0.87329769  0.329045963 -0.99440992\n37   0.849476257  0.637688902  1.92236324  2.347556506  0.29991693\n38  -0.715901327  0.937870473  0.85968642  1.608607373  0.59453346\n39   0.650065210 -1.396484226  1.94927998 -0.642544921  0.45000092\n40  -1.049939407 -2.038410882 -0.84016155 -1.082487156 -0.57433335\n41   1.167596585  0.404638927  0.81754568 -0.937015962  1.74278130\n42  -0.574154778 -0.019965313  0.57934585 -1.709907380  0.54306914\n43  -0.254832321 -1.647672905 -0.65170973  0.260458741  0.43481954\n44  -1.441057180  0.236379635 -1.01156994 -0.761874540 -0.20677232\n45   1.533386482 -1.691596675  0.55890533  0.197958245 -0.44178169\n46  -1.778214691  0.709391251 -0.26322088 -1.543607769 -0.86694964\n47   0.718439237 -1.341357989 -0.36109095 -1.158422330 -0.85435446\n48   0.680346382 -0.213833674  0.90876072  0.839072897 -0.38564961\n49   1.421096378  0.002482364  0.08314624 -0.072831167 -1.56161794\n50   0.829239422  0.907043387  1.45398330  1.077834909  0.21645203\n51   0.398097147  0.066884911  0.35055363 -0.105386704  0.41945738\n52  -0.365552240  1.875864144  0.37455506  0.674663296  0.64433980\n53  -0.002929285  0.119724799 -1.13062467 -1.623328338  0.19641831\n54   0.469924021 -1.332758336  0.61116954  1.289755621 -0.26287861\n55  -1.820975365  0.266133558 -0.21720584  0.822846077 -1.76588676\n56   0.823131478  1.718914070 -1.23039832  1.504998203  0.23976250\n57   0.394716334 -0.637523870 -0.21799501 -0.290477802  1.23634266\n58  -3.023074681  0.721156056 -0.16047783  0.805617429  0.33301113\n59   2.064737351 -1.088080402 -0.09694096  1.641051467 -0.97847022\n60  -0.115948056  1.751798376  0.70160706 -0.288364331 -1.03979899\n61  -1.102449846 -1.123483795  1.23748637 -0.593075150  0.03943300\n62   0.865936542  0.204215335  1.86499953  0.009264709 -1.73368832\n63   0.956844684  1.054799337 -0.35281506 -0.568566259  1.42792496\n64   0.761893416 -0.299803960  0.94243444 -1.911944837 -1.14232135\n65  -0.343731747  0.073334256 -0.77662916 -0.900835048 -0.99274608\n66  -0.579605865 -0.222082722 -1.48109775 -0.348813609  0.06881609\n67   0.930526323 -1.177425993 -0.52643953 -0.685994969 -0.27255205\n68   0.787806440 -1.038366878 -0.51334026 -1.801011297  1.31809675\n69  -0.061281021  0.894094125  0.78300415 -2.033919830  0.83923971\n70  -0.007056614  1.641681103 -0.62750769 -0.193034697 -0.78509288\n71  -1.037758105  0.244063452 -1.97744627 -0.468759986  0.07992237\n72   1.200585072  1.064604010 -2.15218257  0.627668341 -0.38379980\n73  -0.630125003  0.622672236  0.87855534 -0.685104103  1.51130462\n74  -0.192365336  2.036765246 -0.88470024  0.548359836 -1.16352478\n75  -0.451001604  1.545075776 -0.28546211 -2.165937485  3.68927025\n76  -0.138596517 -0.062196802 -0.28578255  0.335445989  0.44232444\n77  -1.979811763 -0.292756853  2.26777337 -0.965917901 -2.13150147\n78   0.812847322  0.043968448  0.78404226 -0.653284446 -0.09852058\n79   0.567468780  0.742027692  0.57594292  0.396205449 -0.06562701\n80  -0.253874203  0.981027368 -0.23006793  0.589050176  0.50062079\n81   0.817003189 -0.278397665 -0.20882429  0.973035705 -1.43775722\n82   1.204389015 -0.525255551 -0.50176213 -0.902797689 -0.60381791\n83   0.090600713 -1.234738644 -1.56747959  0.747395341 -0.94784413\n84  -0.450072036  1.391278773 -1.29420293 -2.641378451  0.95944610\n85  -0.642227021  1.574682420  1.83134884 -1.814879524  1.41180820\n86  -0.973151628 -1.047846101 -1.05495239  1.573713103  0.84688192\n87  -0.293686848  0.646872272  0.73903710  0.431800296  0.09957473\n88  -1.469948519 -0.156543674 -0.47849187  0.453136837  0.48165720\n89   1.618818222  1.199528946  1.42618624 -0.243281588  0.09329646\n90   1.340347328  0.936091145  1.43493023  0.517966649  0.65293376\n91   0.826097188  0.055312872  0.46673546  0.419006825 -1.01146296\n92   0.191001673  0.664011347  0.34177281  1.078977272  0.63687967\n93  -0.503368854 -1.450545873  0.05138750 -0.229844982  2.17032256\n94  -1.801408219 -1.023705419 -1.16313715  0.965321704 -0.27422350\n95  -0.757034284  0.368327443 -0.76555516  0.972675990  0.47537770\n96  -0.166776176 -0.434932759  0.31873564 -0.731554319 -0.63745941\n97   0.545062882  0.465629315 -0.99694461  0.548161799 -1.00921217\n98   1.449637821  0.822853017  1.31203720 -0.453902001 -0.47741280\n99  -0.481815066  0.492379550 -0.57473019  0.878499365 -0.04742394\n100 -0.612470929  0.724189548  1.22473848 -0.203424051 -0.71522368\n\n\nCode\ndat |&gt;\n  select(ends_with(\"var_1\")) \n\n\ndata frame with 0 columns and 100 rows\n\n\nCode\ndat |&gt;\n  select(contains(\"_1_\")) \n\n\n         var_1_1      var_1_2     var_1_3      var_1_4     var_1_5\n1    1.095442902  0.366423272 -1.78488201  1.055068821 -0.77649495\n2    0.779676484 -0.549384439 -0.65978409 -0.061740629  1.00021851\n3   -0.337104610  1.325813109 -0.70924751  0.793660086 -0.34115075\n4   -1.610260864  0.605105954 -0.85660631 -0.397584952 -0.48698161\n5   -1.458857854  1.085196960  0.18943063  0.207311213  0.11346815\n6   -0.596405767 -0.277215257  0.16651390  0.926534914  0.72932900\n7   -0.609204412 -0.165135663 -0.46245122  0.227123205 -0.87624471\n8   -0.029987790  1.302921712 -0.84145758 -0.957935258  0.47878028\n9   -0.964839350  0.275599632  0.64066559 -0.909252112 -1.37987881\n10   1.976726508 -1.218981253  1.02202034  0.323641928  0.05473175\n11   1.415279530 -1.758368687  0.01440304  0.414018879  0.85771473\n12   0.191985821  0.850464855  0.05962837 -0.188892956  0.43802285\n13  -1.584973841  1.069805357 -0.96758794 -0.453954494 -0.18440600\n14  -0.948715009 -0.818320182  1.39705579 -0.550353040  1.46504722\n15   1.191186932 -0.381435272 -0.72988255 -0.183559183  1.84640505\n16   0.135308193 -0.165767861  0.50901385 -0.625069934 -0.08570638\n17   1.313470972  0.138430187 -1.17508810  0.568921366 -0.22264983\n18   0.949078698 -0.583493490 -1.76108776  2.686186943  0.87859459\n19  -0.131063030 -0.315667231 -0.16762945 -1.450904437 -1.03984266\n20  -1.520289441 -0.280510288 -1.31792077 -0.013708123  0.20079596\n21   0.288551666  0.470760305  1.70639721 -0.706325949  0.55078743\n22   1.891627087 -1.222451003  0.29000456  0.476856074  0.56685044\n23  -1.821891553 -0.860418498  0.54185375  0.451101625 -0.17079650\n24   1.502477397 -2.333225167 -0.66364002 -1.046766775  0.38055706\n25   0.230353098  1.212100419  0.83267836 -2.168843513 -1.28000122\n26   0.440982081 -2.170288445 -0.55255228  2.020639074 -1.31051484\n27  -0.774485150  1.651270537 -0.07154614 -0.223647449  0.10986797\n28  -0.782579275 -1.150467326 -0.41637031  0.579720348 -0.39576783\n29   0.171250053  1.399209913 -0.41719488 -0.036670140 -0.50305399\n30   1.546784254 -1.164923296  1.04647838  1.115334735  0.42357044\n31  -2.279434097  1.376531624  1.39675513 -0.436325346  0.45079433\n32  -1.169901007  0.703597140 -0.27124307 -0.145782755 -0.84588016\n33  -0.639876747 -0.906908330 -0.44734450 -0.356460112 -1.08380717\n34   0.432507289 -0.285776095  0.97273970  0.859321858  0.91188556\n35  -0.366996466  0.046989784  1.40137499 -2.523031200 -0.01734269\n36  -2.131279164  0.565728408  0.87329769  0.329045963 -0.99440992\n37   0.849476257  0.637688902  1.92236324  2.347556506  0.29991693\n38  -0.715901327  0.937870473  0.85968642  1.608607373  0.59453346\n39   0.650065210 -1.396484226  1.94927998 -0.642544921  0.45000092\n40  -1.049939407 -2.038410882 -0.84016155 -1.082487156 -0.57433335\n41   1.167596585  0.404638927  0.81754568 -0.937015962  1.74278130\n42  -0.574154778 -0.019965313  0.57934585 -1.709907380  0.54306914\n43  -0.254832321 -1.647672905 -0.65170973  0.260458741  0.43481954\n44  -1.441057180  0.236379635 -1.01156994 -0.761874540 -0.20677232\n45   1.533386482 -1.691596675  0.55890533  0.197958245 -0.44178169\n46  -1.778214691  0.709391251 -0.26322088 -1.543607769 -0.86694964\n47   0.718439237 -1.341357989 -0.36109095 -1.158422330 -0.85435446\n48   0.680346382 -0.213833674  0.90876072  0.839072897 -0.38564961\n49   1.421096378  0.002482364  0.08314624 -0.072831167 -1.56161794\n50   0.829239422  0.907043387  1.45398330  1.077834909  0.21645203\n51   0.398097147  0.066884911  0.35055363 -0.105386704  0.41945738\n52  -0.365552240  1.875864144  0.37455506  0.674663296  0.64433980\n53  -0.002929285  0.119724799 -1.13062467 -1.623328338  0.19641831\n54   0.469924021 -1.332758336  0.61116954  1.289755621 -0.26287861\n55  -1.820975365  0.266133558 -0.21720584  0.822846077 -1.76588676\n56   0.823131478  1.718914070 -1.23039832  1.504998203  0.23976250\n57   0.394716334 -0.637523870 -0.21799501 -0.290477802  1.23634266\n58  -3.023074681  0.721156056 -0.16047783  0.805617429  0.33301113\n59   2.064737351 -1.088080402 -0.09694096  1.641051467 -0.97847022\n60  -0.115948056  1.751798376  0.70160706 -0.288364331 -1.03979899\n61  -1.102449846 -1.123483795  1.23748637 -0.593075150  0.03943300\n62   0.865936542  0.204215335  1.86499953  0.009264709 -1.73368832\n63   0.956844684  1.054799337 -0.35281506 -0.568566259  1.42792496\n64   0.761893416 -0.299803960  0.94243444 -1.911944837 -1.14232135\n65  -0.343731747  0.073334256 -0.77662916 -0.900835048 -0.99274608\n66  -0.579605865 -0.222082722 -1.48109775 -0.348813609  0.06881609\n67   0.930526323 -1.177425993 -0.52643953 -0.685994969 -0.27255205\n68   0.787806440 -1.038366878 -0.51334026 -1.801011297  1.31809675\n69  -0.061281021  0.894094125  0.78300415 -2.033919830  0.83923971\n70  -0.007056614  1.641681103 -0.62750769 -0.193034697 -0.78509288\n71  -1.037758105  0.244063452 -1.97744627 -0.468759986  0.07992237\n72   1.200585072  1.064604010 -2.15218257  0.627668341 -0.38379980\n73  -0.630125003  0.622672236  0.87855534 -0.685104103  1.51130462\n74  -0.192365336  2.036765246 -0.88470024  0.548359836 -1.16352478\n75  -0.451001604  1.545075776 -0.28546211 -2.165937485  3.68927025\n76  -0.138596517 -0.062196802 -0.28578255  0.335445989  0.44232444\n77  -1.979811763 -0.292756853  2.26777337 -0.965917901 -2.13150147\n78   0.812847322  0.043968448  0.78404226 -0.653284446 -0.09852058\n79   0.567468780  0.742027692  0.57594292  0.396205449 -0.06562701\n80  -0.253874203  0.981027368 -0.23006793  0.589050176  0.50062079\n81   0.817003189 -0.278397665 -0.20882429  0.973035705 -1.43775722\n82   1.204389015 -0.525255551 -0.50176213 -0.902797689 -0.60381791\n83   0.090600713 -1.234738644 -1.56747959  0.747395341 -0.94784413\n84  -0.450072036  1.391278773 -1.29420293 -2.641378451  0.95944610\n85  -0.642227021  1.574682420  1.83134884 -1.814879524  1.41180820\n86  -0.973151628 -1.047846101 -1.05495239  1.573713103  0.84688192\n87  -0.293686848  0.646872272  0.73903710  0.431800296  0.09957473\n88  -1.469948519 -0.156543674 -0.47849187  0.453136837  0.48165720\n89   1.618818222  1.199528946  1.42618624 -0.243281588  0.09329646\n90   1.340347328  0.936091145  1.43493023  0.517966649  0.65293376\n91   0.826097188  0.055312872  0.46673546  0.419006825 -1.01146296\n92   0.191001673  0.664011347  0.34177281  1.078977272  0.63687967\n93  -0.503368854 -1.450545873  0.05138750 -0.229844982  2.17032256\n94  -1.801408219 -1.023705419 -1.16313715  0.965321704 -0.27422350\n95  -0.757034284  0.368327443 -0.76555516  0.972675990  0.47537770\n96  -0.166776176 -0.434932759  0.31873564 -0.731554319 -0.63745941\n97   0.545062882  0.465629315 -0.99694461  0.548161799 -1.00921217\n98   1.449637821  0.822853017  1.31203720 -0.453902001 -0.47741280\n99  -0.481815066  0.492379550 -0.57473019  0.878499365 -0.04742394\n100 -0.612470929  0.724189548  1.22473848 -0.203424051 -0.71522368",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#practice-the-pipe-again",
    "href": "chapters/data_transformation.html#practice-the-pipe-again",
    "title": "6  Data transformation",
    "section": "6.5 Practice the pipe again",
    "text": "6.5 Practice the pipe again\nCombine the above function calls using pipes. Notice how this involves fewer objects in your environment, and therefore less potential for confusion or error.\nRemember: this is how we solve coding problems: break them down into smaller tasks and problems, get each of them working individually, then combine them together again. When you only see the end product, it’s easy to think the author simply wrote the code as you see it, when they often wrote much more verbose chunks of code and then combined them together.\nRewrite the rename and select calls for the AMP and self report data too.\n\n\nCode\n# remove all objects in environment\nrm(list = ls())\n\n\ndata_demographics_trimmed &lt;-\n  # read in the data\n  read_csv(\"../data/raw/data_demographics_raw.csv\") %&gt;%\n  \n  # convert to snake case\n  clean_names() %&gt;%\n  \n  # make names more intuitive\n  rename(unique_id = subject,\n         item = trialcode) %&gt;%\n  \n  # retain only columns of interest\n  select(unique_id, item, response)\n\n\ndata_selfreport_trimmed &lt;- \n  read_csv(\"../data/raw/data_selfreport_raw.csv\") %&gt;%\n  clean_names() %&gt;%\n  rename(unique_id = subject,\n         item = trialcode) %&gt;%\n  select(unique_id, item, response)\n\ndata_amp_trimmed &lt;- \n  read_csv(\"../data/raw/data_amp_raw.csv\") %&gt;%\n  clean_names() %&gt;%\n  rename(unique_id = subject,\n         block_type = blockcode,\n         trial_type = trialcode,\n         trial_id = blocknum_and_trialnum,\n         rt_ms = latency) %&gt;%\n  select(unique_id, \n         # methods variables\n         block_type,\n         trial_type,\n         trial_id,\n         # responses \n         rt_ms, \n         correct)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#counting-frequencies",
    "href": "chapters/data_transformation.html#counting-frequencies",
    "title": "6  Data transformation",
    "section": "6.6 Counting frequencies",
    "text": "6.6 Counting frequencies\nAfter renaming and selecting columns, we know what columns we have. But what rows do we have in each of these? What might we need to exclude, change, work with in some way later on? It is very useful to use count() to obtain the frequency of each unique value of a given column\n\n\nCode\ndata_demographics_trimmed %&gt;%\n  count(item)\n\n\n# A tibble: 2 × 2\n  item       n\n  &lt;chr&gt;  &lt;int&gt;\n1 age      100\n2 gender   100\n\n\nCode\ndata_demographics_trimmed %&gt;%\n  count(response)\n\n\n# A tibble: 50 × 2\n   response     n\n   &lt;chr&gt;    &lt;int&gt;\n 1 18           1\n 2 19           4\n 3 20           1\n 4 21           6\n 5 22           2\n 6 23           6\n 7 24           1\n 8 25           3\n 9 26           4\n10 27           5\n# ℹ 40 more rows\n\n\n\n\nCode\ndata_selfreport_trimmed %&gt;%\n  count(item)\n\n\n# A tibble: 4 × 2\n  item             n\n  &lt;chr&gt;        &lt;int&gt;\n1 instructions    99\n2 like            99\n3 positive        97\n4 prefer          97\n\n\nCode\ndata_selfreport_trimmed %&gt;%\n  count(response)\n\n\n# A tibble: 9 × 2\n  response     n\n  &lt;chr&gt;    &lt;int&gt;\n1 1          193\n2 2           43\n3 3           26\n4 4           16\n5 5            7\n6 57          99\n7 6            4\n8 7            3\n9 Ctrl+'B'     1\n\n\n\n\nCode\ndata_amp_trimmed %&gt;%\n  count(trial_type)\n\n\n# A tibble: 5 × 2\n  trial_type                  n\n  &lt;chr&gt;                   &lt;int&gt;\n1 instructions                2\n2 prime_negative           3604\n3 prime_negative_practice   508\n4 prime_positive           3604\n5 prime_positive_practice   506\n\n\nCode\ndata_amp_trimmed %&gt;%\n  count(block_type)\n\n\n# A tibble: 2 × 2\n  block_type     n\n  &lt;chr&gt;      &lt;int&gt;\n1 practice    1014\n2 test        7210\n\n\nCode\ndata_amp_trimmed %&gt;%\n  count(correct)\n\n\n# A tibble: 2 × 2\n  correct     n\n    &lt;dbl&gt; &lt;int&gt;\n1       0  3440\n2       1  4784\n\n\nCode\ndata_amp_trimmed %&gt;%\n  count(rt_ms)\n\n\n# A tibble: 2,165 × 2\n   rt_ms     n\n   &lt;dbl&gt; &lt;int&gt;\n 1     1     2\n 2     3     1\n 3     5     2\n 4     8     1\n 5     9     1\n 6    11     1\n 7    13     1\n 8    14     1\n 9    16     1\n10    18     1\n# ℹ 2,155 more rows\n\n\n\n6.6.1 Frequncies of sets of columns\nNote that it is also possible to use count to obtain the frequencies of sets of unique values across columns, e.g., unique combinations of item and response.\n\n\nCode\ndata_demographics_trimmed %&gt;%\n  count(item)\n\n\n# A tibble: 2 × 2\n  item       n\n  &lt;chr&gt;  &lt;int&gt;\n1 age      100\n2 gender   100\n\n\nCode\ndata_demographics_trimmed %&gt;%\n  count(response)\n\n\n# A tibble: 50 × 2\n   response     n\n   &lt;chr&gt;    &lt;int&gt;\n 1 18           1\n 2 19           4\n 3 20           1\n 4 21           6\n 5 22           2\n 6 23           6\n 7 24           1\n 8 25           3\n 9 26           4\n10 27           5\n# ℹ 40 more rows\n\n\nCode\ndata_demographics_trimmed %&gt;%\n  count(item, response)\n\n\n# A tibble: 51 × 3\n   item  response     n\n   &lt;chr&gt; &lt;chr&gt;    &lt;int&gt;\n 1 age   18           1\n 2 age   19           4\n 3 age   20           1\n 4 age   21           6\n 5 age   22           2\n 6 age   23           5\n 7 age   24           1\n 8 age   25           3\n 9 age   26           4\n10 age   27           5\n# ℹ 41 more rows\n\n\nIt can be useful to arrange the output by the frequencies.\n\n\nCode\ndata_demographics_trimmed %&gt;%\n  count(item, response) %&gt;%\n  arrange(desc(n)) # arrange in descending order\n\n\n# A tibble: 51 × 3\n   item   response     n\n   &lt;chr&gt;  &lt;chr&gt;    &lt;int&gt;\n 1 gender Male        36\n 2 gender female      27\n 3 gender male        18\n 4 gender Female      11\n 5 age    21           6\n 6 age    23           5\n 7 age    27           5\n 8 age    32           5\n 9 age    19           4\n10 age    26           4\n# ℹ 41 more rows",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#filtering-rows",
    "href": "chapters/data_transformation.html#filtering-rows",
    "title": "6  Data transformation",
    "section": "6.7 Filtering rows",
    "text": "6.7 Filtering rows\nOnce we know the contents of our columns, we may wish to exclude some rows using filter().\nYou can specify the logical test for filtering in many ways, including equivalence (==), negation (!=), or membership (%in%). It is often better to define what you do want (using equivalence or membership) rather than what you do not want (negation), as negations are less robust to new data with weird values you didn’t think of when you wrote the code. E.g., you could specify gender != \"non-binary\" but this would not catch non binary. If you were for example looking to include only men and women, instead use gender %in% c(\"man\", \"woman\").*\n*[This is just an example; there is usually no good a priori reason to exclude gender diverse participants]\n\n\nCode\n# example using equivalence\nexample_equivalence &lt;- data_amp_trimmed %&gt;%\n  filter(block_type == \"test\")\n\n# example using negation\nexample_negation &lt;- data_selfreport_trimmed %&gt;%\n  filter(item != \"instructions\")\n\n# example using membership\nexample_membership &lt;- data_selfreport_trimmed %&gt;%\n  filter(item %in% c(\"positive\", \"prefer\", \"like\"))\n\n\n\n6.7.1 Multiple criteria, ‘and’ or ‘or’ combinations\nYou can also have multiple criteria in your filter call, both of which have to be met (x & y), or either one of which have to be met (x | y).\n\n\nCode\nexample_multiple_criteria_1 &lt;- data_amp_trimmed %&gt;%\n  filter(block_type != \"test\" & correct == 1)\n\nexample_multiple_criteria_2 &lt;- data_amp_trimmed %&gt;%\n  filter(block_type != \"test\" | correct == 1)\n\n# note that these provide different results - make sure you understand why\nidentical(example_multiple_criteria_1, example_multiple_criteria_2)\n\n\n[1] FALSE\n\n\n\n\n6.7.2 Practice filtering\nFilter the self reports data frame to remove the instructions. Filter the AMP data frame to remove the practice blocks and the instruction trials.\n\n\nCode\ndata_selfreport_trials &lt;- data_selfreport_trimmed %&gt;%\n  #filter(item != \"instructions\")\n  filter(item %in% c(\"positive\", \"prefer\", \"like\"))\n\n# this probably contains things we don't want\ndata_amp_trimmed %&gt;%\n  count(trial_type, block_type)\n\n\n# A tibble: 5 × 3\n  trial_type              block_type     n\n  &lt;chr&gt;                   &lt;chr&gt;      &lt;int&gt;\n1 instructions            test           2\n2 prime_negative          test        3604\n3 prime_negative_practice practice     508\n4 prime_positive          test        3604\n5 prime_positive_practice practice     506\n\n\nCode\n# we exclude them\ndata_amp_test_trials &lt;- data_amp_trimmed %&gt;%\n  filter(block_type == \"test\") %&gt;%\n  filter(trial_type != \"instructions\")\n\n# check they are excluded\ndata_amp_test_trials %&gt;%\n  count(trial_type, block_type)\n\n\n# A tibble: 2 × 3\n  trial_type     block_type     n\n  &lt;chr&gt;          &lt;chr&gt;      &lt;int&gt;\n1 prime_negative test        3604\n2 prime_positive test        3604\n\n\n\n\n6.7.3 More flexible filtering\nReturn rows with exactly this contents\n\n\nCode\ndata_amp_test_trials |&gt;\n  filter(trial_id == \"A\") # \n\n\n# A tibble: 0 × 6\n# ℹ 6 variables: unique_id &lt;dbl&gt;, block_type &lt;chr&gt;, trial_type &lt;chr&gt;,\n#   trial_id &lt;chr&gt;, rt_ms &lt;dbl&gt;, correct &lt;dbl&gt;\n\n\nReturn rows containing contents but not exactly it\n\n\nCode\nlibrary(stringr)\n\ntest &lt;- c(\"A\", \"AB\", \"B\")\n\ntest == \"A\"\n\n\n[1]  TRUE FALSE FALSE\n\n\nCode\nstr_detect(test, \"A\")\n\n\n[1]  TRUE  TRUE FALSE\n\n\nCode\nstr_detect(test, \"B\")\n\n\n[1] FALSE  TRUE  TRUE\n\n\nCode\ndata_amp_test_trials |&gt;\n  filter(str_detect(trial_id, \"2_\")) \n\n\n# A tibble: 7,208 × 6\n   unique_id block_type trial_type     trial_id rt_ms correct\n       &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;          &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1 504546409 test       prime_positive 2_2        161       0\n 2 504546409 test       prime_positive 2_3        328       0\n 3 504546409 test       prime_positive 2_4        220       1\n 4 504546409 test       prime_negative 2_5        308       1\n 5 504546409 test       prime_negative 2_6        235       1\n 6 504546409 test       prime_negative 2_7        224       1\n 7 504546409 test       prime_negative 2_8        369       0\n 8 504546409 test       prime_positive 2_9       1105       1\n 9 994692692 test       prime_positive 2_2       1611       0\n10 994692692 test       prime_negative 2_3        627       0\n# ℹ 7,198 more rows\n\n\n\n6.7.3.1 Multiple logical tests\n\n\nCode\n# \"|\" = OR\n# \"&\" = AND\n\ndata_amp_test_trials |&gt;\n  filter(str_detect(trial_id, \"2_\") &\n           str_detect(trial_id, \"3_\"))\n\n\n# A tibble: 0 × 6\n# ℹ 6 variables: unique_id &lt;dbl&gt;, block_type &lt;chr&gt;, trial_type &lt;chr&gt;,\n#   trial_id &lt;chr&gt;, rt_ms &lt;dbl&gt;, correct &lt;dbl&gt;\n\n\nCode\ndata_amp_test_trials |&gt;\n  mutate(rt_ms = ifelse(str_detect(trial_id, \"2_\"), rt_ms+100, rt_ms))\n\n\n# A tibble: 7,208 × 6\n   unique_id block_type trial_type     trial_id rt_ms correct\n       &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;          &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1 504546409 test       prime_positive 2_2        261       0\n 2 504546409 test       prime_positive 2_3        428       0\n 3 504546409 test       prime_positive 2_4        320       1\n 4 504546409 test       prime_negative 2_5        408       1\n 5 504546409 test       prime_negative 2_6        335       1\n 6 504546409 test       prime_negative 2_7        324       1\n 7 504546409 test       prime_negative 2_8        469       0\n 8 504546409 test       prime_positive 2_9       1205       1\n 9 994692692 test       prime_positive 2_2       1711       0\n10 994692692 test       prime_negative 2_3        727       0\n# ℹ 7,198 more rows",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#check-your-learning",
    "href": "chapters/data_transformation.html#check-your-learning",
    "title": "6  Data transformation",
    "section": "6.8 Check your learning",
    "text": "6.8 Check your learning\nWhat is the difference between select and filter?\nWhich is for rows and which is for columns?",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#mutating-creating-new-columns-or-changing-the-contents-of-existing-ones",
    "href": "chapters/data_transformation.html#mutating-creating-new-columns-or-changing-the-contents-of-existing-ones",
    "title": "6  Data transformation",
    "section": "6.9 Mutating: creating new columns or changing the contents of existing ones",
    "text": "6.9 Mutating: creating new columns or changing the contents of existing ones\n\n6.9.1 Understanding mutate()\nmutate() is used to create new columns or to change the contents of existing ones.\n\n\nCode\n# mutating new variables\nexample_1 &lt;- data_amp_test_trials %&gt;%\n  mutate(latency_plus_1 = rt_ms + 1)\n\nexample_2 &lt;- data_amp_test_trials %&gt;%\n  mutate(log_latency = log(rt_ms))\n\n# mutating the contents of existing variables\nexample_3 &lt;- data_amp_test_trials %&gt;%\n  mutate(rt_s = rt_ms / 1000) # latency is now in seconds rather than milliseconds\n\n\nThe operations inside mutate can range from the very simple, like the above, to much more complex. The below example uses other functions we haven’t learned yet. For now, just notice that there can be multiple mutate calls and they can produce a cleaned up gender variable.\n\n\nCode\n# illustrate the problem with the gender responses:\ndata_demographics_trimmed %&gt;%\n  # filter only the gender item, not age\n  filter(item == \"gender\") %&gt;%\n  count(response) %&gt;%\n  arrange(desc(n))\n\n\n# A tibble: 11 × 2\n   response       n\n   &lt;chr&gt;      &lt;int&gt;\n 1 Male          36\n 2 female        27\n 3 male          18\n 4 Female        11\n 5 Non-Binary     2\n 6 23             1\n 7 FEMALE         1\n 8 MALE           1\n 9 Woman          1\n10 non binary     1\n11 yes            1\n\n\nCode\n# clean up the gender variable\ndata_demographics_gender_tidy_1 &lt;- data_demographics_trimmed %&gt;%\n  # filter only the gender item, not age\n  filter(item == \"gender\") %&gt;%\n  # change the name of the response variable to what it now represents: gender\n  rename(gender = response) %&gt;%\n  # change or remove weird responses to the gender question\n  mutate(gender = str_to_lower(gender)) %&gt;%\n  mutate(gender = str_remove_all(gender, \"[\\\\d.]\")) %&gt;% # remove everything except letters\n  mutate(gender = na_if(gender, \"\")) %&gt;% \n  mutate(gender = case_when(gender == \"woman\" ~ \"female\",\n                            gender == \"man\" ~ \"male\",\n                            gender == \"girl\" ~ \"female\",\n                            gender == \"yes\" ~ NA_character_,\n                            gender == \"dude\" ~ \"male\",\n                            gender == \"non binary\" ~ \"non-binary\",\n                            TRUE ~ gender)) %&gt;%\n  # select only the columns of interest\n  select(unique_id, gender)\n\n# illustrate the data after cleaning:\ndata_demographics_gender_tidy_1 %&gt;%\n  count(gender) %&gt;%\n  arrange(desc(n))\n\n\n# A tibble: 4 × 2\n  gender         n\n  &lt;chr&gt;      &lt;int&gt;\n1 male          55\n2 female        40\n3 non-binary     3\n4 &lt;NA&gt;           2\n\n\nA single mutate call can contain multiple mutates. The code from the last chunk could be written more simply like this:\n\n\nCode\n# clean up the gender variable\ndata_demographics_gender_tidy_2 &lt;- data_demographics_trimmed %&gt;%\n  # filter only the gender item, not age\n  filter(item == \"gender\") %&gt;%\n  # change the name of the response variable to what it now represents: gender\n  rename(gender = response) %&gt;%\n  # change or remove weird responses to the gender question\n  mutate(gender = str_to_lower(gender),\n         gender = str_remove_all(gender, \"[\\\\d.]\"), # remove everything except letters\n         gender = na_if(gender, \"\"), \n         gender = case_when(gender == \"woman\" ~ \"female\",\n                            gender == \"man\" ~ \"male\",\n                            gender == \"girl\" ~ \"female\",\n                            gender == \"yes\" ~ NA_character_,\n                            gender == \"dude\" ~ \"male\",\n                            gender == \"non binary\" ~ \"non-binary\",\n                            TRUE ~ gender)) %&gt;%\n  # select only the columns of interest\n  select(unique_id, gender)\n\n# check they are identical\nidentical(data_demographics_gender_tidy_1, data_demographics_gender_tidy_2)\n\n\n[1] TRUE\n\n\n\n\n6.9.2 Practice mutate()\nWhen analyzing cognitive behavioral tasks, it is common to employ mastery criteria to exclude participants who have not met or maintained some criterion within the task. We’ll do the actual exclusions etc. later on, but for practice using mutate() by creating a new fast_trial column to indicate trials where the response was implausibly fast (e.g., &lt; 100 ms).\nTry doing this with a simple logical test of whether latency &lt; 100. You can do this with or without using the ifelse() function.\n\n\nCode\ndata_amp_test_trials_with_fast_trials &lt;- data_amp_test_trials %&gt;%\n  mutate(fast_trial = ifelse(test = rt_ms &lt; 100,\n                             yes = TRUE,\n                             no = FALSE))\n\n# more briefly but less explicitly\ndata_amp_test_trials_with_fast_trials &lt;- data_amp_test_trials %&gt;%\n  mutate(fast_trial = rt_ms &lt; 100)\n\n\n\n\n6.9.3 Practice mutate() & learn ifelse()\nUse mutate() to remove weird values from data_demographics_trimmed$response, for the rows referring to age, that aren’t numbers.\nWhat function could you use to first determine what values are present in this column, to know which could be retained or changed?\nIn simple cases like this, you can use mutate() and ifelse() to change impossible values to NA.\n\n\nCode\n# what values are present?\ndata_demographics_trimmed %&gt;%\n  filter(item == \"age\") %&gt;%\n  count(response) \n\n\n# A tibble: 40 × 2\n   response     n\n   &lt;chr&gt;    &lt;int&gt;\n 1 18           1\n 2 19           4\n 3 20           1\n 4 21           6\n 5 22           2\n 6 23           5\n 7 24           1\n 8 25           3\n 9 26           4\n10 27           5\n# ℹ 30 more rows\n\n\nCode\n# fix them with mutate\ndata_demographics_age_tidy &lt;- data_demographics_trimmed %&gt;%\n  filter(item == \"age\") %&gt;%\n  mutate(response = ifelse(test = response == \"old\",\n                           yes = NA_integer_,\n                           no = response)) %&gt;%\n  mutate(response = as.numeric(response)) %&gt;%\n  rename(age = response)\n\n# check this has fixed the issue\ndata_demographics_age_tidy %&gt;%\n  count(age)\n\n\n# A tibble: 40 × 2\n     age     n\n   &lt;dbl&gt; &lt;int&gt;\n 1    18     1\n 2    19     4\n 3    20     1\n 4    21     6\n 5    22     2\n 6    23     5\n 7    24     1\n 8    25     3\n 9    26     4\n10    27     5\n# ℹ 30 more rows\n\n\n\n\n6.9.4 Practice mutate() & ifelse()\nUse mutate() to remove weird values from data_selfreport_trials$response that aren’t Likert responses.\nFirst determine what values are present in this column.\nUse ifelse() and %in% inside mutate() to change values other than the Likert responses to NA.\nIf you struggle to do this: practice writing ‘pseudocode’ here. That is, without knowing the right code, explain in precise logic what you want the computer to do. This can be converted to R more easily.\n\n\nCode\n# what values are present?\ndata_selfreport_trials %&gt;%\n  count(response)\n\n\n# A tibble: 8 × 2\n  response     n\n  &lt;chr&gt;    &lt;int&gt;\n1 1          193\n2 2           43\n3 3           26\n4 4           16\n5 5            7\n6 6            4\n7 7            3\n8 Ctrl+'B'     1\n\n\nCode\n# what type of data is the response column?\nclass(data_selfreport_trials$response)\n\n\n[1] \"character\"\n\n\nCode\n# remove non Likert values\ndata_selfreport_tidy &lt;- data_selfreport_trials %&gt;%\n  mutate(response = ifelse(response == \"Ctrl+'B'\", NA_integer_, response),\n         response = as.numeric(response))\n\n\n# show the data after changes\ndata_selfreport_tidy %&gt;%\n  count(response)\n\n\n# A tibble: 8 × 2\n  response     n\n     &lt;dbl&gt; &lt;int&gt;\n1        1   193\n2        2    43\n3        3    26\n4        4    16\n5        5     7\n6        6     4\n7        7     3\n8       NA     1\n\n\nCode\nclass(data_selfreport_tidy$response)\n\n\n[1] \"numeric\"\n\n\nWhat other ways are there of implementing this mutate, e.g., without using %in%? What are the pros and cons of each?\n\n\nCode\n# write examples here\n\n\n\n\n6.9.5 Practice mutate() & learn case_when()\ncase_when() allows you to compare multiple logical tests or if-else tests.\nThe AMP data needs to be reverse scored. Just like an item on a self-report that is worded negatively (e.g., most items: I am a good person; some items: I am a bad person), the negative prime trials have the opposite ‘accuracy’ values that they should. Use mutate() and case_when() to reverse score the negative prime trials, so that what was 0 is now 1 and what was 1 is now 0.\n\n\nCode\n# in your own time later, see if you can rewrite this yourself without looking at the answer to practice using case_when\ndata_amp_tidy &lt;- data_amp_test_trials_with_fast_trials %&gt;%\n  mutate(correct = case_when(trial_type == \"prime_positive\" ~ correct,\n                             trial_type == \"prime_negative\" & correct == 0 ~ 1,\n                             trial_type == \"prime_negative\" & correct == 1 ~ 0))\n\n# you can also specify a default value to return if none of the logical tests are passed with 'TRUE ~':\ndata_amp_tidy &lt;- data_amp_test_trials_with_fast_trials %&gt;%\n  mutate(correct = case_when(trial_type == \"prime_negative\" & correct == 0 ~ 1,\n                             trial_type == \"prime_negative\" & correct == 1 ~ 0,\n                             TRUE ~ correct))",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#summarizing-across-rows",
    "href": "chapters/data_transformation.html#summarizing-across-rows",
    "title": "6  Data transformation",
    "section": "6.10 Summarizing across rows",
    "text": "6.10 Summarizing across rows\nIt is very common that we need to create summaries across rows. For example, to create the mean and standard deviation of a column like age. This can be done with summarize(). Remember: mutate() creates new columns or modifies the contents of existing columns, but does not change the number of rows. Whereas summarize() reduces a data frame down to one row.\n\n\nCode\n# mean\ndata_demographics_age_tidy %&gt;%\n  summarize(mean_age = mean(age, na.rm = TRUE))\n\n\n# A tibble: 1 × 1\n  mean_age\n     &lt;dbl&gt;\n1     35.7\n\n\nCode\n# SD\ndata_demographics_age_tidy %&gt;%\n  summarize(sd_age = sd(age, na.rm = TRUE))\n\n\n# A tibble: 1 × 1\n  sd_age\n   &lt;dbl&gt;\n1   12.4\n\n\nCode\n# mean and SD with rounding, illustrating how multiple summarizes can be done in one function call\ndata_demographics_age_tidy %&gt;%\n  summarize(mean_age = mean(age, na.rm = TRUE),\n            sd_age = sd(age, na.rm = TRUE)) |&gt;\n  mutate(mean_age = round_half_up(mean_age, digits = 2),\n         sd_age = round_half_up(sd_age, digits = 2))\n\n\n# A tibble: 1 × 2\n  mean_age sd_age\n     &lt;dbl&gt;  &lt;dbl&gt;\n1     35.7   12.4\n\n\n\n6.10.1 group_by()\nOften, we don’t want to reduce a data frame down to a single row / summarize the whole dataset, but instead we want to create a summary for each (sub)group. For example\n\n\nCode\n# # this code creates data needed for this example - you can simply load the data from disk and skip over this commented-out code. we will come back to things like 'joins' later\n# data_demographics_unique_participant_codes &lt;- data_demographics_trimmed %&gt;%\n#   count(unique_id) %&gt;%\n#   filter(n == 2)\n# \n# data_demographics_age_gender_tidy &lt;- data_demographics_trimmed %&gt;%\n#   semi_join(data_demographics_unique_participant_codes, by = \"unique_id\") %&gt;%\n#   pivot_wider(names_from = \"item\",\n#               values_from = \"response\") %&gt;%\n#   mutate(age = ifelse(age == \"old\", NA, age),\n#          age = as.numeric(age),\n#          gender = tolower(gender),\n#          gender = stringr::str_remove_all(gender, regex(\"\\\\W+\")), # regex is both very useful and awful to write\n#          gender = case_when(gender == \"female\" ~ gender,\n#                             gender == \"male\" ~ gender,\n#                             gender == \"nonbinary\" ~ gender,\n#                             gender == \"woman\" ~ \"female\",\n#                             gender == \"man\" ~ \"male\"))\n# \n# dir.create(\"../data/processed\")\n# write_csv(data_demographics_age_gender_tidy, \"../data/processed/data_demographics_age_gender_tidy.csv\")\n\n# load suitable example data from disk\ndata_demographics_age_gender_tidy &lt;-\n  read_csv(\"../data/processed/data_demographics_age_gender_tidy.csv\")\n\n\n# illustrate use of group_by() and summarize()\ndata_demographics_age_gender_tidy %&gt;%\n  summarize(mean_age = mean(age, na.rm = TRUE))\n\n\n# A tibble: 1 × 1\n  mean_age\n     &lt;dbl&gt;\n1     35.9\n\n\nCode\ndata_demographics_age_gender_tidy %&gt;%\n  group_by(gender) %&gt;%\n  summarize(mean_age = mean(age, na.rm = TRUE))\n\n\n# A tibble: 4 × 2\n  gender    mean_age\n  &lt;chr&gt;        &lt;dbl&gt;\n1 female        35.3\n2 male          37.3\n3 nonbinary     24.3\n4 &lt;NA&gt;          23  \n\n\n\n\n6.10.2 n()\nn() calculates the number of rows, i.e., the N. It can be useful in summarize.\n\n\nCode\n# summarize n\ndata_demographics_age_gender_tidy %&gt;%\n  summarize(n_age = n())\n\n\n# A tibble: 1 × 1\n  n_age\n  &lt;int&gt;\n1    98\n\n\nCode\n# summarize n per gender group\ndata_demographics_age_gender_tidy %&gt;%\n  group_by(gender) %&gt;%\n  summarize(n_age = n())\n\n\n# A tibble: 4 × 2\n  gender    n_age\n  &lt;chr&gt;     &lt;int&gt;\n1 female       40\n2 male         53\n3 nonbinary     3\n4 &lt;NA&gt;          2\n\n\nNote that count() is just the combination of group_by() and summiarize() and n()! they produce the same results as above.\n\n\nCode\n# summarize n\ndata_demographics_age_gender_tidy %&gt;%\n  count()\n\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1    98\n\n\nCode\n# summarize n per gender group\ndata_demographics_age_gender_tidy %&gt;%\n  count(gender)\n\n\n# A tibble: 4 × 2\n  gender        n\n  &lt;chr&gt;     &lt;int&gt;\n1 female       40\n2 male         53\n3 nonbinary     3\n4 &lt;NA&gt;          2\n\n\n\n\n6.10.3 More complex summarizations\nLike mutate, the operation you do to summarize can also be more complex, such as finding the mean result of a logical test to calculate a proportion. For example, the proportion of participants who are less than 25 years old:\n\n\nCode\ndata_demographics_age_tidy %&gt;%\n  summarize(proportion_less_than_25 = mean(age &lt; 25, na.rm = TRUE)) %&gt;%\n  mutate(percent_less_than_25 = round_half_up(proportion_less_than_25 * 100, 1))\n\n\n# A tibble: 1 × 2\n  proportion_less_than_25 percent_less_than_25\n                    &lt;dbl&gt;                &lt;dbl&gt;\n1                   0.202                 20.2\n\n\nYou can also summarize (or indeed mutate) multiple columns in the same way using across(), for do-this-across-columns. We won’t cover how to use this here or all the variations that are possible, just know that it can be done. For example:\n\n\nCode\n# using the mtcars dataset that is built in to {dplyr}, ... \nmtcars %&gt;%\n  # ... calculate the mean of every numeric column in the dataset ...\n  summarise(across(where(is.numeric), mean, na.rm = TRUE)) %&gt;%\n  # ... and then round every column to one decimal place\n  mutate(across(everything(), round_half_up, digits = 1))\n\n\n   mpg cyl  disp    hp drat  wt qsec  vs  am gear carb\n1 20.1 6.2 230.7 146.7  3.6 3.2 17.8 0.4 0.4  3.7  2.8\n\n\n\n\n6.10.4 Realise that count() is just a wrapper function for summarize()\n\n\nCode\ndat &lt;- data.frame(x = c(\n  rnorm(n = 50),\n  rep(NA_integer_, 10)\n))\n\ndat |&gt;\n  mutate(x_is_na = is.na(x)) |&gt;\n  count(x_is_na)\n\n\n  x_is_na  n\n1   FALSE 50\n2    TRUE 10\n\n\nCode\ndat |&gt;\n  summarise(n_na = sum(is.na(x)))\n\n\n  n_na\n1   10\n\n\n\n\n6.10.5 Practice using summarize()\nCalculate the min, max, mean, and SD of all responses on the self report data.\n\n\nCode\ndata_selfreport_tidy %&gt;%\n  summarize(mean = mean(response, na.rm = TRUE),\n            sd = sd(response, na.rm = TRUE),\n            min = min(response, na.rm = TRUE),\n            max = max(response, na.rm = TRUE))\n\n\n# A tibble: 1 × 4\n   mean    sd   min   max\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  1.72  1.26     1     7\n\n\nCurrently each participant has up to three responses on the self-report scales (three item scale: like, positive, and prefer). Create a new dataframe containing each unique_id’s mean score across the items. Also calculate how many items each participant has data for, and whether they have complete data (i.e., data for three items).\n\n\nCode\ndata_selfreport_scored &lt;- data_selfreport_tidy %&gt;%\n  group_by(unique_id) %&gt;%\n  summarize(mean_self_report = mean(response),\n            n_self_report_items = n()) %&gt;%\n  mutate(self_report_complete = n_self_report_items == 3)\n\n\n# test &lt;- c(3, 5, 7, NA)\n# #test &lt;- c(3, 5, 7)\n# mean(test)\n# mean(test, na.rm = TRUE)\n# \n# dat |&gt;\n#   summarize(mean = mean(response, na.rm = TRUE))\n# \n# dat |&gt;\n#   filter(!is.na(response)) |&gt;\n#   summarize(mean = mean(response))\n# \n# mean_not_dumb &lt;- function(x){mean(x, na.rm = TRUE)}\n\n\nUsing only participants with complete, calculate the mean and SD of all participant’s mean scores on the self-reports.\n\n\nCode\n# data_selfreport_scored %&gt;%\n\n\nCreate a new data frame that calculates the proportion of prime-congruent trials for each participant on the AMP (i.e., the mean of the ‘correct’ column), their proportion of too-fast trials, and their number of trials.\nAlso add to that data frame a new column called “exclude_amp” and set it to “exclude” if more than 10% of a participant’s trials are too-fast trials and “include” if not.\n\n\nCode\n# data_amp_scored &lt;- data_amp_tidy %&gt;%\n\n\nCalculate the proportion of participants who are to be excluded.\n\n\nCode\n# data_amp_scored %&gt;%",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#check-your-learning-1",
    "href": "chapters/data_transformation.html#check-your-learning-1",
    "title": "6  Data transformation",
    "section": "6.11 Check your learning",
    "text": "6.11 Check your learning\nWhat is the difference between mutate() and summarize()? If I use the wrong one, will I get the same answer? E.g., mutate(mean_age = mean(age, na.rm = TRUE)) vs. summarize(mean_age = mean(age, na.rm = TRUE))",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#writing-data-to-disk",
    "href": "chapters/data_transformation.html#writing-data-to-disk",
    "title": "6  Data transformation",
    "section": "6.12 Writing data to disk",
    "text": "6.12 Writing data to disk\n\n\nCode\n# write_csv(data_processed, \"../data/processed/data_processed.csv\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/reshaping_and_pivots.html",
    "href": "chapters/reshaping_and_pivots.html",
    "title": "7  Reshaping and pivots",
    "section": "",
    "text": "7.1 Resources\nSee code and gifs here which illustrate pivots (and indeed other tidyverse verbs).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reshaping and pivots</span>"
    ]
  },
  {
    "objectID": "chapters/reshaping_and_pivots.html#dependencies",
    "href": "chapters/reshaping_and_pivots.html#dependencies",
    "title": "7  Reshaping and pivots",
    "section": "7.2 Dependencies",
    "text": "7.2 Dependencies\n\n\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tibble)\n#install.packages(\"devtools\")\n#devtools::install_github(\"debruine/faux\")\nlibrary(faux)\nlibrary(janitor)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(psych)\nlibrary(readr)\nlibrary(knitr)\nlibrary(kableExtra)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reshaping and pivots</span>"
    ]
  },
  {
    "objectID": "chapters/reshaping_and_pivots.html#example",
    "href": "chapters/reshaping_and_pivots.html#example",
    "title": "7  Reshaping and pivots",
    "section": "7.3 Example",
    "text": "7.3 Example\n\n7.3.1 Simulate data in wide format\n\n\nCode\n# set seed for reproducibility\nset.seed(123)\n\n# generate data \ndata_wide &lt;- \n  faux::rnorm_multi(n = 100,\n                    vars = 5,\n                    mu = 3,\n                    sd = 1,\n                    r = 0.5,\n                    varnames = paste0(\"item_\", 1:5),\n                    empirical = FALSE) %&gt;%\n  rownames_to_column(var = \"id\")\n\n# recode responses less than 1 or more than 5 to those values, then round scores to whole numbers\n# note that {faux} has functions for doing this better\n\n\n# dat &lt;- data_wide |&gt;\n#   mutate(item_1 = round_half_up(item_1, digits = 0),\n#          item_1 = ifewlse\n\ndata_wide_likert &lt;- data_wide %&gt;%\n  mutate(across(starts_with(\"item_\"), ~ round_half_up(.x, digits = 0))) %&gt;%\n  mutate(across(starts_with(\"item_\"), ~ ifelse(.x &lt; 1, 1, ifelse(.x &gt; 5, 5, .x))))\n\n\n\n\n7.3.2 Cronbach’s alpha\nWide data like this is a) common and b) useful for calculating metrics like internal consistency.\n\n\nCode\nres_alpha &lt;- data_wide_likert %&gt;%\n  #select(-id) %&gt;%\n  select(starts_with(\"item_\")) %&gt;%\n  psych::alpha()\n\ncronbachs_alpha_estimate &lt;- res_alpha$total$raw_alpha |&gt;\n  round_half_up(digits = 2)\n\n\nCronbach’s \\(\\alpha\\) = 0.79\n\n\n7.3.3 Plot simulated data\n\n\nCode\nggplot(data_wide_likert, aes(x = item_1)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nCode\nggplot(data_wide_likert, aes(x = item_2)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nCode\nggplot(data_wide_likert, aes(x = item_3)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nCode\nggplot(data_wide_likert, aes(x = item_4)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nCode\nggplot(data_wide_likert, aes(x = item_5)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n\nThese plots repeat the mortal coding sin of repeating ourselves. If we reshaped the data to ‘long’ format we could use just one ggplot() call that includes facet_wrap().\n\n\n\n7.3.4 Reshape\nUsing pivot_longer().\n\n\nCode\n# positive selection\ndata_long &lt;- data_wide_likert %&gt;%\n  pivot_longer(cols = starts_with(\"item_\"),\n               names_to = \"item\",\n               values_to = \"response\")\n\n# positive selection using a different tidy select function\ndata_long &lt;- data_wide_likert %&gt;%\n  pivot_longer(cols = contains(\"item_\"),\n               names_to = \"item\",\n               values_to = \"response\")\n\n# negative selection\ndata_long &lt;- data_wide_likert %&gt;%\n  pivot_longer(cols = -id,\n               names_to = \"item\",\n               values_to = \"response\") |&gt;\n  mutate(item = stringr::str_remove(item, \"item_\"))\n\nggplot(data_long, aes(x = response)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw() +\n  facet_wrap(~ item)\n\n\n\n\n\n\n\n\n\n\nWhat other ways could you specify this pivot_longer call’s arguments?\nfacet_wrap() is to {ggplot} as group_by() is to {dplyr}\n\n\n7.3.4.1 Calculate sum scores\n\n\nCode\ntemp &lt;- data_wide_likert |&gt;\n  group_by(id) |&gt;\n  mutate(sum_score = item_1 + item_2 + item_3 + item_4 + item_5)\n  #mutate(sum_score = rowSums(item_1, item_2, item_3, item_4, item_5))\n\n\n\nrow math is much faster than column math in R!\n\n\n\nCode\nsum_scores &lt;- data_long %&gt;%\n  group_by(id) %&gt;%\n  summarise(sum_score = sum(response))\n\n\nggplot(sum_scores, aes(x = sum_score)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  scale_x_continuous(breaks = breaks_pretty(n = 10)) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.5 Convert this long data back to wide\nJust to know how to do it.\n\n\nCode\ndata_wide_again &lt;- data_long %&gt;%\n  pivot_wider(names_from = item,\n              values_from = response,\n              names_prefix = \"item_\")\n\n\n\n\n7.3.6 Combine item and sum scores in one data frame\n\n\nCode\ndata_item_and_sum_scores &lt;- data_wide_again %&gt;%\n  left_join(sum_scores, by = \"id\")\n\n# why joins are needed over bind_cols \n# wrong &lt;- bind_cols(data_wide_again, sum_scores |&gt; select(-id))",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reshaping and pivots</span>"
    ]
  },
  {
    "objectID": "chapters/reshaping_and_pivots.html#new-facet-plot-with-items-and-sum-score",
    "href": "chapters/reshaping_and_pivots.html#new-facet-plot-with-items-and-sum-score",
    "title": "7  Reshaping and pivots",
    "section": "7.4 New facet plot with items and sum score",
    "text": "7.4 New facet plot with items and sum score\n\n\nCode\ndata_long_with_sum_score &lt;- data_item_and_sum_scores %&gt;%\n  pivot_longer(cols = -id,\n               names_to = \"item\",\n               values_to = \"response\")\n\nggplot(data_long_with_sum_score, aes(x = response)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw() +\n  facet_wrap(~ item, scales = \"free\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reshaping and pivots</span>"
    ]
  },
  {
    "objectID": "chapters/reshaping_and_pivots.html#practice",
    "href": "chapters/reshaping_and_pivots.html#practice",
    "title": "7  Reshaping and pivots",
    "section": "7.5 Practice",
    "text": "7.5 Practice\nWrangle the demographics data included in this exercise more efficiently by reshaping it into wide format. Before, we used filter() to wrangle the age and gender data separately.\n\n\nCode\ndat &lt;- read_csv(\"../data/raw/data_demographics_raw.csv\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reshaping and pivots</span>"
    ]
  },
  {
    "objectID": "chapters/joins.html",
    "href": "chapters/joins.html",
    "title": "8  Joins",
    "section": "",
    "text": "8.1 Dependencies\nCode\nlibrary(dplyr)\nlibrary(readr)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "chapters/joins.html#get-data",
    "href": "chapters/joins.html#get-data",
    "title": "8  Joins",
    "section": "8.2 Get data",
    "text": "8.2 Get data\n\n\nCode\ndata_unique_id_subset &lt;- read_csv(\"../data/raw/data_unique_id_subset.csv\")\ndata_age_gender_subset &lt;- read_csv(\"../data/raw/data_age_gender_subset.csv\")\ndata_amp_summary_subset &lt;- read_csv(\"../data/raw/data_amp_summary_subset.csv\")\ndata_selfreport_summary_subset &lt;- read_csv(\"../data/raw/data_selfreport_summary_subset.csv\")\n\nnrow(data_unique_id_subset)\n\n\n[1] 92\n\n\nCode\nnrow(data_age_gender_subset)\n\n\n[1] 90\n\n\nCode\nnrow(data_amp_summary_subset)\n\n\n[1] 31\n\n\nCode\nnrow(data_selfreport_summary_subset)\n\n\n[1] 76",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "chapters/joins.html#practicing-joins",
    "href": "chapters/joins.html#practicing-joins",
    "title": "8  Joins",
    "section": "8.3 Practicing joins",
    "text": "8.3 Practicing joins\nUsing the data frames below and functions from the _join family, write code to do the following joins.\n\n8.3.1 Practice 1\ncreate ‘data_combined’ by joining data_amp_summary_subset and data_age_gender_subset so that unique_ids in either data frame are retained. which join is this? implement it.\n\n\nCode\n# data_combined &lt;- \n\n\n\n\n8.3.2 Practice 2\ncreate ‘data_self_reports_and_their_amp_data’ by joining data_selfreport_summary_subset and data_amp_summary_subset so that all participants have self-report data, + AMP data if available. which join is this? implement it.\n\n\nCode\n# data_self_reports_and_their_amp_data &lt;- \n\n\n\n\n8.3.3 Practice 3\ndo the opposite: create ‘data_amp_data_and_their_self_reports’ by joining data_amp_summary_subset and data_selfreport_summary_subset so that all participants have AMP data, + self-report data if available. which join is this? implement it.\n\n\nCode\n# data_amp_data_and_their_self_reports &lt;- \n\n\n\n\n8.3.4 Practice 4\ncreate data_combined_2 by joining ‘data_combined’ and data_selfreport_summary_subset only unique_ids already present in data_combined are retained. which join is this? implement it.\n\n\nCode\n# data_combined_2 &lt;- \n\n\n\n\n8.3.5 Practice 5\ncreate ‘data_missing_ids’ which should list the unique_ids are missing from data_unique_id_subset but are present in at least one of data_age_gender_subset, data_amp_summary_subset, and data_selfreport_summary_subset. This will require two different joins. Which? Implement them.\n\n\nCode\n# data_missing_ids &lt;-",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "chapters/reporting.html",
    "href": "chapters/reporting.html",
    "title": "10  Reporting",
    "section": "",
    "text": "10.1 Dependencies\nCode\nlibrary(dplyr)\nlibrary(readr)\nlibrary(report) # part of {easystats}\nlibrary(see) # part of {easystats}\nlibrary(parameters) # part of {easystats}\nlibrary(correlation) # part of {easystats}\nlibrary(effectsize) # part of {easystats}\nlibrary(performance) # part of {easystats}\nlibrary(janitor)\nlibrary(lme4)\nlibrary(knitr)\nlibrary(kableExtra)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Reporting</span>"
    ]
  },
  {
    "objectID": "chapters/reporting.html#inference-tests",
    "href": "chapters/reporting.html#inference-tests",
    "title": "10  Reporting",
    "section": "10.2 Inference tests",
    "text": "10.2 Inference tests\n\n10.2.1 Regressions\n\n\nCode\n# fit model\nmodel &lt;- lm(wt ~ 1 + am + mpg, data = mtcars)\n\n# report - text output (nb omits intercept!)\nreport(model)\n\n\nWe fitted a linear model (estimated using OLS) to predict wt with am and mpg\n(formula: wt ~ 1 + am + mpg). The model explains a statistically significant\nand substantial proportion of variance (R2 = 0.80, F(2, 29) = 57.66, p &lt; .001,\nadj. R2 = 0.79). The model's intercept, corresponding to am = 0 and mpg = 0, is\nat 5.74 (95% CI [5.11, 6.36], t(29) = 18.64, p &lt; .001). Within this model:\n\n  - The effect of am is statistically significant and negative (beta = -0.53, 95%\nCI [-0.94, -0.11], t(29) = -2.58, p = 0.015; Std. beta = -0.27, 95% CI [-0.48,\n-0.06])\n  - The effect of mpg is statistically significant and negative (beta = -0.11,\n95% CI [-0.15, -0.08], t(29) = -6.79, p &lt; .001; Std. beta = -0.71, 95% CI\n[-0.92, -0.49])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nCode\n# each parameter (including intercept)\nreport_parameters(model)\n\n\n  - The intercept is statistically significant and positive (beta = 5.74, 95% CI [5.11, 6.36], t(29) = 18.64, p &lt; .001; Std. beta = 1.10e-16, 95% CI [-0.17, 0.17])\n  - The effect of am is statistically significant and negative (beta = -0.53, 95% CI [-0.94, -0.11], t(29) = -2.58, p = 0.015; Std. beta = -0.27, 95% CI [-0.48, -0.06])\n  - The effect of mpg is statistically significant and negative (beta = -0.11, 95% CI [-0.15, -0.08], t(29) = -6.79, p &lt; .001; Std. beta = -0.71, 95% CI [-0.92, -0.49])\n\n\nCode\n# just parameters in text format\nreport_statistics(model)\n\n\nbeta = 5.74, 95% CI [5.11, 6.36], t(29) = 18.64, p &lt; .001; Std. beta = 1.10e-16, 95% CI [-0.17, 0.17]\nbeta = -0.53, 95% CI [-0.94, -0.11], t(29) = -2.58, p = 0.015; Std. beta = -0.27, 95% CI [-0.48, -0.06]\nbeta = -0.11, 95% CI [-0.15, -0.08], t(29) = -6.79, p &lt; .001; Std. beta = -0.71, 95% CI [-0.92, -0.49]\n\n\nCode\n# just parameters in table format\nparameters(model)\n\n\nParameter   | Coefficient |   SE |         95% CI | t(29) |      p\n------------------------------------------------------------------\n(Intercept) |        5.74 | 0.31 | [ 5.11,  6.36] | 18.64 | &lt; .001\nam          |       -0.53 | 0.20 | [-0.94, -0.11] | -2.58 | 0.015 \nmpg         |       -0.11 | 0.02 | [-0.15, -0.08] | -6.79 | &lt; .001\n\n\nCode\n# just parameters in table html format \nparameters(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\n\n\n\n\n(Intercept)\n5.74\n0.31\n0.95\n5.11\n6.36\n18.64\n29\np &lt; .001\n\n\nam\n-0.53\n0.20\n0.95\n-0.94\n-0.11\n-2.58\n29\np = 0.015\n\n\nmpg\n-0.11\n0.02\n0.95\n-0.15\n-0.08\n-6.79\n29\np &lt; .001\n\n\n\n\n\nCode\n# what if i just want some of these cols?\nparameters(model) |&gt;\n  as.data.frame() |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  select(r = Coefficient, ci_lower = CI_low, ci_upper = CI_high, p) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2)\n\n\n      r ci_lower ci_upper         p\n1  5.74     5.11     6.36  p &lt; .001\n2 -0.53    -0.94    -0.11 p = 0.015\n3 -0.11    -0.15    -0.08  p &lt; .001\n\n\nCode\n# table in markdown format\nreport_table(model)\n\n\nParameter   | Coefficient |         95% CI | t(29) |      p | Std. Coef.\n------------------------------------------------------------------------\n(Intercept) |        5.74 | [ 5.11,  6.36] | 18.64 | &lt; .001 |   1.10e-16\nam          |       -0.53 | [-0.94, -0.11] | -2.58 | 0.015  |      -0.27\nmpg         |       -0.11 | [-0.15, -0.08] | -6.79 | &lt; .001 |      -0.71\n            |             |                |       |        |           \nAIC         |             |                |       |        |           \nAICc        |             |                |       |        |           \nBIC         |             |                |       |        |           \nR2          |             |                |       |        |           \nR2 (adj.)   |             |                |       |        |           \nSigma       |             |                |       |        |           \n\nParameter   | Std. Coef. 95% CI |   Fit\n---------------------------------------\n(Intercept) |    [-0.17,  0.17] |      \nam          |    [-0.48, -0.06] |      \nmpg         |    [-0.92, -0.49] |      \n            |                   |      \nAIC         |                   | 45.05\nAICc        |                   | 46.53\nBIC         |                   | 50.91\nR2          |                   |  0.80\nR2 (adj.)   |                   |  0.79\nSigma       |                   |  0.45\n\n\nCode\n# table in html format - needs to be rounded manually\nreport_table(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\n\nParameter\nCoefficient\nCI\nCI_low\nCI_high\nt\ndf_error\np\nStd_Coefficient\nStd_Coefficient_CI_low\nStd_Coefficient_CI_high\nFit\n\n\n\n\n1\n(Intercept)\n5.74\n0.95\n5.11\n6.36\n18.64\n29\np &lt; .001\n0.00\n-0.17\n0.17\nNA\n\n\n2\nam\n-0.53\n0.95\n-0.94\n-0.11\n-2.58\n29\np = 0.015\n-0.27\n-0.48\n-0.06\nNA\n\n\n3\nmpg\n-0.11\n0.95\n-0.15\n-0.08\n-6.79\n29\np &lt; .001\n-0.71\n-0.92\n-0.49\nNA\n\n\n4\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\n\n\n5\nAIC\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n45.05\n\n\n6\nAICc\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n46.53\n\n\n7\nBIC\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n50.91\n\n\n8\nR2\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n0.80\n\n\n9\nR2 (adj.)\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n0.79\n\n\n11\nSigma\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n0.45\n\n\n\n\n\nCode\n# plot\nparameters(model) |&gt;\n  plot() \n\n\n\n\n\n\n\n\n\n\n\n10.2.2 Correlations\n\n10.2.2.1 Single correlation tests\n\n\nCode\n# fit model\nmodel &lt;- cor.test(mtcars$mpg, mtcars$wt)\n\n# report - text output \nreport(model)\n\n\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Pearson's product-moment correlation between mtcars$mpg and mtcars$wt is\nnegative, statistically significant, and very large (r = -0.87, 95% CI [-0.93,\n-0.74], t(30) = -9.56, p &lt; .001)\n\n\nCode\n# table in html format - needs to be rounded manually\nreport_table(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nAlternative\n\n\n\n\nmtcars$mpg\nmtcars$wt\n-0.87\n0.95\n-0.93\n-0.74\n-9.56\n30\np &lt; .001\nPearson's product-moment correlation\ntwo.sided\n\n\n\n\n\n\n\n10.2.2.2 Many\n\n\nCode\nresults &lt;- correlation(iris)\n\nresults\n\n\n# Correlation Matrix (pearson-method)\n\nParameter1   |   Parameter2 |     r |         95% CI | t(148) |         p\n-------------------------------------------------------------------------\nSepal.Length |  Sepal.Width | -0.12 | [-0.27,  0.04] |  -1.44 | 0.152    \nSepal.Length | Petal.Length |  0.87 | [ 0.83,  0.91] |  21.65 | &lt; .001***\nSepal.Length |  Petal.Width |  0.82 | [ 0.76,  0.86] |  17.30 | &lt; .001***\nSepal.Width  | Petal.Length | -0.43 | [-0.55, -0.29] |  -5.77 | &lt; .001***\nSepal.Width  |  Petal.Width | -0.37 | [-0.50, -0.22] |  -4.79 | &lt; .001***\nPetal.Length |  Petal.Width |  0.96 | [ 0.95,  0.97] |  43.39 | &lt; .001***\n\np-value adjustment method: Holm (1979)\nObservations: 150\n\n\nCode\nresults %&gt;%\n  summary(redundant = TRUE) %&gt;%\n  plot()\n\n\n\n\n\n\n\n\n\n\n\n10.2.2.3 By group\n\n\nCode\niris %&gt;%\n  select(Species, Sepal.Length, Sepal.Width, Petal.Width) %&gt;%\n  group_by(Species) %&gt;%\n  correlation()\n\n\n# Correlation Matrix (pearson-method)\n\nGroup      |   Parameter1 |  Parameter2 |    r |        95% CI | t(48) |         p\n----------------------------------------------------------------------------------\nsetosa     | Sepal.Length | Sepal.Width | 0.74 | [ 0.59, 0.85] |  7.68 | &lt; .001***\nsetosa     | Sepal.Length | Petal.Width | 0.28 | [ 0.00, 0.52] |  2.01 | 0.101    \nsetosa     |  Sepal.Width | Petal.Width | 0.23 | [-0.05, 0.48] |  1.66 | 0.104    \nversicolor | Sepal.Length | Sepal.Width | 0.53 | [ 0.29, 0.70] |  4.28 | &lt; .001***\nversicolor | Sepal.Length | Petal.Width | 0.55 | [ 0.32, 0.72] |  4.52 | &lt; .001***\nversicolor |  Sepal.Width | Petal.Width | 0.66 | [ 0.47, 0.80] |  6.15 | &lt; .001***\nvirginica  | Sepal.Length | Sepal.Width | 0.46 | [ 0.20, 0.65] |  3.56 | 0.002**  \nvirginica  | Sepal.Length | Petal.Width | 0.28 | [ 0.00, 0.52] |  2.03 | 0.048*   \nvirginica  |  Sepal.Width | Petal.Width | 0.54 | [ 0.31, 0.71] |  4.42 | &lt; .001***\n\np-value adjustment method: Holm (1979)\nObservations: 50\n\n\n\n\n\n10.2.3 t-tests\nNB Cohen’s d is approximated - better to calculate it separately and accurately.\n\n\nCode\n# fit model\nmodel &lt;- t.test(mpg ~ am, data = mtcars)\n\n# report - text output \nreport(model)\n\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference of mpg by am (mean in group\n0 = 17.15, mean in group 1 = 24.39) suggests that the effect is negative,\nstatistically significant, and large (difference = -7.24, 95% CI [-11.28,\n-3.21], t(18.33) = -3.77, p = 0.001; Cohen's d = -1.76, 95% CI [-2.82, -0.67])\n\n\nCode\n# table in html format - needs to be rounded manually\nreport_table(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nParameter\nGroup\nMean_Group1\nMean_Group2\nDifference\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nAlternative\nd\nd_CI_low\nd_CI_high\n\n\n\n\nmpg\nam\n17.15\n24.39\n-7.24\n0.95\n-11.28\n-3.21\n-3.77\n18.33\np = 0.001\nWelch Two Sample t-test\ntwo.sided\n-1.76\n-2.82\n-0.67\n\n\n\n\n\nCode\n# estimate Cohen's d directly from data\ncohens_d(mpg ~ am, data = mtcars)\n\n\nCohen's d |         95% CI\n--------------------------\n-1.48     | [-2.27, -0.67]\n\n- Estimated using pooled SD.\n\n\n\n\n10.2.4 Multilevel/hierarchical/mixed models\n\n\nCode\n# fit model\nmodel &lt;- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)\n\n# parameters in text format \nreport(model)\n\n\nWe fitted a linear mixed model (estimated using REML and nloptwrap optimizer)\nto predict Reaction with Days (formula: Reaction ~ Days). The model included\nDays as random effects (formula: ~Days | Subject). The model's total\nexplanatory power is substantial (conditional R2 = 0.80) and the part related\nto the fixed effects alone (marginal R2) is of 0.28. The model's intercept,\ncorresponding to Days = 0, is at 251.41 (95% CI [237.94, 264.87], t(174) =\n36.84, p &lt; .001). Within this model:\n\n  - The effect of Days is statistically significant and positive (beta = 10.47,\n95% CI [7.42, 13.52], t(174) = 6.77, p &lt; .001; Std. beta = 0.54, 95% CI [0.38,\n0.69])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nCode\n# parameters in table format\nparameters(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\nEffects\nGroup\n\n\n\n\n(Intercept)\n251.41\n6.82\n0.95\n237.94\n264.87\n36.84\n174\np &lt; .001\nfixed\n\n\n\nDays\n10.47\n1.55\n0.95\n7.42\n13.52\n6.77\n174\np &lt; .001\nfixed\n\n\n\nSD (Intercept)\n24.74\nNA\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\n\n\nSD (Days)\n5.92\nNA\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\n\n\nCor (Intercept~Days)\n0.07\nNA\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\n\n\nSD (Observations)\n25.59\nNA\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nResidual\n\n\n\n\n\nCode\n# table in html format - needs to be rounded manually\nreport_table(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\n\nParameter\nCoefficient\nCI\nCI_low\nCI_high\nt\ndf_error\np\nEffects\nGroup\nStd_Coefficient\nStd_Coefficient_CI_low\nStd_Coefficient_CI_high\nFit\n\n\n\n\n1\n(Intercept)\n251.41\n0.95\n237.94\n264.87\n36.84\n174\np &lt; .001\nfixed\n\n0.00\n-0.32\n0.32\nNA\n\n\n2\nDays\n10.47\n0.95\n7.42\n13.52\n6.77\n174\np &lt; .001\nfixed\n\n0.54\n0.38\n0.69\nNA\n\n\n3\nNA\n24.74\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\nNA\nNA\nNA\nNA\n\n\n4\nNA\n5.92\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\nNA\nNA\nNA\nNA\n\n\n5\nNA\n0.07\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\nNA\nNA\nNA\nNA\n\n\n6\nNA\n25.59\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nResidual\nNA\nNA\nNA\nNA\n\n\n7\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n8\nAIC\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n1755.63\n\n\n9\nAICc\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n1756.11\n\n\n10\nBIC\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n1774.79\n\n\n11\nR2 (conditional)\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n0.80\n\n\n12\nR2 (marginal)\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n0.28\n\n\n15\nSigma\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n25.59\n\n\n\n\n\nCode\n# plot\nparameters(model) |&gt;\n  plot() \n\n\n\n\n\n\n\n\n\nCode\n# check assumptions of random effects\nresult &lt;- check_normality(model, effects = \"random\")\nplot(result)\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n10.2.5 ANOVAs\n\n\nCode\n# fit model\nmodel &lt;- aov(mpg ~ factor(gear) + factor(carb), data = mtcars)\n\n# commonly used effect size: partial eta squared\neta_squared(model)\n\n\n# Effect Size for ANOVA (Type I)\n\nParameter    | Eta2 (partial) |       95% CI\n--------------------------------------------\nfactor(gear) |           0.69 | [0.49, 1.00]\nfactor(carb) |           0.66 | [0.41, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\nCode\n# better effect size: partialomega squared\nomega_squared(model)\n\n\n# Effect Size for ANOVA (Type I)\n\nParameter    | Omega2 (partial) |       95% CI\n----------------------------------------------\nfactor(gear) |             0.62 | [0.38, 1.00]\nfactor(carb) |             0.57 | [0.26, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Reporting</span>"
    ]
  },
  {
    "objectID": "chapters/reporting.html#summary-statistics",
    "href": "chapters/reporting.html#summary-statistics",
    "title": "10  Reporting",
    "section": "10.3 Summary statistics",
    "text": "10.3 Summary statistics\n\n\nCode\n# all columns\niris |&gt;\n  group_by(Species) |&gt;\n  report_table() \n\n\nGroup      |     Variable | n_Obs | Mean |   SD | Median |  MAD |  Min |  Max\n-----------------------------------------------------------------------------\nsetosa     | Sepal.Length |    50 | 5.01 | 0.35 |   5.00 | 0.30 | 4.30 | 5.80\nsetosa     |  Sepal.Width |    50 | 3.43 | 0.38 |   3.40 | 0.37 | 2.30 | 4.40\nsetosa     | Petal.Length |    50 | 1.46 | 0.17 |   1.50 | 0.15 | 1.00 | 1.90\nsetosa     |  Petal.Width |    50 | 0.25 | 0.11 |   0.20 | 0.00 | 0.10 | 0.60\nversicolor | Sepal.Length |    50 | 5.94 | 0.52 |   5.90 | 0.52 | 4.90 | 7.00\nversicolor |  Sepal.Width |    50 | 2.77 | 0.31 |   2.80 | 0.30 | 2.00 | 3.40\nversicolor | Petal.Length |    50 | 4.26 | 0.47 |   4.35 | 0.52 | 3.00 | 5.10\nversicolor |  Petal.Width |    50 | 1.33 | 0.20 |   1.30 | 0.22 | 1.00 | 1.80\nvirginica  | Sepal.Length |    50 | 6.59 | 0.64 |   6.50 | 0.59 | 4.90 | 7.90\nvirginica  |  Sepal.Width |    50 | 2.97 | 0.32 |   3.00 | 0.30 | 2.20 | 3.80\nvirginica  | Petal.Length |    50 | 5.55 | 0.55 |   5.55 | 0.67 | 4.50 | 6.90\nvirginica  |  Petal.Width |    50 | 2.03 | 0.27 |   2.00 | 0.30 | 1.40 | 2.50\n\nGroup      | Skewness | Kurtosis | n_Missing\n--------------------------------------------\nsetosa     |     0.12 |    -0.25 |         0\nsetosa     |     0.04 |     0.95 |         0\nsetosa     |     0.11 |     1.02 |         0\nsetosa     |     1.25 |     1.72 |         0\nversicolor |     0.11 |    -0.53 |         0\nversicolor |    -0.36 |    -0.37 |         0\nversicolor |    -0.61 |     0.05 |         0\nversicolor |    -0.03 |    -0.41 |         0\nvirginica  |     0.12 |     0.03 |         0\nvirginica  |     0.37 |     0.71 |         0\nvirginica  |     0.55 |    -0.15 |         0\nvirginica  |    -0.13 |    -0.60 |         0\n\n\nCode\n# all columns - html output with rounding\niris |&gt;\n  group_by(Species) |&gt;\n  report_table() |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nGroup\nVariable\nn_Obs\nMean\nSD\nMedian\nMAD\nMin\nMax\nSkewness\nKurtosis\nn_Missing\n\n\n\n\nsetosa\nSepal.Length\n50\n5.01\n0.35\n5.00\n0.30\n4.3\n5.8\n0.12\n-0.25\n0\n\n\nsetosa\nSepal.Width\n50\n3.43\n0.38\n3.40\n0.37\n2.3\n4.4\n0.04\n0.95\n0\n\n\nsetosa\nPetal.Length\n50\n1.46\n0.17\n1.50\n0.15\n1.0\n1.9\n0.11\n1.02\n0\n\n\nsetosa\nPetal.Width\n50\n0.25\n0.11\n0.20\n0.00\n0.1\n0.6\n1.25\n1.72\n0\n\n\nversicolor\nSepal.Length\n50\n5.94\n0.52\n5.90\n0.52\n4.9\n7.0\n0.11\n-0.53\n0\n\n\nversicolor\nSepal.Width\n50\n2.77\n0.31\n2.80\n0.30\n2.0\n3.4\n-0.36\n-0.37\n0\n\n\nversicolor\nPetal.Length\n50\n4.26\n0.47\n4.35\n0.52\n3.0\n5.1\n-0.61\n0.05\n0\n\n\nversicolor\nPetal.Width\n50\n1.33\n0.20\n1.30\n0.22\n1.0\n1.8\n-0.03\n-0.41\n0\n\n\nvirginica\nSepal.Length\n50\n6.59\n0.64\n6.50\n0.59\n4.9\n7.9\n0.12\n0.03\n0\n\n\nvirginica\nSepal.Width\n50\n2.97\n0.32\n3.00\n0.30\n2.2\n3.8\n0.37\n0.71\n0\n\n\nvirginica\nPetal.Length\n50\n5.55\n0.55\n5.55\n0.67\n4.5\n6.9\n0.55\n-0.15\n0\n\n\nvirginica\nPetal.Width\n50\n2.03\n0.27\n2.00\n0.30\n1.4\n2.5\n-0.13\n-0.60\n0\n\n\n\n\n\nCode\n# subset of columns\niris |&gt;\n  group_by(Species) |&gt;\n  report_table() |&gt;\n  select(Group, Variable, n_Obs, Mean, SD) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nGroup\nVariable\nn_Obs\nMean\nSD\n\n\n\n\nsetosa\nSepal.Length\n50\n5.01\n0.35\n\n\nsetosa\nSepal.Width\n50\n3.43\n0.38\n\n\nsetosa\nPetal.Length\n50\n1.46\n0.17\n\n\nsetosa\nPetal.Width\n50\n0.25\n0.11\n\n\nversicolor\nSepal.Length\n50\n5.94\n0.52\n\n\nversicolor\nSepal.Width\n50\n2.77\n0.31\n\n\nversicolor\nPetal.Length\n50\n4.26\n0.47\n\n\nversicolor\nPetal.Width\n50\n1.33\n0.20\n\n\nvirginica\nSepal.Length\n50\n6.59\n0.64\n\n\nvirginica\nSepal.Width\n50\n2.97\n0.32\n\n\nvirginica\nPetal.Length\n50\n5.55\n0.55\n\n\nvirginica\nPetal.Width\n50\n2.03\n0.27",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Reporting</span>"
    ]
  },
  {
    "objectID": "chapters/reporting.html#assumption-checks",
    "href": "chapters/reporting.html#assumption-checks",
    "title": "10  Reporting",
    "section": "10.4 Assumption checks",
    "text": "10.4 Assumption checks\nBeware that checking assumptions can lead to as many bad practices as it does good ones! (e.g., poorly justified post hoc outlier exclusion)\n\n10.4.1 Multiple checks at once\n\n\nCode\n# fit model\nmodel &lt;- lm(wt ~ 1 + am + mpg, data = mtcars)\n\n# check multiple model assumptions\ncheck_model(model)\n\n\n\n\n\n\n\n\n\n\n\n10.4.2 Normality of distribution of residuals\n\n\nCode\nres_normality &lt;- check_normality(model)\n\nres_normality\n\n\nWarning: Non-normality of residuals detected (p = 0.013).\n\n\nCode\nplot(res_normality, type = \"qq\")\n\n\n\n\n\n\n\n\n\nCode\nplot(res_normality, type = \"density\")\n\n\n\n\n\n\n\n\n\n\n\n10.4.3 Multicolinearity\n\n\nCode\nres_collinearity &lt;- check_collinearity(model)\n\nres_collinearity\n\n\n# Check for Multicollinearity\n\nLow Correlation\n\n Term  VIF   VIF 95% CI adj. VIF Tolerance Tolerance 95% CI\n   am 1.56 [1.19, 2.68]     1.25      0.64     [0.37, 0.84]\n  mpg 1.56 [1.19, 2.68]     1.25      0.64     [0.37, 0.84]\n\n\nCode\nplot(res_collinearity)\n\n\n\n\n\n\n\n\n\n\n\n10.4.4 Outliers\n\n\nCode\nres_outliers &lt;- check_outliers(model, method = \"cook\") # \"all\" requires other dependencies and can take some time to run  \n#res_outliers &lt;- check_outliers(model, method = \"all\") # \"all\" requires other dependencies and can take some time to run  \n\nres_outliers\n\n\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.808).\n- For variable: (Whole model)\n\n\nCode\nplot(res_outliers)\n\n\n\n\n\n\n\n\n\n\n\n10.4.5 Heteroscedasticity\n\n\nCode\nres_het &lt;- check_heteroscedasticity(model)\n\nres_het\n\n\nOK: Error variance appears to be homoscedastic (p = 0.053).\n\n\nCode\nplot(res_het)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Reporting</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html",
    "href": "chapters/visualization.html",
    "title": "10  Visualization",
    "section": "",
    "text": "11 Dependencies\nCode\nlibrary(readr)\nlibrary(ggplot2)\n# install.packages(\"datasauRus\")\nlibrary(datasauRus) \nlibrary(scales)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(plotrix) \n\n# install.packages(\"devtools\")\n# devtools::install_github(\"matthewbjane/ThemePark\")\nlibrary(ThemePark)\nlibrary(patchwork)\nlibrary(janitor)\nlibrary(knitr)\nlibrary(kableExtra)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#simple-plot-for-self-reports",
    "href": "chapters/visualization.html#simple-plot-for-self-reports",
    "title": "10  Visualization",
    "section": "14.1 Simple plot for self-reports",
    "text": "14.1 Simple plot for self-reports\n\n\nCode\nggplot(data = data_after_exclusions,\n       aes(x = mean_self_report)) +\n  geom_histogram(binwidth = 1)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#slightly-better-plot-for-self-reports",
    "href": "chapters/visualization.html#slightly-better-plot-for-self-reports",
    "title": "10  Visualization",
    "section": "14.2 Slightly better plot for self-reports",
    "text": "14.2 Slightly better plot for self-reports\n\n\nCode\nggplot(data = data_after_exclusions,\n       aes(x = mean_self_report)) +\n  # more intelligent choices for the binwidth and boundary\n  geom_histogram(binwidth = 1, boundary = 0.5) +\n  # labeling of the axis points\n  scale_x_continuous(breaks = scales::breaks_pretty(n = 7),\n                     limits = c(0.5, 7.5)) +\n  scale_y_continuous(breaks = seq(0, 60, 10)) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#exercise-plot-for-gender",
    "href": "chapters/visualization.html#exercise-plot-for-gender",
    "title": "10  Visualization",
    "section": "14.3 Exercise: Plot for gender",
    "text": "14.3 Exercise: Plot for gender\nCreate a similar plot for the gender variable in data_processed (ie before exclusions).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#exercise-plot-for-amp",
    "href": "chapters/visualization.html#exercise-plot-for-amp",
    "title": "10  Visualization",
    "section": "14.4 Exercise: Plot for AMP",
    "text": "14.4 Exercise: Plot for AMP\nCreate a similar plot for the AMP scores in data_after_exclusions.\n\n\nCode\nmean_amp &lt;- data_after_exclusions |&gt;\n  summarize(mean_amp = mean(amp_score)) |&gt;\n  pull(mean_amp)\n\n\nplot_amp &lt;- \n  ggplot(data = data_after_exclusions,\n         aes(x = amp_score)) +\n  geom_histogram(binwidth = 0.1) +\n  scale_x_continuous(breaks = seq(0, 1, .10),\n                     name = \"AMP score\") +\n  scale_y_continuous(breaks = seq(0, 40, 5),\n                     name = \"Frequency\") +\n  geom_vline(xintercept = mean_amp, linetype = \"dotted\") +\n  theme_linedraw()\n\nplot_amp\n\n\n\n\n\n\n\n\n\nCode\nggsave(plot = plot_amp,\n       filename = \"plots/plot_amp.pdf\", \n       width = 6,\n       height = 5)\n\n\n\nExercise: How to add a dashed vertical line at the sample’s mean AMP score?",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#simple-plot-for-self-reports-1",
    "href": "chapters/visualization.html#simple-plot-for-self-reports-1",
    "title": "10  Visualization",
    "section": "15.1 Simple plot for self-reports",
    "text": "15.1 Simple plot for self-reports\n\n\nCode\nggplot(data = data_after_exclusions,\n       aes(x = mean_self_report)) +\n  geom_density(adjust = 1, # the degree of smoothing can be adjusted here \n               color = \"#FF69B4\",\n               fill = \"darkblue\", \n               alpha = 0.3) +\n  # labeling of the axis points\n  scale_x_continuous(breaks = scales::breaks_pretty(n = 7),\n                     limits = c(1, 7)) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#exercise-plot-for-amp-1",
    "href": "chapters/visualization.html#exercise-plot-for-amp-1",
    "title": "10  Visualization",
    "section": "15.2 Exercise: Plot for AMP",
    "text": "15.2 Exercise: Plot for AMP\nMake a similar density plot for the AMP.\n\nAdd a theme.\nMake the X axis breaks prettier.\nName both axis names more clearly.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#simple-plot-for-amp",
    "href": "chapters/visualization.html#simple-plot-for-amp",
    "title": "10  Visualization",
    "section": "16.1 Simple plot for AMP",
    "text": "16.1 Simple plot for AMP\n\n\nCode\n# create the summary values to be plotted\nsummary_amp &lt;- data_after_exclusions %&gt;%\n  group_by(gender) %&gt;%\n  summarize(amp_mean = mean(amp_score),\n            amp_se = plotrix::std.error(amp_score))\n\n# plot these values\nggplot(data = summary_amp, \n       aes(x = gender, \n           y = amp_mean)) +\n  geom_col() +\n  # geom_bar(stat = \"identity\") + # NB geom_col is equivalent to geom_bar when stat == \"identity\n  geom_linerange(aes(ymin = amp_mean - amp_se, \n                     ymax = amp_mean + amp_se))",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#slightly-better-plot-for-amp",
    "href": "chapters/visualization.html#slightly-better-plot-for-amp",
    "title": "10  Visualization",
    "section": "16.2 Slightly better plot for AMP",
    "text": "16.2 Slightly better plot for AMP\n\n\nCode\nggplot(data = summary_amp, \n       aes(x = gender, \n           y = amp_mean)) +\n  geom_col(fill = \"#0b6623\", # note that you can specify specific colors using hex codes or names\n           color = \"black\", \n           width = 0.6) +\n  geom_errorbar(aes(ymin = amp_mean - amp_se, \n                    ymax = amp_mean + amp_se), \n                width = 0.1, \n                color = \"black\") +\n  labs(title = \"Bar Plot of with Standard Errors\",\n       x = \"Gender\",\n       y = \"Mean AMP score\") +\n  theme_linedraw()",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#exercise-plot-for-self-reports",
    "href": "chapters/visualization.html#exercise-plot-for-self-reports",
    "title": "10  Visualization",
    "section": "16.3 Exercise: Plot for self-reports",
    "text": "16.3 Exercise: Plot for self-reports\nMake a similar plot for the self-reports.\n\nUse coord_flip() to swap the X and Y axes.\n\n\nExercise: How to capitalize ‘Male’ and ‘Female’ by wrangling the data before plotting?",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#exercise",
    "href": "chapters/visualization.html#exercise",
    "title": "10  Visualization",
    "section": "18.1 Exercise",
    "text": "18.1 Exercise\nCreate a plot that assesses the association between self report scores and AMP scores. By wrangling data_processed more prior to plotting, and using facet_grid(), compare a) men vs women and b) participants who are 30+ years old vs younger than 30.\nImprove the appearance of the plot, including its text, colors, theme, etc.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/license.html",
    "href": "chapters/license.html",
    "title": "11  License and citation",
    "section": "",
    "text": "© Ian Hussey (2025)\nText and figures are licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) license.\nCode is licensed under the MIT License.\nYou are free to copy, share, adapt, and reuse the contents of this book — text, figures, and code — for any purpose, including commercial use, provided you cite it.\nSuggested citation:\nHussey, I. (2025) Reproducible data processing and visualization in R and tidyverse. https://github.com/ianhussey/reproducible-data-processing-and-visualization-in-r",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>License and citation</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html#automatic-renaming-with-janitorclean_names",
    "href": "chapters/the_pipe_and_renaming.html#automatic-renaming-with-janitorclean_names",
    "title": "6  The pipe and renaming",
    "section": "6.5 Automatic renaming with janitor::clean_names()",
    "text": "6.5 Automatic renaming with janitor::clean_names()\nCleaning names is such a common task that there are functions that rename all columns in a dataset at once, such as janitor::clean_names().\nHowever, clean_names() can only rename to a standard naming convention and remove problematic characters, it can’t choose meaningful variable names.\n\n\nCode\nlibrary(janitor) # for clean_names()\n\ndat_demographics_renamed &lt;- dat_demographics_raw %&gt;%\n  clean_names()\n\ndat_demographics_renamed %&gt;%\n  head() %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nsubject_code\nbuild\nblock_code_and_trial_number\ntrial_code\nkey_response_use_this\ncorrect\nx0_ms_onset_rt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n\n\n\nIt’s still very useful as part of a tidy workflow:\n\n\nCode\n# code you might write to help you write the final varsion below\ndat_demographics_temp &lt;- dat_demographics_raw %&gt;%\n  clean_names()\n\ndat_demographics_temp %&gt;%\n  colnames() %&gt;%\n  dput()\n\n\nc(\"date\", \"subject_code\", \"build\", \"block_code_and_trial_number\", \n\"trial_code\", \"key_response_use_this\", \"correct\", \"x0_ms_onset_rt\"\n)\n\n\nCode\n# final working version\ndat_demographics_renamed &lt;- dat_demographics_raw %&gt;%\n  clean_names() %&gt;%\n  rename(id = subject_code, \n         block_trial = block_code_and_trial_number, \n         question = trial_code, \n         response = key_response_use_this, \n         rt = x0_ms_onset_rt)\n\ndat_demographics_renamed %&gt;%\n  head() %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nid\nbuild\nblock_trial\nquestion\nresponse\ncorrect\nrt\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The pipe and renaming</span>"
    ]
  },
  {
    "objectID": "chapters/the_linear_model.html",
    "href": "chapters/the_linear_model.html",
    "title": "11  Understanding (almost) everything as a Linear Model",
    "section": "",
    "text": "TODO\nEase of reporting via automated reported has to be strongly balanced against thorough understanding of the models themselves.\n\nlinear model\n(almost) everything is a linear model\n\neven means and SDs\neven correlations\neven named tests\neven CFA and path analysis",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Understanding (almost) everything as a Linear Model</span>"
    ]
  },
  {
    "objectID": "chapters/the_pipe_and_renaming.html#exploring-column-names-and-rows",
    "href": "chapters/the_pipe_and_renaming.html#exploring-column-names-and-rows",
    "title": "6  The pipe and renaming",
    "section": "",
    "text": "Click to show answer\n\n\n\n\n\n\n\nCode\ndat_demographics_raw &lt;- read_csv(file = \"../data/raw/data_demographics_raw_messy.csv\", \n                                 skip = 2) # add skip = 2 to ignore the first two lines\n\nhead(dat_demographics_raw) %&gt;%\n  kable() %&gt;%\n  kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\nSubject Code\nbuild\nblock code and trial number\nTrial Code\nKey response (use this!)\ncorrect\n0 ms onset RT\n\n\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\nage\n23\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\ngender\nfemale\n1\n619\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_2\npsychiatric diagnosis\nschizophrenia\n1\n1372\n\n\n23.06.2022\n548957868\n06.06.2000\ndemographics_3\nprolific ID\nasldkjaao87809\n1\n619\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_2\nage\n48\n1\n3946\n\n\n23.06.2022\n504546409\n06.06.2000\ndemographics_3\ngender\nyes\n1\n3724\n\n\n\n\n\n\n\n\n\n6.1.1 Count rows and columns with nrow() and ncol()\nProcessing and cleaning any data set requires an understanding what it contains - as well as a thorough understanding of how the data was generated (e.g., the study’s design and specific implementation; what rows represent what measurement and in what way, etc.).\nA rudimentary but important step to understanding what a data set contains is to know how many rows and columns it contains.\nThis is useful to check at multiple steps of your data processing to make sure you have not done something wrong by gaining or losing columns or rows that you should not.\nNumber of rows:\n\n\nCode\nnrow(dat_demographics_raw)\n\n\n[1] 16\n\n\nNumber of columns:\n\n\nCode\nncol(dat_demographics_raw)\n\n\n[1] 8\n\n\n\n\n6.1.2 Viewing column names with colnames()\nHow would you know what variables are in a data frame? You can view the data frame, but it can also be useful to print them. Knowing what you have is one of the first steps to working with it.\n\n\nCode\ncolnames(dat_demographics_raw)\n\n\n[1] \"date\"                        \"Subject Code\"               \n[3] \"build\"                       \"block code and trial number\"\n[5] \"Trial Code\"                  \"Key response (use this!)\"   \n[7] \"correct\"                     \"0 ms onset RT\"              \n\n\nLater, when you’re used to using functions such as rename() and mutate(), you will often want a vector of column names that you can easily copy-paste into code, without all the extra white-space and including commas between them. For this, you can use dput():\n\n\nCode\ndput(colnames(dat_demographics_raw))\n\n\nc(\"date\", \"Subject Code\", \"build\", \"block code and trial number\", \n\"Trial Code\", \"Key response (use this!)\", \"correct\", \"0 ms onset RT\"\n)\n\n\nThis takes the output of colnames() and applies dput() to it. When your data processing calls muliple functions in a row, this could get complicated to read and write. It’s therefore time to introduce ‘the pipe’.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The pipe and renaming</span>"
    ]
  },
  {
    "objectID": "chapters/structuring_projects.html",
    "href": "chapters/structuring_projects.html",
    "title": "4  Structuring projects",
    "section": "",
    "text": "4.1 psych-DS\nhttps://psych-ds.github.io",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Structuring projects</span>"
    ]
  },
  {
    "objectID": "chapters/structuring_projects.html#psych-ds",
    "href": "chapters/structuring_projects.html#psych-ds",
    "title": "4  Structuring projects",
    "section": "",
    "text": "github_repository_name/\n├── code/\n│   ├── analysis.qmd\n│   └── processing.qmd\n├── communications/\n│   ├── preprint/\n│   │   └── preprint.docx\n│   └── presentations/\n│       └── conference_presentation.pptx\n├── dataset_description.json\n├── data/\n│   ├── processed/\n│   │   ├── study_1_processed_data.csv\n│   │   ├── study_1_processed_codebook.xlsx\n│   │   ├── study_2_processed_data.csv\n│   │   └── study_2_processed_codebook.xlsx\n│   └── raw/\n│       ├── study_1_raw_behavioraltask_data.csv\n│       ├── study_2_raw_behavioraltask_data.csv\n│       ├── study_1_raw_codebook.xlsx\n│       ├── study_2_raw_codebook.xlsx\n│       ├── study_1_raw_demographics_data.csv\n│       ├── study_2_raw_demographics_data.csv\n│       ├── study_1_raw_selfreports_data.csv\n│       └── study_2_raw_selfreports_data.csv\n├── license\n├── methods/\n│   ├── instructions.docx\n│   ├── study_1/\n│   │   └── study_1_labjs.json\n│   └── study_2/\n│       └── study_2_labjs.json\n└── readme.md",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Structuring projects</span>"
    ]
  },
  {
    "objectID": "chapters/structuring_projects.html#github",
    "href": "chapters/structuring_projects.html#github",
    "title": "4  Structuring projects",
    "section": "4.2 GitHub",
    "text": "4.2 GitHub\nhttps://ui-research.github.io/reproducibility-at-urban/git-overview.html",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Structuring projects</span>"
    ]
  }
]