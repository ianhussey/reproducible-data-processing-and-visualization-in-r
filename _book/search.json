[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reproducible Data Processing and Visualization",
    "section": "",
    "text": "Introduction\nThis e-book provides materials for the course “Reproducible Data Processing and Visualization in R”, delivered by Psychology of Digitalisation research group at at the University of Bern Institute of Psychology.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/learning_resources.html",
    "href": "chapters/learning_resources.html",
    "title": "1  Other learning resources",
    "section": "",
    "text": "You can find cheatsheets in the /resources folder [add link]\nThe Open Source textbook R for Data Science (aka, Wickham’s R4DS) is invaluable. Hadley Wickham is the main developer of the “tidyverse” set of packages, including dplyr, tidyr, ggplot2, stringr, lubridate, and others. See its section on data transformation.\n\nThe entire second edition of the book is available at https://r4ds.hadley.nz/.\nThe first edition is also available. It does some things better in my opinion, e.g., it has a better explanation of the pipe (%&gt;% or |&gt;). See https://r4ds.had.co.nz/pipes.html.\nThe first edition also talks about RMarkdown, whereas the second edition has moved to a different technology called Quarto (which we won’t cover, although they’re similar). See https://r4ds.had.co.nz/r-markdown.html.\n\nFor people who prefer to learn in an interactive environment, I suggest this web app: https://allisonhorst.shinyapps.io/dplyr-learnr/#section-welcome.\nFor people who prefer some video content - although seeing other people code can never replace practicing coding yourself! - I can also recommend De Bruine et al.’s Open Source textbook and videos Data Skills for Reproducible Research. E.g., see their page with links to videos for dplyr and tidyr.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Other learning resources</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html",
    "href": "chapters/fundamentals.html",
    "title": "2  Fundamentals",
    "section": "",
    "text": "2.1 RStudio settings\nFor reproducibility, please ensure RStudio’s settings never save the objects in your environment to disk on exist or load them again when opening RStudio. Open the Tools&gt;Global Options menu, go to General, and untick the following box and set save to ‘Never’.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#assignment-of-objects",
    "href": "chapters/fundamentals.html#assignment-of-objects",
    "title": "2  Fundamentals",
    "section": "2.5 Assignment of objects",
    "text": "2.5 Assignment of objects\nAssignment of objects is done via &lt;- by convention.\n\n\nCode\nx &lt;- 5\nx\n\n\n[1] 5\n\n\nTechnically you can also use =, but it’s best to avoid it.\n\n\nCode\ny = \"hello\"\ny\n\n\n[1] \"hello\"\n\n\nIt’s somewhat less well known, but you can also do “right-assignment” (-&gt;) instead of the much more common left assignment (&lt;-).\n\n\nCode\n\"really? yes.\" -&gt; z\nz\n\n\n[1] \"really? yes.\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#how-to-access-help-menu",
    "href": "chapters/fundamentals.html#how-to-access-help-menu",
    "title": "2  Fundamentals",
    "section": "2.4 How to access help menu",
    "text": "2.4 How to access help menu\nFor any function in a loaded package, simply type ? before the function’s name to call up the help menu. This helps you understand the function’s purpose, its arguments, and outputs.\n\n\nCode\n?read_csv\n\n\n\nWhy use {reader}’s read_csv() over the base R read.csv()? Because read_csv() is more explicit about what assumption it is making about column types, and prints warning messages about what it has assumed.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#rounding-round-probably-doesnt-do-what-you-think",
    "href": "chapters/fundamentals.html#rounding-round-probably-doesnt-do-what-you-think",
    "title": "2  Fundamentals",
    "section": "2.6 Rounding: round() probably doesn’t do what you think",
    "text": "2.6 Rounding: round() probably doesn’t do what you think\nDid you know that R doesn’t use the rounding method most of us are taught in school, where .5 is rounded up to the next integer? Instead it uses “banker’s rounding”, which is better when you round a very large number of numbers, but worse for reporting the results of specific analyses.\nThis is easier to show than explain. What do you expect the output of the below chunk to be? And what is the actual output?\n\n\nCode\nround(c(0.5, \n        1.5, \n        2.5, \n        3.5, \n        4.5, \n        5.5))\n\n\n[1] 0 2 2 4 4 6\n\n\nIn most of your R scripts, you should probably instead use janitor::round_half_up():\n\n\nCode\nlibrary(janitor)\n\njanitor::round_half_up(c(0.5, \n                         1.5, \n                         2.5, \n                         3.5, \n                         4.5, \n                         5.5))\n\n\n[1] 1 2 3 4 5 6\n\n\nor roundwork::round_up(0.5):\n\n\nCode\nlibrary(roundwork) \n\nroundwork::round_up(c(0.5, \n                      1.5, \n                      2.5, \n                      3.5, \n                      4.5, \n                      5.5))\n\n\n[1] 1 2 3 4 5 6",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#rstudio-shortcuts",
    "href": "chapters/fundamentals.html#rstudio-shortcuts",
    "title": "2  Fundamentals",
    "section": "2.7 RStudio shortcuts",
    "text": "2.7 RStudio shortcuts\nLater chapters describe chunks, pipes, etc. For the moment, know that there are shortcuts for them:\nWindows\n\nInsert Chunk: Ctrl + Alt + I\nInsert Pipe (|&gt;): shift + Ctrl + M\nMulti-line typing: Alt + Mouse click-and-drag, then type\nFix Indentation: Select Text + Ctrl + I\nComment out (#) multiple Lines: Mouse click-and-drag multiple lines, then Shift + Ctrl + C\n\nMac\n\nInsert Chunk: Cmd + Alt + I\nInsert Pipe (|&gt;): shift + Cmd + M\nMulti-line typing: Alt + Mouse click-and-drag, then type\nFix Indentation: Select Text + Cmd + I\nComment out (#) multiple Lines: Mouse click-and-drag multiple lines, then Shift + Cmd + C",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html",
    "href": "chapters/reproducible_reports.html",
    "title": "3  Reproducible reports",
    "section": "",
    "text": "3.1 Literature programming and code chunks\nLiterate programming is the idea that code and text should be written in the same document to produce a narrative with reproducible results. It is therefore very suited to writing scientific reports and manuscripts.\nCode can be written in ‘in line’ in the text as follows: 2. In the RMarkdown document, you have hover over the in line code and press enter or return to run the code.\nYou can also write it in chunks:\nCode\n2+2\n\n\n[1] 4\nOutput appears below chunks. You can run all code in a chunk by clicking the right-arrow button to the right of the chunk. You can also run all previous chunks in a document not including the current chunk by clicking the downward arrow button to the right of the chunk.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#math-via-latex",
    "href": "chapters/reproducible_reports.html#math-via-latex",
    "title": "3  Reproducible reports",
    "section": "3.2 Math via LaTeX",
    "text": "3.2 Math via LaTeX\nYou can include math in line with LaTeX code placed between dollar signs: e.g., “\\(\\eta_{p}^{2}\\) = 0.03”.\nYou can also write longer chunks of LaTeX, for example to specify that the mean (\\(\\bar{x}\\)) is the sum of all elements of the vector \\(x\\) divided by number of elements in the vector (\\(n\\)).\nThis code:\n$$\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i.\n$$\nProduces this math:\n\\[\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#source-versus-visual-editor",
    "href": "chapters/reproducible_reports.html#source-versus-visual-editor",
    "title": "3  Reproducible reports",
    "section": "3.3 Source versus Visual editor",
    "text": "3.3 Source versus Visual editor",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#knitingrendering-and-reproducibilty",
    "href": "chapters/reproducible_reports.html#knitingrendering-and-reproducibilty",
    "title": "3  Reproducible reports",
    "section": "3.4 kniting/rendering and reproducibilty",
    "text": "3.4 kniting/rendering and reproducibilty",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_reports.html#levels-of-heading",
    "href": "chapters/reproducible_reports.html#levels-of-heading",
    "title": "3  Reproducible reports",
    "section": "3.5 Levels of heading",
    "text": "3.5 Levels of heading",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reproducible reports</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html",
    "href": "chapters/loading_data.html",
    "title": "4  Fundamentals",
    "section": "",
    "text": "4.1 Dependencies\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(janitor) # for clean_names() and round_half_up()\nlibrary(roundwork) # for round_up()\nlibrary(stringr)\nlibrary(knitr) # for kable()\nlibrary(kableExtra) # for kable_classic()\nlibrary(readxl) # for read_excel()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading data</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#loading-data",
    "href": "chapters/loading_data.html#loading-data",
    "title": "4  Fundamentals",
    "section": "4.2 Loading data",
    "text": "4.2 Loading data\n\n4.2.1 Relative vs. absolute paths\nThis data comes from a real study on implicit and self-reported evaluations. The implementation of the procedure produced three data files: one for the demographics data, one for the self-reported evaluations, and one for the implicit measure (the ‘Affect Misattribution Procedure’). This script uses each of these to learn and practice functions from the readr, dplyr, and tidyr libraries that are commonly used for data wrangling. In doing so, we will learn how to do many of the steps involved in data processing for a given experiment.\n\n4.2.1.1 Avoid using setwd()\nadd explainer - breaks between machines, breaks between mac and windows\n\n\nCode\n# \\TODO \n\n\n\n\n4.2.1.2 Use relative paths\nEither through Rmarkdown files, Quarto files, or in regular .R files using the {here} library (see https://here.r-lib.org/).\n\n\nCode\n# demographics data\ndata_demographics_raw &lt;- read_csv(file = \"../data/raw/data_demographics_raw.csv\") \n\n# self report measure data\ndata_selfreport_raw &lt;- read_csv(file = \"../data/raw/data_selfreport_raw.csv\") \n\n# affect attribution procedure data\ndata_amp_raw &lt;- read_csv(file = \"../data/raw/data_amp_raw.csv\")\n\n\n\n\n\n4.2.2 Reading other file formats\nExcel, SPSS, and other file formats can also be loaded. There are several packages available to load Excel files in particular. Any of them are fine except library(xlsx) which requires you to install rJava, which often causes compatibility issues. library(readxl) is a safer bet.\n\n\nCode\ndat_likert_1 &lt;- readxl::read_excel(\"../data/raw/data_likert.xlsx\", sheet = \"data1\")\n\n# print the object\ndat_likert_1\n\n\n# A tibble: 13 × 5\n   `Date created: 02/04/2024` ...2  ...3    ...4     ...5    \n   &lt;chr&gt;                      &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;   \n 1 subset: sample 1           &lt;NA&gt;  &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;    \n 2 &lt;NA&gt;                       &lt;NA&gt;  &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;    \n 3 date                       group subject likert_1 likert_2\n 4 44735                      1     1       1        4       \n 5 44735                      2     2       3        3       \n 6 44735                      2     3       2        1       \n 7 44735                      1     4       5        5       \n 8 44735                      1     5       3        3       \n 9 44735                      2     6       2        1       \n10 44735                      1     7       2        1       \n11 44735                      1     8       1        3       \n12 44735                      1     9       2        5       \n13 44735                      2     10      5        2       \n\n\n\n\n4.2.3 Preserving the raw data / skipping rows\nWith a few exceptions (e.g., removing identifying information before making data public), you should not manually modify raw data.\nSometimes extra rows etc. make a data file harder to read into R. Handle with with code, not by deleting the information in those rows.\n\n\nCode\n# use skip parameter to skip rows\ndat_likert_1 &lt;- readxl::read_excel(\"../data/raw/data_likert.xlsx\", sheet = \"data1\", skip = 3)\n\ndat_likert_1\n\n\n# A tibble: 10 × 5\n   date                group subject likert_1 likert_2\n   &lt;dttm&gt;              &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 2022-06-23 00:00:00     1       1        1        4\n 2 2022-06-23 00:00:00     2       2        3        3\n 3 2022-06-23 00:00:00     2       3        2        1\n 4 2022-06-23 00:00:00     1       4        5        5\n 5 2022-06-23 00:00:00     1       5        3        3\n 6 2022-06-23 00:00:00     2       6        2        1\n 7 2022-06-23 00:00:00     1       7        2        1\n 8 2022-06-23 00:00:00     1       8        1        3\n 9 2022-06-23 00:00:00     1       9        2        5\n10 2022-06-23 00:00:00     2      10        5        2\n\n\n\n\n4.2.4 Combining multiple data sets\nCombining multiple data sets with (nearly) the same structure using bind_rows()\n\n\nCode\ndat_likert_1 &lt;- readxl::read_excel(\"../data/raw/data_likert.xlsx\", sheet = \"data1\", skip = 3)\ndat_likert_2 &lt;- readxl::read_excel(\"../data/raw/data_likert.xlsx\", sheet = \"data2\", skip = 3)\n\ndat_likert &lt;- bind_rows(dat_likert_1,\n                        dat_likert_2)\n\ndat_likert\n\n\n# A tibble: 20 × 5\n   date                group subject likert_1 likert_2\n   &lt;dttm&gt;              &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 2022-06-23 00:00:00     1       1        1        4\n 2 2022-06-23 00:00:00     2       2        3        3\n 3 2022-06-23 00:00:00     2       3        2        1\n 4 2022-06-23 00:00:00     1       4        5        5\n 5 2022-06-23 00:00:00     1       5        3        3\n 6 2022-06-23 00:00:00     2       6        2        1\n 7 2022-06-23 00:00:00     1       7        2        1\n 8 2022-06-23 00:00:00     1       8        1        3\n 9 2022-06-23 00:00:00     1       9        2        5\n10 2022-06-23 00:00:00     2      10        5        2\n11 2022-06-23 00:00:00     1      11        1       NA\n12 2022-06-23 00:00:00     2      12        3       NA\n13 2022-06-23 00:00:00     2      13        2       NA\n14 2022-06-23 00:00:00     1      14        5       NA\n15 2022-06-23 00:00:00     1      15        3       NA\n16 2022-06-23 00:00:00     2      16        2       NA\n17 2022-06-23 00:00:00     1      17        2       NA\n18 2022-06-23 00:00:00     1      18        1       NA\n19 2022-06-23 00:00:00     1      19        2       NA\n20 2022-06-23 00:00:00     2      20        5       NA\n\n\n\n\n4.2.5 Reading multiple data sets at once\nSome psychology software such as PsychoPy often saves each participant’s data as a separate .csv file. FYI you can write code to find all files of a given type (e.g., .csv) in a folder, read them all in, and bind all the data together as a single data frame. This uses some things we won’t cover until later - just know that it can be done quite easily.\nThe below code chunk is set not to run, as there is no such data to be loaded from the data folder.\n\n\nCode\n# list all the files in a directory\nfile_names &lt;- list.files(path = \"../data/individual_files\", \n                         pattern = \"\\\\.csv$\", \n                         full.names = TRUE)\n\n# use (or 'map') the read_csv function onto each of the file names \ndata_combined &lt;- purrr::map_dfr(.x = file_names, .f = read_csv)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading data</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#printing-tables-nicely",
    "href": "chapters/loading_data.html#printing-tables-nicely",
    "title": "4  Fundamentals",
    "section": "4.3 Printing tables nicely",
    "text": "4.3 Printing tables nicely\n\n\nCode\ndat_likert |&gt;\n  knitr::kable(align = \"r\") |&gt;\n  kableExtra::kable_classic(full_width = FALSE)\n\n\n\n\n\ndate\ngroup\nsubject\nlikert_1\nlikert_2\n\n\n\n\n2022-06-23\n1\n1\n1\n4\n\n\n2022-06-23\n2\n2\n3\n3\n\n\n2022-06-23\n2\n3\n2\n1\n\n\n2022-06-23\n1\n4\n5\n5\n\n\n2022-06-23\n1\n5\n3\n3\n\n\n2022-06-23\n2\n6\n2\n1\n\n\n2022-06-23\n1\n7\n2\n1\n\n\n2022-06-23\n1\n8\n1\n3\n\n\n2022-06-23\n1\n9\n2\n5\n\n\n2022-06-23\n2\n10\n5\n2\n\n\n2022-06-23\n1\n11\n1\nNA\n\n\n2022-06-23\n2\n12\n3\nNA\n\n\n2022-06-23\n2\n13\n2\nNA\n\n\n2022-06-23\n1\n14\n5\nNA\n\n\n2022-06-23\n1\n15\n3\nNA\n\n\n2022-06-23\n2\n16\n2\nNA\n\n\n2022-06-23\n1\n17\n2\nNA\n\n\n2022-06-23\n1\n18\n1\nNA\n\n\n2022-06-23\n1\n19\n2\nNA\n\n\n2022-06-23\n2\n20\n5\nNA",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading data</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#exploring-data",
    "href": "chapters/loading_data.html#exploring-data",
    "title": "4  Fundamentals",
    "section": "4.4 Exploring data",
    "text": "4.4 Exploring data\n\n4.4.1 Count number of rows\nA very early step in any data processing is to understand how many rows are in a data frame, as this often represents the number of participants or total number of trials. This is useful to check at multiple steps of your data processing to make sure you have not done something wrong.\n\n\nCode\nnrow(data_demographics_raw)\n\n\n[1] 200\n\n\nCode\nnrow(data_selfreport_raw)\n\n\n[1] 392\n\n\nCode\nnrow(data_amp_raw)\n\n\n[1] 8224\n\n\n\nWhy are there different number of rows in the three data frames when this data all comes from the same participants?\nWhy are the numbers not round?\n\n\n\n4.4.2 Viewing column names\nHow would you know what variables are in a data frame? You can view the data frame, but it can also be useful to print them. Knowing what you have is one of the first steps to working with it.\n\n\nCode\n# print all column names\ncolnames(data_demographics_raw)\n\n\n [1] \"date\"           \"time\"           \"group\"          \"subject\"       \n [5] \"session\"        \"build\"          \"blocknum\"       \"trialnum\"      \n [9] \"blockcode\"      \"trialcode\"      \"pretrialpause\"  \"posttrialpause\"\n[13] \"trialduration\"  \"trialtimeout\"   \"response\"       \"correct\"       \n[17] \"latency\"       \n\n\nCode\n# print all column names as a vector\ndput(colnames(data_demographics_raw))\n\n\nc(\"date\", \"time\", \"group\", \"subject\", \"session\", \"build\", \"blocknum\", \n\"trialnum\", \"blockcode\", \"trialcode\", \"pretrialpause\", \"posttrialpause\", \n\"trialduration\", \"trialtimeout\", \"response\", \"correct\", \"latency\"\n)\n\n\nCode\ndata_demographics_raw %&gt;%\n  colnames() %&gt;%\n  dput()\n\n\nc(\"date\", \"time\", \"group\", \"subject\", \"session\", \"build\", \"blocknum\", \n\"trialnum\", \"blockcode\", \"trialcode\", \"pretrialpause\", \"posttrialpause\", \n\"trialduration\", \"trialtimeout\", \"response\", \"correct\", \"latency\"\n)\n\n\nCode\ndata_selfreport_raw %&gt;%\n  colnames() %&gt;%\n  dput()\n\n\nc(\"date\", \"time\", \"group\", \"subject\", \"session\", \"build\", \"blocknum\", \n\"trialnum\", \"blockcode\", \"trialcode\", \"pretrialpause\", \"posttrialpause\", \n\"trialduration\", \"trialtimeout\", \"response\", \"correct\", \"latency\"\n)\n\n\nCode\ndata_amp_raw %&gt;%\n  colnames() %&gt;%\n  dput()\n\n\nc(\"date\", \"time\", \"subject\", \"blockcode\", \"Blocknum and trialnum\", \n\"trialcode\", \"primestim\", \"targetstim\", \"correct\", \"latency\")\n\n\n\n\n4.4.3 Viewing column names and types\n\n\nCode\nhead(data_demographics_raw) \n\n\n# A tibble: 6 × 17\n  date       time        group subject session build blocknum trialnum blockcode\n  &lt;date&gt;     &lt;time&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n1 2022-06-23 10:46:30   8.66e8  5.49e8       1 6.6.0        1        2 demograp…\n2 2022-06-23 10:46:30   8.66e8  5.49e8       1 6.6.0        1        3 demograp…\n3 2022-06-23 11:54:55   6.31e8  5.05e8       1 6.6.0        1        2 demograp…\n4 2022-06-23 11:54:55   6.31e8  5.05e8       1 6.6.0        1        3 demograp…\n5 2022-06-23 12:23:32   5.69e8  9.95e8       1 6.6.0        1        2 demograp…\n6 2022-06-23 12:23:32   5.69e8  9.95e8       1 6.6.0        1        3 demograp…\n# ℹ 8 more variables: trialcode &lt;chr&gt;, pretrialpause &lt;dbl&gt;,\n#   posttrialpause &lt;dbl&gt;, trialduration &lt;dbl&gt;, trialtimeout &lt;dbl&gt;,\n#   response &lt;chr&gt;, correct &lt;dbl&gt;, latency &lt;dbl&gt;\n\n\nCode\nhead(data_selfreport_raw)\n\n\n# A tibble: 6 × 17\n  date     time         group  subject session build blocknum trialnum blockcode\n  &lt;chr&gt;    &lt;time&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n1 23.06.22 12:37:34 762566308   8.93e8       1 06.0…        1        1 scale    \n2 23.06.22 12:37:34 762566308   8.93e8       1 06.0…        1        2 scale    \n3 23.06.22 12:26:48 569179372   9.95e8       1 06.0…        1        1 scale    \n4 23.06.22 12:26:48 569179372   9.95e8       1 06.0…        1        2 scale    \n5 23.06.22 12:26:48 569179372   9.95e8       1 06.0…        1        3 scale    \n6 23.06.22 12:26:48 569179372   9.95e8       1 06.0…        1        4 scale    \n# ℹ 8 more variables: trialcode &lt;chr&gt;, pretrialpause &lt;dbl&gt;,\n#   posttrialpause &lt;dbl&gt;, trialduration &lt;dbl&gt;, trialtimeout &lt;dbl&gt;,\n#   response &lt;chr&gt;, correct &lt;dbl&gt;, latency &lt;dbl&gt;\n\n\nCode\nhead(data_amp_raw)\n\n\n# A tibble: 6 × 10\n  date     time     subject blockcode Blocknum and trialnu…¹ trialcode primestim\n  &lt;chr&gt;    &lt;time&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;                  &lt;chr&gt;         &lt;dbl&gt;\n1 23.06.22 10:46:38  5.49e8 practice  1_4                    prime_ne…         0\n2 23.06.22 10:46:38  5.49e8 practice  1_5                    prime_ne…         0\n3 23.06.22 10:46:38  5.49e8 practice  1_6                    prime_po…         0\n4 23.06.22 10:46:38  5.49e8 test      2_1                    instruct…         0\n5 23.06.22 11:55:36  5.05e8 practice  1_4                    prime_ne…         0\n6 23.06.22 11:55:36  5.05e8 practice  1_5                    prime_po…         0\n# ℹ abbreviated name: ¹​`Blocknum and trialnum`\n# ℹ 3 more variables: targetstim &lt;dbl&gt;, correct &lt;dbl&gt;, latency &lt;dbl&gt;",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading data</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#the-pipe-or",
    "href": "chapters/loading_data.html#the-pipe-or",
    "title": "4  Fundamentals",
    "section": "4.5 The pipe (%>% or |>)",
    "text": "4.5 The pipe (%&gt;% or |&gt;)\n%&gt;% is the original pipe created for the {magrittr} package and used throughout the tidyverse packages. It is slightly slower but also more flexible.\n|&gt; is a version of the pipe more recently added to base-R. It is slightly faster but less flexible.\nIf you’re not sure, it’s easier to use %&gt;%.\n\n4.5.1 What is the pipe?\nThe output of what is left of the pipe is used as the input to the right of the pipe, usually as the first argument or the data argument.\n\n\nCode\n# use a function without the pipe\nexample_without_pipe &lt;- clean_names(data_demographics_raw)\n\n# use a function with the pipe. \nexample_with_pipe &lt;- data_demographics_raw %&gt;%\n  clean_names()\n\n# check they produce identical results\nidentical(example_without_pipe, example_with_pipe)\n\n\n[1] TRUE\n\n\n\n\n4.5.2 Why use the pipe?\nThe pipe allows us to write code that reads from top to bottom, following a series of steps, in the way that humans organize and describe steps. Without the pipe, code is written from the inside out, in the way that the computer understands it but humans do not as easily.\nThe utility of this becomes more obvious when there are many steps:\n\n\nCode\n# use a series of functions without the pipe\nexample2_without_pipe &lt;- summarise(group_by(mutate(rename(clean_names(dat = data_amp_raw), unique_id = subject, block = blockcode, trial_type = trialcode, rt = latency), fast_trial = ifelse(rt &lt; 100, 1, 0)), unique_id), percent_fast_trials = mean(fast_trial)*100) \n\n# use a series of functions with the pipe\nexample2_with_pipe &lt;- data_amp_raw %&gt;%\n  # clean the column names\n  clean_names() %&gt;%\n  # rename the columns\n  rename(unique_id = subject,\n         block = blockcode,\n         trial_type = trialcode,\n         rt = latency) %&gt;%\n  # create a new variable using existing ones\n  mutate(fast_trial = ifelse(rt &lt; 100, 1, 0)) %&gt;%\n  # summarize across trials for each participant\n  group_by(unique_id) %&gt;%\n  summarise(percent_fast_trials = mean(fast_trial)*100) \n\n# check they produce identical results\nidentical(example2_without_pipe, example2_with_pipe)\n\n\n[1] TRUE",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading data</span>"
    ]
  },
  {
    "objectID": "chapters/loading_data.html#using-the-pipe-cleaning-column-names",
    "href": "chapters/loading_data.html#using-the-pipe-cleaning-column-names",
    "title": "4  Fundamentals",
    "section": "4.6 Using the pipe & cleaning column names",
    "text": "4.6 Using the pipe & cleaning column names\nIt is almost always useful to start by converting all column names to ones that play nice with R/tidyverse and which use the same naming convention (e.g., snake_case, which is standard in tidyverse).\nHow would you bring up the help menu to understand how janitor::clean_names() works?\nRewrite each of the below to use the pipe.\n\n\nCode\ndata_demographics_clean_names &lt;- data_demographics_raw %&gt;%\n  clean_names() \n\ndata_selfreport_clean_names &lt;- data_selfreport_raw %&gt;%\n  clean_names() \n\ndata_amp_clean_names &lt;- data_amp_raw %&gt;%\n  clean_names()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Loading data</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html",
    "href": "chapters/data_transformation.html",
    "title": "5  Data transformation",
    "section": "",
    "text": "5.1 Dependencies and data\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(janitor) # for clean_names() and round_half_up()\nlibrary(roundwork) # for round_up()\nlibrary(stringr)\nlibrary(knitr) # for kable()\nlibrary(kableExtra) # for kable_classic()\n\n# demographics data\ndata_demographics_raw &lt;- read_csv(file = \"../data/raw/data_demographics_raw.csv\") \n\n# self report measure data\ndata_selfreport_raw &lt;- read_csv(file = \"../data/raw/data_selfreport_raw.csv\") \n\n# affect attribution procedure data\ndata_amp_raw &lt;- read_csv(file = \"../data/raw/data_amp_raw.csv\")\n\n# clean column names\ndata_demographics_clean_names &lt;- data_demographics_raw %&gt;%\n  clean_names() \n\ndata_selfreport_clean_names &lt;- data_selfreport_raw %&gt;%\n  clean_names() \n\ndata_amp_clean_names &lt;- data_amp_raw %&gt;%\n  clean_names()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#renaming-columns",
    "href": "chapters/data_transformation.html#renaming-columns",
    "title": "5  Data transformation",
    "section": "5.2 Renaming columns",
    "text": "5.2 Renaming columns\nOften variable names are not intuitive. An early step in any data wrangling is to make them more intuitive.\nRename the self reports and AMP data too.\n\n\nCode\ndata_demographics_renamed &lt;- data_demographics_clean_names %&gt;%\n  rename(unique_id = subject,\n         item = trialcode,\n         rt_ms = latency) \n\ndata_selfreport_renamed &lt;- data_selfreport_clean_names %&gt;%\n  rename(unique_id = subject,\n         item = trialcode,\n         rt_ms = latency) \n\ndata_amp_renamed &lt;- data_amp_clean_names %&gt;%\n  rename(unique_id = subject,\n         block_type = blockcode,\n         trial_type = trialcode,\n         trial_id = blocknum_and_trialnum,\n         rt_ms = latency)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#selecting-columns",
    "href": "chapters/data_transformation.html#selecting-columns",
    "title": "5  Data transformation",
    "section": "5.3 Selecting columns",
    "text": "5.3 Selecting columns\nNot all variables are useful to you. An early step in any data wrangling is to drop the columns that you don’t need.\nSelect the self reports and AMP data too.\n\n\nCode\ndata_demographics_selected_columns &lt;- data_demographics_renamed %&gt;%\n  select(unique_id, item, response)\n\ndata_selfreport_selected_columns &lt;- data_selfreport_renamed %&gt;%\n  select(unique_id, item, response, rt_ms)\n\ndata_amp_selected_columns &lt;- data_amp_renamed %&gt;%\n  select(unique_id, \n         # methods variables\n         block_type,\n         trial_type,\n         trial_id,\n         # responses \n         rt_ms, \n         correct)\n\n\n\n5.3.1 More flexible selecting\n\n\nCode\ndat &lt;- data.frame(\n  var_1_1 = rnorm(n = 100),\n  var_1_2 = rnorm(n = 100),\n  var_1_3 = rnorm(n = 100),\n  var_1_4 = rnorm(n = 100),\n  var_1_5 = rnorm(n = 100),\n  var_2_1 = rnorm(n = 100),\n  var_2_2 = rnorm(n = 100),\n  var_2_3 = rnorm(n = 100),\n  var_2_4 = rnorm(n = 100),\n  var_2_5 = rnorm(n = 100)\n)\n\ndat |&gt;\n  select(starts_with(\"var_1\")) \n\n\n         var_1_1       var_1_2      var_1_3      var_1_4      var_1_5\n1   -1.109879741  1.6272035963  0.419225971  0.091620086  1.080552289\n2   -0.058025292  0.0578149357  1.074568319  0.632877675 -0.662085712\n3    0.887489205 -2.1238746184 -1.405153514 -0.427339910 -0.441269397\n4   -1.569420849 -0.2414041759  0.116974037 -2.403212948 -0.692075345\n5    1.126837025  0.0172259577  0.413689120  2.978568600 -0.683401863\n6   -2.006146678 -0.8784020268  0.088717485  0.920376972 -0.690950011\n7   -0.191339535 -1.2161979071  0.245123686  1.319840624 -0.267891316\n8    0.341325654  1.3019209017  1.032089758 -0.052355161  0.135711013\n9   -0.300736448 -0.8420805243  1.852088857  0.807211931 -3.006017102\n10   0.046617564  0.0394574444 -1.931303116 -1.010602128  0.816211498\n11   0.135379011  0.3412166730 -0.496057805  0.337694693  0.795297781\n12  -0.803426410 -0.4703712523  0.227426550  1.080144309 -1.764097386\n13  -0.105981031  0.8141018778 -1.494287955 -2.843187645  0.584131264\n14  -0.902104835 -0.1456859085 -2.099608293  0.663001229 -0.560153407\n15   1.155369706  0.5447166652  0.444950131  1.351228492 -0.048003518\n16   0.059676788 -0.5472888300  1.598437915 -1.379823595 -0.211328501\n17   0.891094105 -1.5998452018 -0.753613629 -0.257199589  0.041732823\n18  -1.972580753  0.4220019057 -1.394402840 -1.477576963 -0.546220290\n19  -0.881628562 -0.1907654200 -0.459886846 -0.438897483  0.064585767\n20  -0.208867331  0.6333405870 -1.147687872 -1.624535157  0.141451541\n21  -1.034839780  0.5745148147 -1.044955342 -0.936737120 -0.721567758\n22   1.403860677  0.1010480107  1.292421663 -0.202717526 -0.845014150\n23   0.122246372  2.2495808804 -0.871116763  1.045891006  0.447532036\n24  -0.717719785 -0.4893808901 -0.308213309  1.180965944  0.797510471\n25  -1.082037040 -2.3029665381  0.610113097 -0.751434142  0.824638169\n26   2.584843589  0.3922686951  0.270076488 -0.846972856  0.589023460\n27   0.143539027  1.1166226823  0.003926085  0.465153858 -0.586892247\n28  -0.905317607  0.4606830273  0.047943410  0.867489018 -0.019262263\n29   0.563222847  0.8594628773  0.157326127  0.963090402  0.263822049\n30  -1.706080753 -3.6011414841  1.289018385 -0.420003257  0.668889222\n31   0.555658583 -1.1947871486  2.008732175 -0.637478617 -0.350922531\n32   0.763241894 -1.4644684134 -0.383144501  0.476753811 -1.151004621\n33   0.680500592  0.7497763230  0.097207031  0.972442063 -0.344722467\n34   1.135884799 -1.8791585149 -1.680202894 -0.383574662 -0.061365583\n35  -0.025901163  0.8806239098  0.529291559  0.288613676  1.656029727\n36   1.214049783 -0.6307923071  0.055866865 -2.235959747  0.616158871\n37   0.361065559  0.2598568002  0.841032805  0.582308278  1.134693639\n38   1.171616457 -1.3537364693  0.038839320 -0.510802800  1.874398614\n39  -0.468989601 -1.2410036370 -1.194400737 -0.968789128  2.385910810\n40  -1.717672463  1.8334963535  1.241774739 -0.493992294  0.304851166\n41   0.106868858  1.6430984824  2.140269318  0.128598094  0.523248745\n42   0.915297732  0.0001946169 -1.108929474  0.017166174 -0.087298684\n43  -0.931346392  0.9241701505 -0.124843973 -0.665817390  0.844100489\n44   0.561156117 -0.4887360621  0.247983732 -1.045310854  0.709948178\n45   0.220330153  0.4787131222 -0.738398947  0.208944999 -1.318293305\n46   0.056678179  0.0173068835  0.056329509  1.144875618  0.413897629\n47  -1.580826125  1.3156434735 -1.655858908  0.755269876 -0.541671312\n48   0.035016101  0.6511176592 -1.179780790 -0.523250673  0.609600202\n49   1.180473412  0.5343617507  0.196242327 -0.120200929 -0.211245100\n50  -1.473311365 -2.1383479607  1.523123121 -0.439910305 -0.657392950\n51   0.814551882 -1.1853306673 -1.246415735 -0.867953730  2.861829897\n52  -0.412001098  0.6628537758 -0.991095433  0.558227463 -1.038907777\n53  -2.134007289  0.7837409146  0.250630157 -0.294967706  0.440754656\n54  -0.581898511  0.1695019415  1.750144723 -0.629909667  0.146076120\n55   1.577791902  1.1478446450 -0.857025834 -1.012498769 -2.179717042\n56  -1.826712739  0.2550199297  0.467509675 -1.204785363  0.390627351\n57  -1.030344158  1.1258210375  1.129523775  0.823504927 -0.677801172\n58  -1.098704129 -0.9306804161 -0.893439794  0.137379209 -0.070446911\n59  -0.357434603 -0.9985978069 -0.957616560  0.296932141 -0.596714756\n60   0.575595978 -0.9826519017 -0.007317291 -0.405884285  1.139339025\n61   1.756352445 -0.7984170217  0.438643851  0.244581720 -0.071570522\n62  -1.251190343  2.5994280082 -0.449837467  1.592327971  1.243092717\n63  -0.432066705  0.5122474635 -1.321420573 -0.557551756 -0.926398024\n64   0.692394037  0.6311033063  1.017734827  0.061318083  0.456731173\n65  -0.408876623  0.3502484032  2.472533300  3.045198068 -0.628944235\n66  -0.603998998 -0.3338141020 -0.233757003  0.221339538 -0.192886928\n67  -0.858439681  0.8955185928  0.715739566  0.507073884  0.125997781\n68  -0.646350642  0.5775988684  2.233435111  0.072296323 -0.839942259\n69   0.096635576 -0.6552073712  1.644637281 -0.608293511  0.052358226\n70   1.449147834  0.6586332753  0.471151771  2.279524201  0.130590457\n71  -0.251392268  1.1126230861  0.516137940 -0.382228298  0.482649420\n72   0.977522345  0.1618991726  0.966679594  0.146319277  0.529497533\n73   0.180232967 -1.9632233965 -0.017264452 -0.218607691  1.314667998\n74   0.193082730  0.0135716606  0.489389053 -1.143029909 -0.172254402\n75   0.401206041 -0.5515741704 -0.109725263  0.158204624 -0.205684592\n76   1.417987904  0.1505860102 -1.467347189 -0.087036425 -0.672332942\n77  -1.388294438 -1.9464855525  1.329847545 -1.019090327 -0.400885444\n78  -1.471899039 -0.1676907254 -0.078814601  2.026170405  0.629950138\n79   0.479638676 -0.7202257169 -0.559272693 -0.261931937 -0.606446716\n80   0.106138042  0.5875414817  0.764890503 -0.458765955 -0.424978132\n81   0.007671601 -0.4852647460  0.936916369  1.003411173 -2.180548385\n82  -1.456989800  1.4083949161 -1.513056120  0.002868041 -0.788308501\n83   0.057893228  0.1426559994  1.104695346 -0.956049786 -0.596366944\n84  -0.078714220  0.6651943635 -0.904131032 -0.139439758 -1.337003542\n85   1.056118755  0.9979714191  0.751105300 -0.178134151 -0.693850770\n86  -1.135132304 -0.0653430384 -0.707183578  0.819724723 -0.894771809\n87   0.881853608  1.0344802545 -1.152976598  0.600130728 -0.149884281\n88   0.957823091  0.8570531406  1.419193534  0.193914309  1.974182054\n89  -1.328901474  0.5761517395 -1.226737172 -1.320206781 -0.637560754\n90  -0.061549532 -1.3668129598  1.052244011 -0.683978280  0.248505140\n91   1.562008386 -0.5119519153 -0.598038747  1.072262857 -1.026004891\n92   0.162361579 -0.1753115993 -1.124293087 -0.822739822  0.005377899\n93  -1.930358215  0.1706795485  0.333542199  0.184950795 -0.790120473\n94   1.456079084  0.8494290937  0.248190588  0.409123486  0.030798575\n95  -0.373586889  2.2189110043 -1.225868608 -0.100152437 -0.386064517\n96  -0.456441141 -0.6315850312  0.653245075 -0.824020635 -0.817242231\n97  -0.333848589 -1.2857574260  1.074026404 -0.171437298 -2.072934228\n98   0.318833331 -0.4280586722  0.058742883 -0.320993759 -0.387281434\n99   0.740062565  1.4433338372 -0.248195193 -0.608245545  1.254276227\n100  1.387443219  0.3736086722  0.695055334  0.599867571 -0.692780996\n\n\nCode\ndat |&gt;\n  select(ends_with(\"var_1\")) \n\n\ndata frame with 0 columns and 100 rows\n\n\nCode\ndat |&gt;\n  select(contains(\"_1_\")) \n\n\n         var_1_1       var_1_2      var_1_3      var_1_4      var_1_5\n1   -1.109879741  1.6272035963  0.419225971  0.091620086  1.080552289\n2   -0.058025292  0.0578149357  1.074568319  0.632877675 -0.662085712\n3    0.887489205 -2.1238746184 -1.405153514 -0.427339910 -0.441269397\n4   -1.569420849 -0.2414041759  0.116974037 -2.403212948 -0.692075345\n5    1.126837025  0.0172259577  0.413689120  2.978568600 -0.683401863\n6   -2.006146678 -0.8784020268  0.088717485  0.920376972 -0.690950011\n7   -0.191339535 -1.2161979071  0.245123686  1.319840624 -0.267891316\n8    0.341325654  1.3019209017  1.032089758 -0.052355161  0.135711013\n9   -0.300736448 -0.8420805243  1.852088857  0.807211931 -3.006017102\n10   0.046617564  0.0394574444 -1.931303116 -1.010602128  0.816211498\n11   0.135379011  0.3412166730 -0.496057805  0.337694693  0.795297781\n12  -0.803426410 -0.4703712523  0.227426550  1.080144309 -1.764097386\n13  -0.105981031  0.8141018778 -1.494287955 -2.843187645  0.584131264\n14  -0.902104835 -0.1456859085 -2.099608293  0.663001229 -0.560153407\n15   1.155369706  0.5447166652  0.444950131  1.351228492 -0.048003518\n16   0.059676788 -0.5472888300  1.598437915 -1.379823595 -0.211328501\n17   0.891094105 -1.5998452018 -0.753613629 -0.257199589  0.041732823\n18  -1.972580753  0.4220019057 -1.394402840 -1.477576963 -0.546220290\n19  -0.881628562 -0.1907654200 -0.459886846 -0.438897483  0.064585767\n20  -0.208867331  0.6333405870 -1.147687872 -1.624535157  0.141451541\n21  -1.034839780  0.5745148147 -1.044955342 -0.936737120 -0.721567758\n22   1.403860677  0.1010480107  1.292421663 -0.202717526 -0.845014150\n23   0.122246372  2.2495808804 -0.871116763  1.045891006  0.447532036\n24  -0.717719785 -0.4893808901 -0.308213309  1.180965944  0.797510471\n25  -1.082037040 -2.3029665381  0.610113097 -0.751434142  0.824638169\n26   2.584843589  0.3922686951  0.270076488 -0.846972856  0.589023460\n27   0.143539027  1.1166226823  0.003926085  0.465153858 -0.586892247\n28  -0.905317607  0.4606830273  0.047943410  0.867489018 -0.019262263\n29   0.563222847  0.8594628773  0.157326127  0.963090402  0.263822049\n30  -1.706080753 -3.6011414841  1.289018385 -0.420003257  0.668889222\n31   0.555658583 -1.1947871486  2.008732175 -0.637478617 -0.350922531\n32   0.763241894 -1.4644684134 -0.383144501  0.476753811 -1.151004621\n33   0.680500592  0.7497763230  0.097207031  0.972442063 -0.344722467\n34   1.135884799 -1.8791585149 -1.680202894 -0.383574662 -0.061365583\n35  -0.025901163  0.8806239098  0.529291559  0.288613676  1.656029727\n36   1.214049783 -0.6307923071  0.055866865 -2.235959747  0.616158871\n37   0.361065559  0.2598568002  0.841032805  0.582308278  1.134693639\n38   1.171616457 -1.3537364693  0.038839320 -0.510802800  1.874398614\n39  -0.468989601 -1.2410036370 -1.194400737 -0.968789128  2.385910810\n40  -1.717672463  1.8334963535  1.241774739 -0.493992294  0.304851166\n41   0.106868858  1.6430984824  2.140269318  0.128598094  0.523248745\n42   0.915297732  0.0001946169 -1.108929474  0.017166174 -0.087298684\n43  -0.931346392  0.9241701505 -0.124843973 -0.665817390  0.844100489\n44   0.561156117 -0.4887360621  0.247983732 -1.045310854  0.709948178\n45   0.220330153  0.4787131222 -0.738398947  0.208944999 -1.318293305\n46   0.056678179  0.0173068835  0.056329509  1.144875618  0.413897629\n47  -1.580826125  1.3156434735 -1.655858908  0.755269876 -0.541671312\n48   0.035016101  0.6511176592 -1.179780790 -0.523250673  0.609600202\n49   1.180473412  0.5343617507  0.196242327 -0.120200929 -0.211245100\n50  -1.473311365 -2.1383479607  1.523123121 -0.439910305 -0.657392950\n51   0.814551882 -1.1853306673 -1.246415735 -0.867953730  2.861829897\n52  -0.412001098  0.6628537758 -0.991095433  0.558227463 -1.038907777\n53  -2.134007289  0.7837409146  0.250630157 -0.294967706  0.440754656\n54  -0.581898511  0.1695019415  1.750144723 -0.629909667  0.146076120\n55   1.577791902  1.1478446450 -0.857025834 -1.012498769 -2.179717042\n56  -1.826712739  0.2550199297  0.467509675 -1.204785363  0.390627351\n57  -1.030344158  1.1258210375  1.129523775  0.823504927 -0.677801172\n58  -1.098704129 -0.9306804161 -0.893439794  0.137379209 -0.070446911\n59  -0.357434603 -0.9985978069 -0.957616560  0.296932141 -0.596714756\n60   0.575595978 -0.9826519017 -0.007317291 -0.405884285  1.139339025\n61   1.756352445 -0.7984170217  0.438643851  0.244581720 -0.071570522\n62  -1.251190343  2.5994280082 -0.449837467  1.592327971  1.243092717\n63  -0.432066705  0.5122474635 -1.321420573 -0.557551756 -0.926398024\n64   0.692394037  0.6311033063  1.017734827  0.061318083  0.456731173\n65  -0.408876623  0.3502484032  2.472533300  3.045198068 -0.628944235\n66  -0.603998998 -0.3338141020 -0.233757003  0.221339538 -0.192886928\n67  -0.858439681  0.8955185928  0.715739566  0.507073884  0.125997781\n68  -0.646350642  0.5775988684  2.233435111  0.072296323 -0.839942259\n69   0.096635576 -0.6552073712  1.644637281 -0.608293511  0.052358226\n70   1.449147834  0.6586332753  0.471151771  2.279524201  0.130590457\n71  -0.251392268  1.1126230861  0.516137940 -0.382228298  0.482649420\n72   0.977522345  0.1618991726  0.966679594  0.146319277  0.529497533\n73   0.180232967 -1.9632233965 -0.017264452 -0.218607691  1.314667998\n74   0.193082730  0.0135716606  0.489389053 -1.143029909 -0.172254402\n75   0.401206041 -0.5515741704 -0.109725263  0.158204624 -0.205684592\n76   1.417987904  0.1505860102 -1.467347189 -0.087036425 -0.672332942\n77  -1.388294438 -1.9464855525  1.329847545 -1.019090327 -0.400885444\n78  -1.471899039 -0.1676907254 -0.078814601  2.026170405  0.629950138\n79   0.479638676 -0.7202257169 -0.559272693 -0.261931937 -0.606446716\n80   0.106138042  0.5875414817  0.764890503 -0.458765955 -0.424978132\n81   0.007671601 -0.4852647460  0.936916369  1.003411173 -2.180548385\n82  -1.456989800  1.4083949161 -1.513056120  0.002868041 -0.788308501\n83   0.057893228  0.1426559994  1.104695346 -0.956049786 -0.596366944\n84  -0.078714220  0.6651943635 -0.904131032 -0.139439758 -1.337003542\n85   1.056118755  0.9979714191  0.751105300 -0.178134151 -0.693850770\n86  -1.135132304 -0.0653430384 -0.707183578  0.819724723 -0.894771809\n87   0.881853608  1.0344802545 -1.152976598  0.600130728 -0.149884281\n88   0.957823091  0.8570531406  1.419193534  0.193914309  1.974182054\n89  -1.328901474  0.5761517395 -1.226737172 -1.320206781 -0.637560754\n90  -0.061549532 -1.3668129598  1.052244011 -0.683978280  0.248505140\n91   1.562008386 -0.5119519153 -0.598038747  1.072262857 -1.026004891\n92   0.162361579 -0.1753115993 -1.124293087 -0.822739822  0.005377899\n93  -1.930358215  0.1706795485  0.333542199  0.184950795 -0.790120473\n94   1.456079084  0.8494290937  0.248190588  0.409123486  0.030798575\n95  -0.373586889  2.2189110043 -1.225868608 -0.100152437 -0.386064517\n96  -0.456441141 -0.6315850312  0.653245075 -0.824020635 -0.817242231\n97  -0.333848589 -1.2857574260  1.074026404 -0.171437298 -2.072934228\n98   0.318833331 -0.4280586722  0.058742883 -0.320993759 -0.387281434\n99   0.740062565  1.4433338372 -0.248195193 -0.608245545  1.254276227\n100  1.387443219  0.3736086722  0.695055334  0.599867571 -0.692780996",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#practice-the-pipe-again",
    "href": "chapters/data_transformation.html#practice-the-pipe-again",
    "title": "5  Data transformation",
    "section": "5.4 Practice the pipe again",
    "text": "5.4 Practice the pipe again\nCombine the above function calls using pipes. Notice how this involves fewer objects in your environment, and therefore less potential for confusion or error.\nRemember: this is how we solve coding problems: break them down into smaller tasks and problems, get each of them working individually, then combine them together again. When you only see the end product, it’s easy to think the author simply wrote the code as you see it, when they often wrote much more verbose chunks of code and then combined them together.\nRewrite the rename and select calls for the AMP and self report data too.\n\n\nCode\n# remove all objects in environment\nrm(list = ls())\n\n\ndata_demographics_trimmed &lt;-\n  # read in the data\n  read_csv(\"../data/raw/data_demographics_raw.csv\") %&gt;%\n  \n  # convert to snake case\n  clean_names() %&gt;%\n  \n  # make names more intuitive\n  rename(unique_id = subject,\n         item = trialcode) %&gt;%\n  \n  # retain only columns of interest\n  select(unique_id, item, response)\n\n\ndata_selfreport_trimmed &lt;- \n  read_csv(\"../data/raw/data_selfreport_raw.csv\") %&gt;%\n  clean_names() %&gt;%\n  rename(unique_id = subject,\n         item = trialcode) %&gt;%\n  select(unique_id, item, response)\n\ndata_amp_trimmed &lt;- \n  read_csv(\"../data/raw/data_amp_raw.csv\") %&gt;%\n  clean_names() %&gt;%\n  rename(unique_id = subject,\n         block_type = blockcode,\n         trial_type = trialcode,\n         trial_id = blocknum_and_trialnum,\n         rt_ms = latency) %&gt;%\n  select(unique_id, \n         # methods variables\n         block_type,\n         trial_type,\n         trial_id,\n         # responses \n         rt_ms, \n         correct)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#counting-frequencies",
    "href": "chapters/data_transformation.html#counting-frequencies",
    "title": "5  Data transformation",
    "section": "5.5 Counting frequencies",
    "text": "5.5 Counting frequencies\nAfter renaming and selecting columns, we know what columns we have. But what rows do we have in each of these? What might we need to exclude, change, work with in some way later on? It is very useful to use count() to obtain the frequency of each unique value of a given column\n\n\nCode\ndata_demographics_trimmed %&gt;%\n  count(item)\n\n\n# A tibble: 2 × 2\n  item       n\n  &lt;chr&gt;  &lt;int&gt;\n1 age      100\n2 gender   100\n\n\nCode\ndata_demographics_trimmed %&gt;%\n  count(response)\n\n\n# A tibble: 50 × 2\n   response     n\n   &lt;chr&gt;    &lt;int&gt;\n 1 18           1\n 2 19           4\n 3 20           1\n 4 21           6\n 5 22           2\n 6 23           6\n 7 24           1\n 8 25           3\n 9 26           4\n10 27           5\n# ℹ 40 more rows\n\n\n\n\nCode\ndata_selfreport_trimmed %&gt;%\n  count(item)\n\n\n# A tibble: 4 × 2\n  item             n\n  &lt;chr&gt;        &lt;int&gt;\n1 instructions    99\n2 like            99\n3 positive        97\n4 prefer          97\n\n\nCode\ndata_selfreport_trimmed %&gt;%\n  count(response)\n\n\n# A tibble: 9 × 2\n  response     n\n  &lt;chr&gt;    &lt;int&gt;\n1 1          193\n2 2           43\n3 3           26\n4 4           16\n5 5            7\n6 57          99\n7 6            4\n8 7            3\n9 Ctrl+'B'     1\n\n\n\n\nCode\ndata_amp_trimmed %&gt;%\n  count(trial_type)\n\n\n# A tibble: 5 × 2\n  trial_type                  n\n  &lt;chr&gt;                   &lt;int&gt;\n1 instructions                2\n2 prime_negative           3604\n3 prime_negative_practice   508\n4 prime_positive           3604\n5 prime_positive_practice   506\n\n\nCode\ndata_amp_trimmed %&gt;%\n  count(block_type)\n\n\n# A tibble: 2 × 2\n  block_type     n\n  &lt;chr&gt;      &lt;int&gt;\n1 practice    1014\n2 test        7210\n\n\nCode\ndata_amp_trimmed %&gt;%\n  count(correct)\n\n\n# A tibble: 2 × 2\n  correct     n\n    &lt;dbl&gt; &lt;int&gt;\n1       0  3440\n2       1  4784\n\n\nCode\ndata_amp_trimmed %&gt;%\n  count(rt_ms)\n\n\n# A tibble: 2,165 × 2\n   rt_ms     n\n   &lt;dbl&gt; &lt;int&gt;\n 1     1     2\n 2     3     1\n 3     5     2\n 4     8     1\n 5     9     1\n 6    11     1\n 7    13     1\n 8    14     1\n 9    16     1\n10    18     1\n# ℹ 2,155 more rows\n\n\n\n5.5.1 Frequncies of sets of columns\nNote that it is also possible to use count to obtain the frequencies of sets of unique values across columns, e.g., unique combinations of item and response.\n\n\nCode\ndata_demographics_trimmed %&gt;%\n  count(item)\n\n\n# A tibble: 2 × 2\n  item       n\n  &lt;chr&gt;  &lt;int&gt;\n1 age      100\n2 gender   100\n\n\nCode\ndata_demographics_trimmed %&gt;%\n  count(response)\n\n\n# A tibble: 50 × 2\n   response     n\n   &lt;chr&gt;    &lt;int&gt;\n 1 18           1\n 2 19           4\n 3 20           1\n 4 21           6\n 5 22           2\n 6 23           6\n 7 24           1\n 8 25           3\n 9 26           4\n10 27           5\n# ℹ 40 more rows\n\n\nCode\ndata_demographics_trimmed %&gt;%\n  count(item, response)\n\n\n# A tibble: 51 × 3\n   item  response     n\n   &lt;chr&gt; &lt;chr&gt;    &lt;int&gt;\n 1 age   18           1\n 2 age   19           4\n 3 age   20           1\n 4 age   21           6\n 5 age   22           2\n 6 age   23           5\n 7 age   24           1\n 8 age   25           3\n 9 age   26           4\n10 age   27           5\n# ℹ 41 more rows\n\n\nIt can be useful to arrange the output by the frequencies.\n\n\nCode\ndata_demographics_trimmed %&gt;%\n  count(item, response) %&gt;%\n  arrange(desc(n)) # arrange in descending order\n\n\n# A tibble: 51 × 3\n   item   response     n\n   &lt;chr&gt;  &lt;chr&gt;    &lt;int&gt;\n 1 gender Male        36\n 2 gender female      27\n 3 gender male        18\n 4 gender Female      11\n 5 age    21           6\n 6 age    23           5\n 7 age    27           5\n 8 age    32           5\n 9 age    19           4\n10 age    26           4\n# ℹ 41 more rows",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#filtering-rows",
    "href": "chapters/data_transformation.html#filtering-rows",
    "title": "5  Data transformation",
    "section": "5.6 Filtering rows",
    "text": "5.6 Filtering rows\nOnce we know the contents of our columns, we may wish to exclude some rows using filter().\nYou can specify the logical test for filtering in many ways, including equivalence (==), negation (!=), or membership (%in%). It is often better to define what you do want (using equivalence or membership) rather than what you do not want (negation), as negations are less robust to new data with weird values you didn’t think of when you wrote the code. E.g., you could specify gender != \"non-binary\" but this would not catch non binary. If you were for example looking to include only men and women, instead use gender %in% c(\"man\", \"woman\").*\n*[This is just an example; there is usually no good a priori reason to exclude gender diverse participants]\n\n\nCode\n# example using equivalence\nexample_equivalence &lt;- data_amp_trimmed %&gt;%\n  filter(block_type == \"test\")\n\n# example using negation\nexample_negation &lt;- data_selfreport_trimmed %&gt;%\n  filter(item != \"instructions\")\n\n# example using membership\nexample_membership &lt;- data_selfreport_trimmed %&gt;%\n  filter(item %in% c(\"positive\", \"prefer\", \"like\"))\n\n\n\n5.6.1 Multiple criteria, ‘and’ or ‘or’ combinations\nYou can also have multiple criteria in your filter call, both of which have to be met (x & y), or either one of which have to be met (x | y).\n\n\nCode\nexample_multiple_criteria_1 &lt;- data_amp_trimmed %&gt;%\n  filter(block_type != \"test\" & correct == 1)\n\nexample_multiple_criteria_2 &lt;- data_amp_trimmed %&gt;%\n  filter(block_type != \"test\" | correct == 1)\n\n# note that these provide different results - make sure you understand why\nidentical(example_multiple_criteria_1, example_multiple_criteria_2)\n\n\n[1] FALSE\n\n\n\n\n5.6.2 Practice filtering\nFilter the self reports data frame to remove the instructions. Filter the AMP data frame to remove the practice blocks and the instruction trials.\n\n\nCode\ndata_selfreport_trials &lt;- data_selfreport_trimmed %&gt;%\n  #filter(item != \"instructions\")\n  filter(item %in% c(\"positive\", \"prefer\", \"like\"))\n\n# this probably contains things we don't want\ndata_amp_trimmed %&gt;%\n  count(trial_type, block_type)\n\n\n# A tibble: 5 × 3\n  trial_type              block_type     n\n  &lt;chr&gt;                   &lt;chr&gt;      &lt;int&gt;\n1 instructions            test           2\n2 prime_negative          test        3604\n3 prime_negative_practice practice     508\n4 prime_positive          test        3604\n5 prime_positive_practice practice     506\n\n\nCode\n# we exclude them\ndata_amp_test_trials &lt;- data_amp_trimmed %&gt;%\n  filter(block_type == \"test\") %&gt;%\n  filter(trial_type != \"instructions\")\n\n# check they are excluded\ndata_amp_test_trials %&gt;%\n  count(trial_type, block_type)\n\n\n# A tibble: 2 × 3\n  trial_type     block_type     n\n  &lt;chr&gt;          &lt;chr&gt;      &lt;int&gt;\n1 prime_negative test        3604\n2 prime_positive test        3604\n\n\n\n\n5.6.3 More flexible filtering\nReturn rows with exactly this contents\n\n\nCode\ndata_amp_test_trials |&gt;\n  filter(trial_id == \"A\") # \n\n\n# A tibble: 0 × 6\n# ℹ 6 variables: unique_id &lt;dbl&gt;, block_type &lt;chr&gt;, trial_type &lt;chr&gt;,\n#   trial_id &lt;chr&gt;, rt_ms &lt;dbl&gt;, correct &lt;dbl&gt;\n\n\nReturn rows containing contents but not exactly it\n\n\nCode\nlibrary(stringr)\n\ntest &lt;- c(\"A\", \"AB\", \"B\")\n\ntest == \"A\"\n\n\n[1]  TRUE FALSE FALSE\n\n\nCode\nstr_detect(test, \"A\")\n\n\n[1]  TRUE  TRUE FALSE\n\n\nCode\nstr_detect(test, \"B\")\n\n\n[1] FALSE  TRUE  TRUE\n\n\nCode\ndata_amp_test_trials |&gt;\n  filter(str_detect(trial_id, \"2_\")) \n\n\n# A tibble: 7,208 × 6\n   unique_id block_type trial_type     trial_id rt_ms correct\n       &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;          &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1 504546409 test       prime_positive 2_2        161       0\n 2 504546409 test       prime_positive 2_3        328       0\n 3 504546409 test       prime_positive 2_4        220       1\n 4 504546409 test       prime_negative 2_5        308       1\n 5 504546409 test       prime_negative 2_6        235       1\n 6 504546409 test       prime_negative 2_7        224       1\n 7 504546409 test       prime_negative 2_8        369       0\n 8 504546409 test       prime_positive 2_9       1105       1\n 9 994692692 test       prime_positive 2_2       1611       0\n10 994692692 test       prime_negative 2_3        627       0\n# ℹ 7,198 more rows\n\n\n\n5.6.3.1 Multiple logical tests\n\n\nCode\n# \"|\" = OR\n# \"&\" = AND\n\ndata_amp_test_trials |&gt;\n  filter(str_detect(trial_id, \"2_\") &\n           str_detect(trial_id, \"3_\"))\n\n\n# A tibble: 0 × 6\n# ℹ 6 variables: unique_id &lt;dbl&gt;, block_type &lt;chr&gt;, trial_type &lt;chr&gt;,\n#   trial_id &lt;chr&gt;, rt_ms &lt;dbl&gt;, correct &lt;dbl&gt;\n\n\nCode\ndata_amp_test_trials |&gt;\n  mutate(rt_ms = ifelse(str_detect(trial_id, \"2_\"), rt_ms+100, rt_ms))\n\n\n# A tibble: 7,208 × 6\n   unique_id block_type trial_type     trial_id rt_ms correct\n       &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;          &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1 504546409 test       prime_positive 2_2        261       0\n 2 504546409 test       prime_positive 2_3        428       0\n 3 504546409 test       prime_positive 2_4        320       1\n 4 504546409 test       prime_negative 2_5        408       1\n 5 504546409 test       prime_negative 2_6        335       1\n 6 504546409 test       prime_negative 2_7        324       1\n 7 504546409 test       prime_negative 2_8        469       0\n 8 504546409 test       prime_positive 2_9       1205       1\n 9 994692692 test       prime_positive 2_2       1711       0\n10 994692692 test       prime_negative 2_3        727       0\n# ℹ 7,198 more rows",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#check-your-learning",
    "href": "chapters/data_transformation.html#check-your-learning",
    "title": "5  Data transformation",
    "section": "5.7 Check your learning",
    "text": "5.7 Check your learning\nWhat is the difference between select and filter?\nWhich is for rows and which is for columns?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#mutating-creating-new-columns-or-changing-the-contents-of-existing-ones",
    "href": "chapters/data_transformation.html#mutating-creating-new-columns-or-changing-the-contents-of-existing-ones",
    "title": "5  Data transformation",
    "section": "5.8 Mutating: creating new columns or changing the contents of existing ones",
    "text": "5.8 Mutating: creating new columns or changing the contents of existing ones\n\n5.8.1 Understanding mutate()\nmutate() is used to create new columns or to change the contents of existing ones.\n\n\nCode\n# mutating new variables\nexample_1 &lt;- data_amp_test_trials %&gt;%\n  mutate(latency_plus_1 = rt_ms + 1)\n\nexample_2 &lt;- data_amp_test_trials %&gt;%\n  mutate(log_latency = log(rt_ms))\n\n# mutating the contents of existing variables\nexample_3 &lt;- data_amp_test_trials %&gt;%\n  mutate(rt_s = rt_ms / 1000) # latency is now in seconds rather than milliseconds\n\n\nThe operations inside mutate can range from the very simple, like the above, to much more complex. The below example uses other functions we haven’t learned yet. For now, just notice that there can be multiple mutate calls and they can produce a cleaned up gender variable.\n\n\nCode\n# illustrate the problem with the gender responses:\ndata_demographics_trimmed %&gt;%\n  # filter only the gender item, not age\n  filter(item == \"gender\") %&gt;%\n  count(response) %&gt;%\n  arrange(desc(n))\n\n\n# A tibble: 11 × 2\n   response       n\n   &lt;chr&gt;      &lt;int&gt;\n 1 Male          36\n 2 female        27\n 3 male          18\n 4 Female        11\n 5 Non-Binary     2\n 6 23             1\n 7 FEMALE         1\n 8 MALE           1\n 9 Woman          1\n10 non binary     1\n11 yes            1\n\n\nCode\n# clean up the gender variable\ndata_demographics_gender_tidy_1 &lt;- data_demographics_trimmed %&gt;%\n  # filter only the gender item, not age\n  filter(item == \"gender\") %&gt;%\n  # change the name of the response variable to what it now represents: gender\n  rename(gender = response) %&gt;%\n  # change or remove weird responses to the gender question\n  mutate(gender = str_to_lower(gender)) %&gt;%\n  mutate(gender = str_remove_all(gender, \"[\\\\d.]\")) %&gt;% # remove everything except letters\n  mutate(gender = na_if(gender, \"\")) %&gt;% \n  mutate(gender = case_when(gender == \"woman\" ~ \"female\",\n                            gender == \"man\" ~ \"male\",\n                            gender == \"girl\" ~ \"female\",\n                            gender == \"yes\" ~ NA_character_,\n                            gender == \"dude\" ~ \"male\",\n                            gender == \"non binary\" ~ \"non-binary\",\n                            TRUE ~ gender)) %&gt;%\n  # select only the columns of interest\n  select(unique_id, gender)\n\n# illustrate the data after cleaning:\ndata_demographics_gender_tidy_1 %&gt;%\n  count(gender) %&gt;%\n  arrange(desc(n))\n\n\n# A tibble: 4 × 2\n  gender         n\n  &lt;chr&gt;      &lt;int&gt;\n1 male          55\n2 female        40\n3 non-binary     3\n4 &lt;NA&gt;           2\n\n\nA single mutate call can contain multiple mutates. The code from the last chunk could be written more simply like this:\n\n\nCode\n# clean up the gender variable\ndata_demographics_gender_tidy_2 &lt;- data_demographics_trimmed %&gt;%\n  # filter only the gender item, not age\n  filter(item == \"gender\") %&gt;%\n  # change the name of the response variable to what it now represents: gender\n  rename(gender = response) %&gt;%\n  # change or remove weird responses to the gender question\n  mutate(gender = str_to_lower(gender),\n         gender = str_remove_all(gender, \"[\\\\d.]\"), # remove everything except letters\n         gender = na_if(gender, \"\"), \n         gender = case_when(gender == \"woman\" ~ \"female\",\n                            gender == \"man\" ~ \"male\",\n                            gender == \"girl\" ~ \"female\",\n                            gender == \"yes\" ~ NA_character_,\n                            gender == \"dude\" ~ \"male\",\n                            gender == \"non binary\" ~ \"non-binary\",\n                            TRUE ~ gender)) %&gt;%\n  # select only the columns of interest\n  select(unique_id, gender)\n\n# check they are identical\nidentical(data_demographics_gender_tidy_1, data_demographics_gender_tidy_2)\n\n\n[1] TRUE\n\n\n\n\n5.8.2 Practice mutate()\nWhen analyzing cognitive behavioral tasks, it is common to employ mastery criteria to exclude participants who have not met or maintained some criterion within the task. We’ll do the actual exclusions etc. later on, but for practice using mutate() by creating a new fast_trial column to indicate trials where the response was implausibly fast (e.g., &lt; 100 ms).\nTry doing this with a simple logical test of whether latency &lt; 100. You can do this with or without using the ifelse() function.\n\n\nCode\ndata_amp_test_trials_with_fast_trials &lt;- data_amp_test_trials %&gt;%\n  mutate(fast_trial = ifelse(test = rt_ms &lt; 100,\n                             yes = TRUE,\n                             no = FALSE))\n\n# more briefly but less explicitly\ndata_amp_test_trials_with_fast_trials &lt;- data_amp_test_trials %&gt;%\n  mutate(fast_trial = rt_ms &lt; 100)\n\n\n\n\n5.8.3 Practice mutate() & learn ifelse()\nUse mutate() to remove weird values from data_demographics_trimmed$response, for the rows referring to age, that aren’t numbers.\nWhat function could you use to first determine what values are present in this column, to know which could be retained or changed?\nIn simple cases like this, you can use mutate() and ifelse() to change impossible values to NA.\n\n\nCode\n# what values are present?\ndata_demographics_trimmed %&gt;%\n  filter(item == \"age\") %&gt;%\n  count(response) \n\n\n# A tibble: 40 × 2\n   response     n\n   &lt;chr&gt;    &lt;int&gt;\n 1 18           1\n 2 19           4\n 3 20           1\n 4 21           6\n 5 22           2\n 6 23           5\n 7 24           1\n 8 25           3\n 9 26           4\n10 27           5\n# ℹ 30 more rows\n\n\nCode\n# fix them with mutate\ndata_demographics_age_tidy &lt;- data_demographics_trimmed %&gt;%\n  filter(item == \"age\") %&gt;%\n  mutate(response = ifelse(test = response == \"old\",\n                           yes = NA_integer_,\n                           no = response)) %&gt;%\n  mutate(response = as.numeric(response)) %&gt;%\n  rename(age = response)\n\n# check this has fixed the issue\ndata_demographics_age_tidy %&gt;%\n  count(age)\n\n\n# A tibble: 40 × 2\n     age     n\n   &lt;dbl&gt; &lt;int&gt;\n 1    18     1\n 2    19     4\n 3    20     1\n 4    21     6\n 5    22     2\n 6    23     5\n 7    24     1\n 8    25     3\n 9    26     4\n10    27     5\n# ℹ 30 more rows\n\n\n\n\n5.8.4 Practice mutate() & ifelse()\nUse mutate() to remove weird values from data_selfreport_trials$response that aren’t Likert responses.\nFirst determine what values are present in this column.\nUse ifelse() and %in% inside mutate() to change values other than the Likert responses to NA.\nIf you struggle to do this: practice writing ‘pseudocode’ here. That is, without knowing the right code, explain in precise logic what you want the computer to do. This can be converted to R more easily.\n\n\nCode\n# what values are present?\ndata_selfreport_trials %&gt;%\n  count(response)\n\n\n# A tibble: 8 × 2\n  response     n\n  &lt;chr&gt;    &lt;int&gt;\n1 1          193\n2 2           43\n3 3           26\n4 4           16\n5 5            7\n6 6            4\n7 7            3\n8 Ctrl+'B'     1\n\n\nCode\n# what type of data is the response column?\nclass(data_selfreport_trials$response)\n\n\n[1] \"character\"\n\n\nCode\n# remove non Likert values\ndata_selfreport_tidy &lt;- data_selfreport_trials %&gt;%\n  mutate(response = ifelse(response == \"Ctrl+'B'\", NA_integer_, response),\n         response = as.numeric(response))\n\n\n# show the data after changes\ndata_selfreport_tidy %&gt;%\n  count(response)\n\n\n# A tibble: 8 × 2\n  response     n\n     &lt;dbl&gt; &lt;int&gt;\n1        1   193\n2        2    43\n3        3    26\n4        4    16\n5        5     7\n6        6     4\n7        7     3\n8       NA     1\n\n\nCode\nclass(data_selfreport_tidy$response)\n\n\n[1] \"numeric\"\n\n\nWhat other ways are there of implementing this mutate, e.g., without using %in%? What are the pros and cons of each?\n\n\nCode\n# write examples here\n\n\n\n\n5.8.5 Practice mutate() & learn case_when()\ncase_when() allows you to compare multiple logical tests or if-else tests.\nThe AMP data needs to be reverse scored. Just like an item on a self-report that is worded negatively (e.g., most items: I am a good person; some items: I am a bad person), the negative prime trials have the opposite ‘accuracy’ values that they should. Use mutate() and case_when() to reverse score the negative prime trials, so that what was 0 is now 1 and what was 1 is now 0.\n\n\nCode\n# in your own time later, see if you can rewrite this yourself without looking at the answer to practice using case_when\ndata_amp_tidy &lt;- data_amp_test_trials_with_fast_trials %&gt;%\n  mutate(correct = case_when(trial_type == \"prime_positive\" ~ correct,\n                             trial_type == \"prime_negative\" & correct == 0 ~ 1,\n                             trial_type == \"prime_negative\" & correct == 1 ~ 0))\n\n# you can also specify a default value to return if none of the logical tests are passed with 'TRUE ~':\ndata_amp_tidy &lt;- data_amp_test_trials_with_fast_trials %&gt;%\n  mutate(correct = case_when(trial_type == \"prime_negative\" & correct == 0 ~ 1,\n                             trial_type == \"prime_negative\" & correct == 1 ~ 0,\n                             TRUE ~ correct))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#summarizing-across-rows",
    "href": "chapters/data_transformation.html#summarizing-across-rows",
    "title": "5  Data transformation",
    "section": "5.9 Summarizing across rows",
    "text": "5.9 Summarizing across rows\nIt is very common that we need to create summaries across rows. For example, to create the mean and standard deviation of a column like age. This can be done with summarize(). Remember: mutate() creates new columns or modifies the contents of existing columns, but does not change the number of rows. Whereas summarize() reduces a data frame down to one row.\n\n\nCode\n# mean\ndata_demographics_age_tidy %&gt;%\n  summarize(mean_age = mean(age, na.rm = TRUE))\n\n\n# A tibble: 1 × 1\n  mean_age\n     &lt;dbl&gt;\n1     35.7\n\n\nCode\n# SD\ndata_demographics_age_tidy %&gt;%\n  summarize(sd_age = sd(age, na.rm = TRUE))\n\n\n# A tibble: 1 × 1\n  sd_age\n   &lt;dbl&gt;\n1   12.4\n\n\nCode\n# mean and SD with rounding, illustrating how multiple summarizes can be done in one function call\ndata_demographics_age_tidy %&gt;%\n  summarize(mean_age = mean(age, na.rm = TRUE),\n            sd_age = sd(age, na.rm = TRUE)) |&gt;\n  mutate(mean_age = round_half_up(mean_age, digits = 2),\n         sd_age = round_half_up(sd_age, digits = 2))\n\n\n# A tibble: 1 × 2\n  mean_age sd_age\n     &lt;dbl&gt;  &lt;dbl&gt;\n1     35.7   12.4\n\n\n\n5.9.1 group_by()\nOften, we don’t want to reduce a data frame down to a single row / summarize the whole dataset, but instead we want to create a summary for each (sub)group. For example\n\n\nCode\n# # this code creates data needed for this example - you can simply load the data from disk and skip over this commented-out code. we will come back to things like 'joins' later\n# data_demographics_unique_participant_codes &lt;- data_demographics_trimmed %&gt;%\n#   count(unique_id) %&gt;%\n#   filter(n == 2)\n# \n# data_demographics_age_gender_tidy &lt;- data_demographics_trimmed %&gt;%\n#   semi_join(data_demographics_unique_participant_codes, by = \"unique_id\") %&gt;%\n#   pivot_wider(names_from = \"item\",\n#               values_from = \"response\") %&gt;%\n#   mutate(age = ifelse(age == \"old\", NA, age),\n#          age = as.numeric(age),\n#          gender = tolower(gender),\n#          gender = stringr::str_remove_all(gender, regex(\"\\\\W+\")), # regex is both very useful and awful to write\n#          gender = case_when(gender == \"female\" ~ gender,\n#                             gender == \"male\" ~ gender,\n#                             gender == \"nonbinary\" ~ gender,\n#                             gender == \"woman\" ~ \"female\",\n#                             gender == \"man\" ~ \"male\"))\n# \n# dir.create(\"../data/processed\")\n# write_csv(data_demographics_age_gender_tidy, \"../data/processed/data_demographics_age_gender_tidy.csv\")\n\n# load suitable example data from disk\ndata_demographics_age_gender_tidy &lt;-\n  read_csv(\"../data/processed/data_demographics_age_gender_tidy.csv\")\n\n\n# illustrate use of group_by() and summarize()\ndata_demographics_age_gender_tidy %&gt;%\n  summarize(mean_age = mean(age, na.rm = TRUE))\n\n\n# A tibble: 1 × 1\n  mean_age\n     &lt;dbl&gt;\n1     35.9\n\n\nCode\ndata_demographics_age_gender_tidy %&gt;%\n  group_by(gender) %&gt;%\n  summarize(mean_age = mean(age, na.rm = TRUE))\n\n\n# A tibble: 4 × 2\n  gender    mean_age\n  &lt;chr&gt;        &lt;dbl&gt;\n1 female        35.3\n2 male          37.3\n3 nonbinary     24.3\n4 &lt;NA&gt;          23  \n\n\n\n\n5.9.2 n()\nn() calculates the number of rows, i.e., the N. It can be useful in summarize.\n\n\nCode\n# summarize n\ndata_demographics_age_gender_tidy %&gt;%\n  summarize(n_age = n())\n\n\n# A tibble: 1 × 1\n  n_age\n  &lt;int&gt;\n1    98\n\n\nCode\n# summarize n per gender group\ndata_demographics_age_gender_tidy %&gt;%\n  group_by(gender) %&gt;%\n  summarize(n_age = n())\n\n\n# A tibble: 4 × 2\n  gender    n_age\n  &lt;chr&gt;     &lt;int&gt;\n1 female       40\n2 male         53\n3 nonbinary     3\n4 &lt;NA&gt;          2\n\n\nNote that count() is just the combination of group_by() and summiarize() and n()! they produce the same results as above.\n\n\nCode\n# summarize n\ndata_demographics_age_gender_tidy %&gt;%\n  count()\n\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1    98\n\n\nCode\n# summarize n per gender group\ndata_demographics_age_gender_tidy %&gt;%\n  count(gender)\n\n\n# A tibble: 4 × 2\n  gender        n\n  &lt;chr&gt;     &lt;int&gt;\n1 female       40\n2 male         53\n3 nonbinary     3\n4 &lt;NA&gt;          2\n\n\n\n\n5.9.3 More complex summarizations\nLike mutate, the operation you do to summarize can also be more complex, such as finding the mean result of a logical test to calculate a proportion. For example, the proportion of participants who are less than 25 years old:\n\n\nCode\ndata_demographics_age_tidy %&gt;%\n  summarize(proportion_less_than_25 = mean(age &lt; 25, na.rm = TRUE)) %&gt;%\n  mutate(percent_less_than_25 = round_half_up(proportion_less_than_25 * 100, 1))\n\n\n# A tibble: 1 × 2\n  proportion_less_than_25 percent_less_than_25\n                    &lt;dbl&gt;                &lt;dbl&gt;\n1                   0.202                 20.2\n\n\nYou can also summarize (or indeed mutate) multiple columns in the same way using across(), for do-this-across-columns. We won’t cover how to use this here or all the variations that are possible, just know that it can be done. For example:\n\n\nCode\n# using the mtcars dataset that is built in to {dplyr}, ... \nmtcars %&gt;%\n  # ... calculate the mean of every numeric column in the dataset ...\n  summarise(across(where(is.numeric), mean, na.rm = TRUE)) %&gt;%\n  # ... and then round every column to one decimal place\n  mutate(across(everything(), round_half_up, digits = 1))\n\n\n   mpg cyl  disp    hp drat  wt qsec  vs  am gear carb\n1 20.1 6.2 230.7 146.7  3.6 3.2 17.8 0.4 0.4  3.7  2.8\n\n\n\n\n5.9.4 Realise that count() is just a wrapper function for summarize()\n\n\nCode\ndat &lt;- data.frame(x = c(\n  rnorm(n = 50),\n  rep(NA_integer_, 10)\n))\n\ndat |&gt;\n  mutate(x_is_na = is.na(x)) |&gt;\n  count(x_is_na)\n\n\n  x_is_na  n\n1   FALSE 50\n2    TRUE 10\n\n\nCode\ndat |&gt;\n  summarise(n_na = sum(is.na(x)))\n\n\n  n_na\n1   10\n\n\n\n\n5.9.5 Practice using summarize()\nCalculate the min, max, mean, and SD of all responses on the self report data.\n\n\nCode\ndata_selfreport_tidy %&gt;%\n  summarize(mean = mean(response, na.rm = TRUE),\n            sd = sd(response, na.rm = TRUE),\n            min = min(response, na.rm = TRUE),\n            max = max(response, na.rm = TRUE))\n\n\n# A tibble: 1 × 4\n   mean    sd   min   max\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  1.72  1.26     1     7\n\n\nCurrently each participant has up to three responses on the self-report scales (three item scale: like, positive, and prefer). Create a new dataframe containing each unique_id’s mean score across the items. Also calculate how many items each participant has data for, and whether they have complete data (i.e., data for three items).\n\n\nCode\ndata_selfreport_scored &lt;- data_selfreport_tidy %&gt;%\n  group_by(unique_id) %&gt;%\n  summarize(mean_self_report = mean(response),\n            n_self_report_items = n()) %&gt;%\n  mutate(self_report_complete = n_self_report_items == 3)\n\n\n# test &lt;- c(3, 5, 7, NA)\n# #test &lt;- c(3, 5, 7)\n# mean(test)\n# mean(test, na.rm = TRUE)\n# \n# dat |&gt;\n#   summarize(mean = mean(response, na.rm = TRUE))\n# \n# dat |&gt;\n#   filter(!is.na(response)) |&gt;\n#   summarize(mean = mean(response))\n# \n# mean_not_dumb &lt;- function(x){mean(x, na.rm = TRUE)}\n\n\nUsing only participants with complete, calculate the mean and SD of all participant’s mean scores on the self-reports.\n\n\nCode\n# data_selfreport_scored %&gt;%\n\n\nCreate a new data frame that calculates the proportion of prime-congruent trials for each participant on the AMP (i.e., the mean of the ‘correct’ column), their proportion of too-fast trials, and their number of trials.\nAlso add to that data frame a new column called “exclude_amp” and set it to “exclude” if more than 10% of a participant’s trials are too-fast trials and “include” if not.\n\n\nCode\n# data_amp_scored &lt;- data_amp_tidy %&gt;%\n\n\nCalculate the proportion of participants who are to be excluded.\n\n\nCode\n# data_amp_scored %&gt;%",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#check-your-learning-1",
    "href": "chapters/data_transformation.html#check-your-learning-1",
    "title": "5  Data transformation",
    "section": "5.10 Check your learning",
    "text": "5.10 Check your learning\nWhat is the difference between mutate() and summarize()? If I use the wrong one, will I get the same answer? E.g., mutate(mean_age = mean(age, na.rm = TRUE)) vs. summarize(mean_age = mean(age, na.rm = TRUE))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/data_transformation.html#writing-data-to-disk",
    "href": "chapters/data_transformation.html#writing-data-to-disk",
    "title": "5  Data transformation",
    "section": "5.11 Writing data to disk",
    "text": "5.11 Writing data to disk\n\n\nCode\n# write_csv(data_processed, \"../data/processed/data_processed.csv\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "chapters/reshaping_and_pivots.html",
    "href": "chapters/reshaping_and_pivots.html",
    "title": "6  Reshaping and pivots",
    "section": "",
    "text": "6.1 Resources\nSee code and gifs here which illustrate pivots (and indeed other tidyverse verbs).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Reshaping and pivots</span>"
    ]
  },
  {
    "objectID": "chapters/reshaping_and_pivots.html#dependencies",
    "href": "chapters/reshaping_and_pivots.html#dependencies",
    "title": "6  Reshaping and pivots",
    "section": "6.2 Dependencies",
    "text": "6.2 Dependencies\n\n\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tibble)\n#install.packages(\"devtools\")\n#devtools::install_github(\"debruine/faux\")\nlibrary(faux)\nlibrary(janitor)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(psych)\nlibrary(readr)\nlibrary(knitr)\nlibrary(kableExtra)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Reshaping and pivots</span>"
    ]
  },
  {
    "objectID": "chapters/reshaping_and_pivots.html#example",
    "href": "chapters/reshaping_and_pivots.html#example",
    "title": "6  Reshaping and pivots",
    "section": "6.3 Example",
    "text": "6.3 Example\n\n6.3.1 Simulate data in wide format\n\n\nCode\n# set seed for reproducibility\nset.seed(123)\n\n# generate data \ndata_wide &lt;- \n  faux::rnorm_multi(n = 100,\n                    vars = 5,\n                    mu = 3,\n                    sd = 1,\n                    r = 0.5,\n                    varnames = paste0(\"item_\", 1:5),\n                    empirical = FALSE) %&gt;%\n  rownames_to_column(var = \"id\")\n\n# recode responses less than 1 or more than 5 to those values, then round scores to whole numbers\n# note that {faux} has functions for doing this better\n\n\n# dat &lt;- data_wide |&gt;\n#   mutate(item_1 = round_half_up(item_1, digits = 0),\n#          item_1 = ifewlse\n\ndata_wide_likert &lt;- data_wide %&gt;%\n  mutate(across(starts_with(\"item_\"), ~ round_half_up(.x, digits = 0))) %&gt;%\n  mutate(across(starts_with(\"item_\"), ~ ifelse(.x &lt; 1, 1, ifelse(.x &gt; 5, 5, .x))))\n\n\n\n\n6.3.2 Cronbach’s alpha\nWide data like this is a) common and b) useful for calculating metrics like internal consistency.\n\n\nCode\nres_alpha &lt;- data_wide_likert %&gt;%\n  #select(-id) %&gt;%\n  select(starts_with(\"item_\")) %&gt;%\n  psych::alpha()\n\ncronbachs_alpha_estimate &lt;- res_alpha$total$raw_alpha |&gt;\n  round_half_up(digits = 2)\n\n\nCronbach’s \\(\\alpha\\) = 0.79\n\n\n6.3.3 Plot simulated data\n\n\nCode\nggplot(data_wide_likert, aes(x = item_1)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nCode\nggplot(data_wide_likert, aes(x = item_2)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nCode\nggplot(data_wide_likert, aes(x = item_3)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nCode\nggplot(data_wide_likert, aes(x = item_4)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nCode\nggplot(data_wide_likert, aes(x = item_5)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n\nThese plots repeat the mortal coding sin of repeating ourselves. If we reshaped the data to ‘long’ format we could use just one ggplot() call that includes facet_wrap().\n\n\n\n6.3.4 Reshape\nUsing pivot_longer().\n\n\nCode\n# positive selection\ndata_long &lt;- data_wide_likert %&gt;%\n  pivot_longer(cols = starts_with(\"item_\"),\n               names_to = \"item\",\n               values_to = \"response\")\n\n# positive selection using a different tidy select function\ndata_long &lt;- data_wide_likert %&gt;%\n  pivot_longer(cols = contains(\"item_\"),\n               names_to = \"item\",\n               values_to = \"response\")\n\n# negative selection\ndata_long &lt;- data_wide_likert %&gt;%\n  pivot_longer(cols = -id,\n               names_to = \"item\",\n               values_to = \"response\") |&gt;\n  mutate(item = stringr::str_remove(item, \"item_\"))\n\nggplot(data_long, aes(x = response)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw() +\n  facet_wrap(~ item)\n\n\n\n\n\n\n\n\n\n\nWhat other ways could you specify this pivot_longer call’s arguments?\nfacet_wrap() is to {ggplot} as group_by() is to {dplyr}\n\n\n6.3.4.1 Calculate sum scores\n\n\nCode\ntemp &lt;- data_wide_likert |&gt;\n  group_by(id) |&gt;\n  mutate(sum_score = item_1 + item_2 + item_3 + item_4 + item_5)\n  #mutate(sum_score = rowSums(item_1, item_2, item_3, item_4, item_5))\n\n\n\nrow math is much faster than column math in R!\n\n\n\nCode\nsum_scores &lt;- data_long %&gt;%\n  group_by(id) %&gt;%\n  summarise(sum_score = sum(response))\n\n\nggplot(sum_scores, aes(x = sum_score)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  scale_x_continuous(breaks = breaks_pretty(n = 10)) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n\n\n\n6.3.5 Convert this long data back to wide\nJust to know how to do it.\n\n\nCode\ndata_wide_again &lt;- data_long %&gt;%\n  pivot_wider(names_from = item,\n              values_from = response,\n              names_prefix = \"item_\")\n\n\n\n\n6.3.6 Combine item and sum scores in one data frame\n\n\nCode\ndata_item_and_sum_scores &lt;- data_wide_again %&gt;%\n  left_join(sum_scores, by = \"id\")\n\n# why joins are needed over bind_cols \n# wrong &lt;- bind_cols(data_wide_again, sum_scores |&gt; select(-id))",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Reshaping and pivots</span>"
    ]
  },
  {
    "objectID": "chapters/reshaping_and_pivots.html#new-facet-plot-with-items-and-sum-score",
    "href": "chapters/reshaping_and_pivots.html#new-facet-plot-with-items-and-sum-score",
    "title": "6  Reshaping and pivots",
    "section": "6.4 New facet plot with items and sum score",
    "text": "6.4 New facet plot with items and sum score\n\n\nCode\ndata_long_with_sum_score &lt;- data_item_and_sum_scores %&gt;%\n  pivot_longer(cols = -id,\n               names_to = \"item\",\n               values_to = \"response\")\n\nggplot(data_long_with_sum_score, aes(x = response)) +\n  geom_histogram(binwidth = 1, boundary = -0.5) +\n  theme_linedraw() +\n  facet_wrap(~ item, scales = \"free\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Reshaping and pivots</span>"
    ]
  },
  {
    "objectID": "chapters/reshaping_and_pivots.html#practice",
    "href": "chapters/reshaping_and_pivots.html#practice",
    "title": "6  Reshaping and pivots",
    "section": "6.5 Practice",
    "text": "6.5 Practice\nWrangle the demographics data included in this exercise more efficiently by reshaping it into wide format. Before, we used filter() to wrangle the age and gender data separately.\n\n\nCode\ndat &lt;- read_csv(\"../data/raw/data_demographics_raw.csv\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Reshaping and pivots</span>"
    ]
  },
  {
    "objectID": "chapters/joins.html",
    "href": "chapters/joins.html",
    "title": "7  Joins",
    "section": "",
    "text": "7.1 Dependencies\nCode\nlibrary(dplyr)\nlibrary(readr)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "chapters/joins.html#get-data",
    "href": "chapters/joins.html#get-data",
    "title": "7  Joins",
    "section": "7.2 Get data",
    "text": "7.2 Get data\n\n\nCode\ndata_unique_id_subset &lt;- read_csv(\"../data/raw/data_unique_id_subset.csv\")\ndata_age_gender_subset &lt;- read_csv(\"../data/raw/data_age_gender_subset.csv\")\ndata_amp_summary_subset &lt;- read_csv(\"../data/raw/data_amp_summary_subset.csv\")\ndata_selfreport_summary_subset &lt;- read_csv(\"../data/raw/data_selfreport_summary_subset.csv\")\n\nnrow(data_unique_id_subset)\n\n\n[1] 92\n\n\nCode\nnrow(data_age_gender_subset)\n\n\n[1] 90\n\n\nCode\nnrow(data_amp_summary_subset)\n\n\n[1] 31\n\n\nCode\nnrow(data_selfreport_summary_subset)\n\n\n[1] 76",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "chapters/joins.html#practicing-joins",
    "href": "chapters/joins.html#practicing-joins",
    "title": "7  Joins",
    "section": "7.3 Practicing joins",
    "text": "7.3 Practicing joins\nUsing the data frames below and functions from the _join family, write code to do the following joins.\n\n7.3.1 Practice 1\ncreate ‘data_combined’ by joining data_amp_summary_subset and data_age_gender_subset so that unique_ids in either data frame are retained. which join is this? implement it.\n\n\nCode\n# data_combined &lt;- \n\n\n\n\n7.3.2 Practice 2\ncreate ‘data_self_reports_and_their_amp_data’ by joining data_selfreport_summary_subset and data_amp_summary_subset so that all participants have self-report data, + AMP data if available. which join is this? implement it.\n\n\nCode\n# data_self_reports_and_their_amp_data &lt;- \n\n\n\n\n7.3.3 Practice 3\ndo the opposite: create ‘data_amp_data_and_their_self_reports’ by joining data_amp_summary_subset and data_selfreport_summary_subset so that all participants have AMP data, + self-report data if available. which join is this? implement it.\n\n\nCode\n# data_amp_data_and_their_self_reports &lt;- \n\n\n\n\n7.3.4 Practice 4\ncreate data_combined_2 by joining ‘data_combined’ and data_selfreport_summary_subset only unique_ids already present in data_combined are retained. which join is this? implement it.\n\n\nCode\n# data_combined_2 &lt;- \n\n\n\n\n7.3.5 Practice 5\ncreate ‘data_missing_ids’ which should list the unique_ids are missing from data_unique_id_subset but are present in at least one of data_age_gender_subset, data_amp_summary_subset, and data_selfreport_summary_subset. This will require two different joins. Which? Implement them.\n\n\nCode\n# data_missing_ids &lt;-",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "chapters/reporting.html",
    "href": "chapters/reporting.html",
    "title": "8  Reporting",
    "section": "",
    "text": "8.1 Dependencies\nCode\nlibrary(dplyr)\nlibrary(readr)\nlibrary(report) # part of {easystats}\nlibrary(see) # part of {easystats}\nlibrary(parameters) # part of {easystats}\nlibrary(correlation) # part of {easystats}\nlibrary(effectsize) # part of {easystats}\nlibrary(performance) # part of {easystats}\nlibrary(janitor)\nlibrary(lme4)\nlibrary(knitr)\nlibrary(kableExtra)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Reporting</span>"
    ]
  },
  {
    "objectID": "chapters/reporting.html#inference-tests",
    "href": "chapters/reporting.html#inference-tests",
    "title": "8  Reporting",
    "section": "8.2 Inference tests",
    "text": "8.2 Inference tests\n\n8.2.1 Regressions\n\n\nCode\n# fit model\nmodel &lt;- lm(wt ~ 1 + am + mpg, data = mtcars)\n\n# report - text output (nb omits intercept!)\nreport(model)\n\n\nWe fitted a linear model (estimated using OLS) to predict wt with am and mpg\n(formula: wt ~ 1 + am + mpg). The model explains a statistically significant\nand substantial proportion of variance (R2 = 0.80, F(2, 29) = 57.66, p &lt; .001,\nadj. R2 = 0.79). The model's intercept, corresponding to am = 0 and mpg = 0, is\nat 5.74 (95% CI [5.11, 6.36], t(29) = 18.64, p &lt; .001). Within this model:\n\n  - The effect of am is statistically significant and negative (beta = -0.53, 95%\nCI [-0.94, -0.11], t(29) = -2.58, p = 0.015; Std. beta = -0.27, 95% CI [-0.48,\n-0.06])\n  - The effect of mpg is statistically significant and negative (beta = -0.11,\n95% CI [-0.15, -0.08], t(29) = -6.79, p &lt; .001; Std. beta = -0.71, 95% CI\n[-0.92, -0.49])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nCode\n# each parameter (including intercept)\nreport_parameters(model)\n\n\n  - The intercept is statistically significant and positive (beta = 5.74, 95% CI [5.11, 6.36], t(29) = 18.64, p &lt; .001; Std. beta = 1.10e-16, 95% CI [-0.17, 0.17])\n  - The effect of am is statistically significant and negative (beta = -0.53, 95% CI [-0.94, -0.11], t(29) = -2.58, p = 0.015; Std. beta = -0.27, 95% CI [-0.48, -0.06])\n  - The effect of mpg is statistically significant and negative (beta = -0.11, 95% CI [-0.15, -0.08], t(29) = -6.79, p &lt; .001; Std. beta = -0.71, 95% CI [-0.92, -0.49])\n\n\nCode\n# just parameters in text format\nreport_statistics(model)\n\n\nbeta = 5.74, 95% CI [5.11, 6.36], t(29) = 18.64, p &lt; .001; Std. beta = 1.10e-16, 95% CI [-0.17, 0.17]\nbeta = -0.53, 95% CI [-0.94, -0.11], t(29) = -2.58, p = 0.015; Std. beta = -0.27, 95% CI [-0.48, -0.06]\nbeta = -0.11, 95% CI [-0.15, -0.08], t(29) = -6.79, p &lt; .001; Std. beta = -0.71, 95% CI [-0.92, -0.49]\n\n\nCode\n# just parameters in table format\nparameters(model)\n\n\nParameter   | Coefficient |   SE |         95% CI | t(29) |      p\n------------------------------------------------------------------\n(Intercept) |        5.74 | 0.31 | [ 5.11,  6.36] | 18.64 | &lt; .001\nam          |       -0.53 | 0.20 | [-0.94, -0.11] | -2.58 | 0.015 \nmpg         |       -0.11 | 0.02 | [-0.15, -0.08] | -6.79 | &lt; .001\n\n\nCode\n# just parameters in table html format \nparameters(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\n\n\n\n\n(Intercept)\n5.74\n0.31\n0.95\n5.11\n6.36\n18.64\n29\np &lt; .001\n\n\nam\n-0.53\n0.20\n0.95\n-0.94\n-0.11\n-2.58\n29\np = 0.015\n\n\nmpg\n-0.11\n0.02\n0.95\n-0.15\n-0.08\n-6.79\n29\np &lt; .001\n\n\n\n\n\n\n\nCode\n# what if i just want some of these cols?\nparameters(model) |&gt;\n  as.data.frame() |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  select(r = Coefficient, ci_lower = CI_low, ci_upper = CI_high, p) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2)\n\n\n      r ci_lower ci_upper         p\n1  5.74     5.11     6.36  p &lt; .001\n2 -0.53    -0.94    -0.11 p = 0.015\n3 -0.11    -0.15    -0.08  p &lt; .001\n\n\nCode\n# table in markdown format\nreport_table(model)\n\n\nParameter   | Coefficient |         95% CI | t(29) |      p | Std. Coef.\n------------------------------------------------------------------------\n(Intercept) |        5.74 | [ 5.11,  6.36] | 18.64 | &lt; .001 |   1.10e-16\nam          |       -0.53 | [-0.94, -0.11] | -2.58 | 0.015  |      -0.27\nmpg         |       -0.11 | [-0.15, -0.08] | -6.79 | &lt; .001 |      -0.71\n            |             |                |       |        |           \nAIC         |             |                |       |        |           \nAICc        |             |                |       |        |           \nBIC         |             |                |       |        |           \nR2          |             |                |       |        |           \nR2 (adj.)   |             |                |       |        |           \nSigma       |             |                |       |        |           \n\nParameter   | Std. Coef. 95% CI |   Fit\n---------------------------------------\n(Intercept) |    [-0.17,  0.17] |      \nam          |    [-0.48, -0.06] |      \nmpg         |    [-0.92, -0.49] |      \n            |                   |      \nAIC         |                   | 45.05\nAICc        |                   | 46.53\nBIC         |                   | 50.91\nR2          |                   |  0.80\nR2 (adj.)   |                   |  0.79\nSigma       |                   |  0.45\n\n\nCode\n# table in html format - needs to be rounded manually\nreport_table(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\n\nParameter\nCoefficient\nCI\nCI_low\nCI_high\nt\ndf_error\np\nStd_Coefficient\nStd_Coefficient_CI_low\nStd_Coefficient_CI_high\nFit\n\n\n\n\n1\n(Intercept)\n5.74\n0.95\n5.11\n6.36\n18.64\n29\np &lt; .001\n0.00\n-0.17\n0.17\nNA\n\n\n2\nam\n-0.53\n0.95\n-0.94\n-0.11\n-2.58\n29\np = 0.015\n-0.27\n-0.48\n-0.06\nNA\n\n\n3\nmpg\n-0.11\n0.95\n-0.15\n-0.08\n-6.79\n29\np &lt; .001\n-0.71\n-0.92\n-0.49\nNA\n\n\n4\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\n\n\n5\nAIC\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n45.05\n\n\n6\nAICc\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n46.53\n\n\n7\nBIC\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n50.91\n\n\n8\nR2\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n0.80\n\n\n9\nR2 (adj.)\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n0.79\n\n\n11\nSigma\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\n0.45\n\n\n\n\n\n\n\nCode\n# plot\nparameters(model) |&gt;\n  plot() \n\n\n\n\n\n\n\n\n\n\n\n8.2.2 Correlations\n\n8.2.2.1 Single correlation tests\n\n\nCode\n# fit model\nmodel &lt;- cor.test(mtcars$mpg, mtcars$wt)\n\n# report - text output \nreport(model)\n\n\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Pearson's product-moment correlation between mtcars$mpg and mtcars$wt is\nnegative, statistically significant, and very large (r = -0.87, 95% CI [-0.93,\n-0.74], t(30) = -9.56, p &lt; .001)\n\n\nCode\n# table in html format - needs to be rounded manually\nreport_table(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nAlternative\n\n\n\n\nmtcars$mpg\nmtcars$wt\n-0.87\n0.95\n-0.93\n-0.74\n-9.56\n30\np &lt; .001\nPearson's product-moment correlation\ntwo.sided\n\n\n\n\n\n\n\n\n\n8.2.2.2 Many\n\n\nCode\nresults &lt;- correlation(iris)\n\nresults\n\n\n# Correlation Matrix (pearson-method)\n\nParameter1   |   Parameter2 |     r |         95% CI | t(148) |         p\n-------------------------------------------------------------------------\nSepal.Length |  Sepal.Width | -0.12 | [-0.27,  0.04] |  -1.44 | 0.152    \nSepal.Length | Petal.Length |  0.87 | [ 0.83,  0.91] |  21.65 | &lt; .001***\nSepal.Length |  Petal.Width |  0.82 | [ 0.76,  0.86] |  17.30 | &lt; .001***\nSepal.Width  | Petal.Length | -0.43 | [-0.55, -0.29] |  -5.77 | &lt; .001***\nSepal.Width  |  Petal.Width | -0.37 | [-0.50, -0.22] |  -4.79 | &lt; .001***\nPetal.Length |  Petal.Width |  0.96 | [ 0.95,  0.97] |  43.39 | &lt; .001***\n\np-value adjustment method: Holm (1979)\nObservations: 150\n\n\nCode\nresults %&gt;%\n  summary(redundant = TRUE) %&gt;%\n  plot()\n\n\n\n\n\n\n\n\n\n\n\n8.2.2.3 By group\n\n\nCode\niris %&gt;%\n  select(Species, Sepal.Length, Sepal.Width, Petal.Width) %&gt;%\n  group_by(Species) %&gt;%\n  correlation()\n\n\n# Correlation Matrix (pearson-method)\n\nGroup      |   Parameter1 |  Parameter2 |    r |        95% CI | t(48) |         p\n----------------------------------------------------------------------------------\nsetosa     | Sepal.Length | Sepal.Width | 0.74 | [ 0.59, 0.85] |  7.68 | &lt; .001***\nsetosa     | Sepal.Length | Petal.Width | 0.28 | [ 0.00, 0.52] |  2.01 | 0.101    \nsetosa     |  Sepal.Width | Petal.Width | 0.23 | [-0.05, 0.48] |  1.66 | 0.104    \nversicolor | Sepal.Length | Sepal.Width | 0.53 | [ 0.29, 0.70] |  4.28 | &lt; .001***\nversicolor | Sepal.Length | Petal.Width | 0.55 | [ 0.32, 0.72] |  4.52 | &lt; .001***\nversicolor |  Sepal.Width | Petal.Width | 0.66 | [ 0.47, 0.80] |  6.15 | &lt; .001***\nvirginica  | Sepal.Length | Sepal.Width | 0.46 | [ 0.20, 0.65] |  3.56 | 0.002**  \nvirginica  | Sepal.Length | Petal.Width | 0.28 | [ 0.00, 0.52] |  2.03 | 0.048*   \nvirginica  |  Sepal.Width | Petal.Width | 0.54 | [ 0.31, 0.71] |  4.42 | &lt; .001***\n\np-value adjustment method: Holm (1979)\nObservations: 50\n\n\n\n\n\n8.2.3 t-tests\nNB Cohen’s d is approximated - better to calculate it separately and accurately.\n\n\nCode\n# fit model\nmodel &lt;- t.test(mpg ~ am, data = mtcars)\n\n# report - text output \nreport(model)\n\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference of mpg by am (mean in group\n0 = 17.15, mean in group 1 = 24.39) suggests that the effect is negative,\nstatistically significant, and large (difference = -7.24, 95% CI [-11.28,\n-3.21], t(18.33) = -3.77, p = 0.001; Cohen's d = -1.76, 95% CI [-2.82, -0.67])\n\n\nCode\n# table in html format - needs to be rounded manually\nreport_table(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nParameter\nGroup\nMean_Group1\nMean_Group2\nDifference\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nAlternative\nd\nd_CI_low\nd_CI_high\n\n\n\n\nmpg\nam\n17.15\n24.39\n-7.24\n0.95\n-11.28\n-3.21\n-3.77\n18.33\np = 0.001\nWelch Two Sample t-test\ntwo.sided\n-1.76\n-2.82\n-0.67\n\n\n\n\n\n\n\nCode\n# estimate Cohen's d directly from data\ncohens_d(mpg ~ am, data = mtcars)\n\n\nCohen's d |         95% CI\n--------------------------\n-1.48     | [-2.27, -0.67]\n\n- Estimated using pooled SD.\n\n\n\n\n8.2.4 Multilevel/hierarchical/mixed models\n\n\nCode\n# fit model\nmodel &lt;- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)\n\n# parameters in text format \nreport(model)\n\n\nWe fitted a linear mixed model (estimated using REML and nloptwrap optimizer)\nto predict Reaction with Days (formula: Reaction ~ Days). The model included\nDays as random effects (formula: ~Days | Subject). The model's total\nexplanatory power is substantial (conditional R2 = 0.80) and the part related\nto the fixed effects alone (marginal R2) is of 0.28. The model's intercept,\ncorresponding to Days = 0, is at 251.41 (95% CI [237.94, 264.87], t(174) =\n36.84, p &lt; .001). Within this model:\n\n  - The effect of Days is statistically significant and positive (beta = 10.47,\n95% CI [7.42, 13.52], t(174) = 6.77, p &lt; .001; Std. beta = 0.54, 95% CI [0.38,\n0.69])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nCode\n# parameters in table format\nparameters(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\nEffects\nGroup\n\n\n\n\n(Intercept)\n251.41\n6.82\n0.95\n237.94\n264.87\n36.84\n174\np &lt; .001\nfixed\n\n\n\nDays\n10.47\n1.55\n0.95\n7.42\n13.52\n6.77\n174\np &lt; .001\nfixed\n\n\n\nSD (Intercept)\n24.74\nNA\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\n\n\nSD (Days)\n5.92\nNA\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\n\n\nCor (Intercept~Days)\n0.07\nNA\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\n\n\nSD (Observations)\n25.59\nNA\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nResidual\n\n\n\n\n\n\n\nCode\n# table in html format - needs to be rounded manually\nreport_table(model) |&gt;\n  mutate(p = insight::format_p(p)) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\n\nParameter\nCoefficient\nCI\nCI_low\nCI_high\nt\ndf_error\np\nEffects\nGroup\nStd_Coefficient\nStd_Coefficient_CI_low\nStd_Coefficient_CI_high\nFit\n\n\n\n\n1\n(Intercept)\n251.41\n0.95\n237.94\n264.87\n36.84\n174\np &lt; .001\nfixed\n\n0.00\n-0.32\n0.32\nNA\n\n\n2\nDays\n10.47\n0.95\n7.42\n13.52\n6.77\n174\np &lt; .001\nfixed\n\n0.54\n0.38\n0.69\nNA\n\n\n3\nNA\n24.74\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\nNA\nNA\nNA\nNA\n\n\n4\nNA\n5.92\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\nNA\nNA\nNA\nNA\n\n\n5\nNA\n0.07\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nSubject\nNA\nNA\nNA\nNA\n\n\n6\nNA\n25.59\n0.95\nNA\nNA\nNA\nNA\n\nrandom\nResidual\nNA\nNA\nNA\nNA\n\n\n7\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n8\nAIC\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n1755.63\n\n\n9\nAICc\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n1756.11\n\n\n10\nBIC\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n1774.79\n\n\n11\nR2 (conditional)\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n0.80\n\n\n12\nR2 (marginal)\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n0.28\n\n\n15\nSigma\nNA\nNA\nNA\nNA\nNA\nNA\n\nNA\nNA\nNA\nNA\nNA\n25.59\n\n\n\n\n\n\n\nCode\n# plot\nparameters(model) |&gt;\n  plot() \n\n\n\n\n\n\n\n\n\nCode\n# check assumptions of random effects\nresult &lt;- check_normality(model, effects = \"random\")\nplot(result)\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n8.2.5 ANOVAs\n\n\nCode\n# fit model\nmodel &lt;- aov(mpg ~ factor(gear) + factor(carb), data = mtcars)\n\n# commonly used effect size: partial eta squared\neta_squared(model)\n\n\n# Effect Size for ANOVA (Type I)\n\nParameter    | Eta2 (partial) |       95% CI\n--------------------------------------------\nfactor(gear) |           0.69 | [0.49, 1.00]\nfactor(carb) |           0.66 | [0.41, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\nCode\n# better effect size: partialomega squared\nomega_squared(model)\n\n\n# Effect Size for ANOVA (Type I)\n\nParameter    | Omega2 (partial) |       95% CI\n----------------------------------------------\nfactor(gear) |             0.62 | [0.38, 1.00]\nfactor(carb) |             0.57 | [0.26, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Reporting</span>"
    ]
  },
  {
    "objectID": "chapters/reporting.html#summary-statistics",
    "href": "chapters/reporting.html#summary-statistics",
    "title": "8  Reporting",
    "section": "8.3 Summary statistics",
    "text": "8.3 Summary statistics\n\n\nCode\n# all columns\niris |&gt;\n  group_by(Species) |&gt;\n  report_table() \n\n\nGroup      |     Variable | n_Obs | Mean |   SD | Median |  MAD |  Min |  Max\n-----------------------------------------------------------------------------\nsetosa     | Sepal.Length |    50 | 5.01 | 0.35 |   5.00 | 0.30 | 4.30 | 5.80\nsetosa     |  Sepal.Width |    50 | 3.43 | 0.38 |   3.40 | 0.37 | 2.30 | 4.40\nsetosa     | Petal.Length |    50 | 1.46 | 0.17 |   1.50 | 0.15 | 1.00 | 1.90\nsetosa     |  Petal.Width |    50 | 0.25 | 0.11 |   0.20 | 0.00 | 0.10 | 0.60\nversicolor | Sepal.Length |    50 | 5.94 | 0.52 |   5.90 | 0.52 | 4.90 | 7.00\nversicolor |  Sepal.Width |    50 | 2.77 | 0.31 |   2.80 | 0.30 | 2.00 | 3.40\nversicolor | Petal.Length |    50 | 4.26 | 0.47 |   4.35 | 0.52 | 3.00 | 5.10\nversicolor |  Petal.Width |    50 | 1.33 | 0.20 |   1.30 | 0.22 | 1.00 | 1.80\nvirginica  | Sepal.Length |    50 | 6.59 | 0.64 |   6.50 | 0.59 | 4.90 | 7.90\nvirginica  |  Sepal.Width |    50 | 2.97 | 0.32 |   3.00 | 0.30 | 2.20 | 3.80\nvirginica  | Petal.Length |    50 | 5.55 | 0.55 |   5.55 | 0.67 | 4.50 | 6.90\nvirginica  |  Petal.Width |    50 | 2.03 | 0.27 |   2.00 | 0.30 | 1.40 | 2.50\n\nGroup      | Skewness | Kurtosis | n_Missing\n--------------------------------------------\nsetosa     |     0.12 |    -0.25 |         0\nsetosa     |     0.04 |     0.95 |         0\nsetosa     |     0.11 |     1.02 |         0\nsetosa     |     1.25 |     1.72 |         0\nversicolor |     0.11 |    -0.53 |         0\nversicolor |    -0.36 |    -0.37 |         0\nversicolor |    -0.61 |     0.05 |         0\nversicolor |    -0.03 |    -0.41 |         0\nvirginica  |     0.12 |     0.03 |         0\nvirginica  |     0.37 |     0.71 |         0\nvirginica  |     0.55 |    -0.15 |         0\nvirginica  |    -0.13 |    -0.60 |         0\n\n\nCode\n# all columns - html output with rounding\niris |&gt;\n  group_by(Species) |&gt;\n  report_table() |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nGroup\nVariable\nn_Obs\nMean\nSD\nMedian\nMAD\nMin\nMax\nSkewness\nKurtosis\nn_Missing\n\n\n\n\nsetosa\nSepal.Length\n50\n5.01\n0.35\n5.00\n0.30\n4.3\n5.8\n0.12\n-0.25\n0\n\n\nsetosa\nSepal.Width\n50\n3.43\n0.38\n3.40\n0.37\n2.3\n4.4\n0.04\n0.95\n0\n\n\nsetosa\nPetal.Length\n50\n1.46\n0.17\n1.50\n0.15\n1.0\n1.9\n0.11\n1.02\n0\n\n\nsetosa\nPetal.Width\n50\n0.25\n0.11\n0.20\n0.00\n0.1\n0.6\n1.25\n1.72\n0\n\n\nversicolor\nSepal.Length\n50\n5.94\n0.52\n5.90\n0.52\n4.9\n7.0\n0.11\n-0.53\n0\n\n\nversicolor\nSepal.Width\n50\n2.77\n0.31\n2.80\n0.30\n2.0\n3.4\n-0.36\n-0.37\n0\n\n\nversicolor\nPetal.Length\n50\n4.26\n0.47\n4.35\n0.52\n3.0\n5.1\n-0.61\n0.05\n0\n\n\nversicolor\nPetal.Width\n50\n1.33\n0.20\n1.30\n0.22\n1.0\n1.8\n-0.03\n-0.41\n0\n\n\nvirginica\nSepal.Length\n50\n6.59\n0.64\n6.50\n0.59\n4.9\n7.9\n0.12\n0.03\n0\n\n\nvirginica\nSepal.Width\n50\n2.97\n0.32\n3.00\n0.30\n2.2\n3.8\n0.37\n0.71\n0\n\n\nvirginica\nPetal.Length\n50\n5.55\n0.55\n5.55\n0.67\n4.5\n6.9\n0.55\n-0.15\n0\n\n\nvirginica\nPetal.Width\n50\n2.03\n0.27\n2.00\n0.30\n1.4\n2.5\n-0.13\n-0.60\n0\n\n\n\n\n\n\n\nCode\n# subset of columns\niris |&gt;\n  group_by(Species) |&gt;\n  report_table() |&gt;\n  select(Group, Variable, n_Obs, Mean, SD) |&gt;\n  mutate_if(is.numeric, round_half_up, digits = 2) |&gt;\n  kable() |&gt;\n  kable_classic(full_width = FALSE)\n\n\n\n\n\nGroup\nVariable\nn_Obs\nMean\nSD\n\n\n\n\nsetosa\nSepal.Length\n50\n5.01\n0.35\n\n\nsetosa\nSepal.Width\n50\n3.43\n0.38\n\n\nsetosa\nPetal.Length\n50\n1.46\n0.17\n\n\nsetosa\nPetal.Width\n50\n0.25\n0.11\n\n\nversicolor\nSepal.Length\n50\n5.94\n0.52\n\n\nversicolor\nSepal.Width\n50\n2.77\n0.31\n\n\nversicolor\nPetal.Length\n50\n4.26\n0.47\n\n\nversicolor\nPetal.Width\n50\n1.33\n0.20\n\n\nvirginica\nSepal.Length\n50\n6.59\n0.64\n\n\nvirginica\nSepal.Width\n50\n2.97\n0.32\n\n\nvirginica\nPetal.Length\n50\n5.55\n0.55\n\n\nvirginica\nPetal.Width\n50\n2.03\n0.27",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Reporting</span>"
    ]
  },
  {
    "objectID": "chapters/reporting.html#assumption-checks",
    "href": "chapters/reporting.html#assumption-checks",
    "title": "8  Reporting",
    "section": "8.4 Assumption checks",
    "text": "8.4 Assumption checks\nBeware that checking assumptions can lead to as many bad practices as it does good ones! (e.g., poorly justified post hoc outlier exclusion)\n\n8.4.1 Multiple checks at once\n\n\nCode\n# fit model\nmodel &lt;- lm(wt ~ 1 + am + mpg, data = mtcars)\n\n# check multiple model assumptions\ncheck_model(model)\n\n\n\n\n\n\n\n\n\n\n\n8.4.2 Normality of distribution of residuals\n\n\nCode\nres_normality &lt;- check_normality(model)\n\nres_normality\n\n\nWarning: Non-normality of residuals detected (p = 0.013).\n\n\nCode\nplot(res_normality, type = \"qq\")\n\n\n\n\n\n\n\n\n\nCode\nplot(res_normality, type = \"density\")\n\n\n\n\n\n\n\n\n\n\n\n8.4.3 Multicolinearity\n\n\nCode\nres_collinearity &lt;- check_collinearity(model)\n\nres_collinearity\n\n\n# Check for Multicollinearity\n\nLow Correlation\n\n Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n   am 1.56 [1.19, 2.68]         1.25      0.64     [0.37, 0.84]\n  mpg 1.56 [1.19, 2.68]         1.25      0.64     [0.37, 0.84]\n\n\nCode\nplot(res_collinearity)\n\n\n\n\n\n\n\n\n\n\n\n8.4.4 Outliers\n\n\nCode\nres_outliers &lt;- check_outliers(model, method = \"cook\") # \"all\" requires other dependencies and can take some time to run  \n#res_outliers &lt;- check_outliers(model, method = \"all\") # \"all\" requires other dependencies and can take some time to run  \n\nres_outliers\n\n\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.808).\n- For variable: (Whole model)\n\n\nCode\nplot(res_outliers)\n\n\n\n\n\n\n\n\n\n\n\n8.4.5 Heteroscedasticity\n\n\nCode\nres_het &lt;- check_heteroscedasticity(model)\n\nres_het\n\n\nOK: Error variance appears to be homoscedastic (p = 0.053).\n\n\nCode\nplot(res_het)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Reporting</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html",
    "href": "chapters/visualization.html",
    "title": "9  Visualization",
    "section": "",
    "text": "10 Dependencies\nCode\nlibrary(readr)\nlibrary(ggplot2)\n# install.packages(\"datasauRus\")\nlibrary(datasauRus) \nlibrary(scales)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(plotrix) \n\n# install.packages(\"devtools\")\n# devtools::install_github(\"matthewbjane/ThemePark\")\nlibrary(ThemePark)\nlibrary(patchwork)\nlibrary(janitor)\nlibrary(knitr)\nlibrary(kableExtra)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#simple-plot-for-self-reports",
    "href": "chapters/visualization.html#simple-plot-for-self-reports",
    "title": "9  Visualization",
    "section": "13.1 Simple plot for self-reports",
    "text": "13.1 Simple plot for self-reports\n\n\nCode\nggplot(data = data_after_exclusions,\n       aes(x = mean_self_report)) +\n  geom_histogram(binwidth = 1)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#slightly-better-plot-for-self-reports",
    "href": "chapters/visualization.html#slightly-better-plot-for-self-reports",
    "title": "9  Visualization",
    "section": "13.2 Slightly better plot for self-reports",
    "text": "13.2 Slightly better plot for self-reports\n\n\nCode\nggplot(data = data_after_exclusions,\n       aes(x = mean_self_report)) +\n  # more intelligent choices for the binwidth and boundary\n  geom_histogram(binwidth = 1, boundary = 0.5) +\n  # labeling of the axis points\n  scale_x_continuous(breaks = scales::breaks_pretty(n = 7),\n                     limits = c(0.5, 7.5)) +\n  scale_y_continuous(breaks = seq(0, 60, 10)) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#exercise-plot-for-gender",
    "href": "chapters/visualization.html#exercise-plot-for-gender",
    "title": "9  Visualization",
    "section": "13.3 Exercise: Plot for gender",
    "text": "13.3 Exercise: Plot for gender\nCreate a similar plot for the gender variable in data_processed (ie before exclusions).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#exercise-plot-for-amp",
    "href": "chapters/visualization.html#exercise-plot-for-amp",
    "title": "9  Visualization",
    "section": "13.4 Exercise: Plot for AMP",
    "text": "13.4 Exercise: Plot for AMP\nCreate a similar plot for the AMP scores in data_after_exclusions.\n\n\nCode\nmean_amp &lt;- data_after_exclusions |&gt;\n  summarize(mean_amp = mean(amp_score)) |&gt;\n  pull(mean_amp)\n\n\nplot_amp &lt;- \n  ggplot(data = data_after_exclusions,\n         aes(x = amp_score)) +\n  geom_histogram(binwidth = 0.1) +\n  scale_x_continuous(breaks = seq(0, 1, .10),\n                     name = \"AMP score\") +\n  scale_y_continuous(breaks = seq(0, 40, 5),\n                     name = \"Frequency\") +\n  geom_vline(xintercept = mean_amp, linetype = \"dotted\") +\n  theme_linedraw()\n\nplot_amp\n\n\n\n\n\n\n\n\n\nCode\nggsave(plot = plot_amp,\n       filename = \"plots/plot_amp.pdf\", \n       width = 6,\n       height = 5)\n\n\n\nExercise: How to add a dashed vertical line at the sample’s mean AMP score?",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#simple-plot-for-self-reports-1",
    "href": "chapters/visualization.html#simple-plot-for-self-reports-1",
    "title": "9  Visualization",
    "section": "14.1 Simple plot for self-reports",
    "text": "14.1 Simple plot for self-reports\n\n\nCode\nggplot(data = data_after_exclusions,\n       aes(x = mean_self_report)) +\n  geom_density(adjust = 1, # the degree of smoothing can be adjusted here \n               color = \"#FF69B4\",\n               fill = \"darkblue\", \n               alpha = 0.3) +\n  # labeling of the axis points\n  scale_x_continuous(breaks = scales::breaks_pretty(n = 7),\n                     limits = c(1, 7)) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#exercise-plot-for-amp-1",
    "href": "chapters/visualization.html#exercise-plot-for-amp-1",
    "title": "9  Visualization",
    "section": "14.2 Exercise: Plot for AMP",
    "text": "14.2 Exercise: Plot for AMP\nMake a similar density plot for the AMP.\n\nAdd a theme.\nMake the X axis breaks prettier.\nName both axis names more clearly.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#simple-plot-for-amp",
    "href": "chapters/visualization.html#simple-plot-for-amp",
    "title": "9  Visualization",
    "section": "15.1 Simple plot for AMP",
    "text": "15.1 Simple plot for AMP\n\n\nCode\n# create the summary values to be plotted\nsummary_amp &lt;- data_after_exclusions %&gt;%\n  group_by(gender) %&gt;%\n  summarize(amp_mean = mean(amp_score),\n            amp_se = plotrix::std.error(amp_score))\n\n# plot these values\nggplot(data = summary_amp, \n       aes(x = gender, \n           y = amp_mean)) +\n  geom_col() +\n  # geom_bar(stat = \"identity\") + # NB geom_col is equivalent to geom_bar when stat == \"identity\n  geom_linerange(aes(ymin = amp_mean - amp_se, \n                     ymax = amp_mean + amp_se))",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#slightly-better-plot-for-amp",
    "href": "chapters/visualization.html#slightly-better-plot-for-amp",
    "title": "9  Visualization",
    "section": "15.2 Slightly better plot for AMP",
    "text": "15.2 Slightly better plot for AMP\n\n\nCode\nggplot(data = summary_amp, \n       aes(x = gender, \n           y = amp_mean)) +\n  geom_col(fill = \"#0b6623\", # note that you can specify specific colors using hex codes or names\n           color = \"black\", \n           width = 0.6) +\n  geom_errorbar(aes(ymin = amp_mean - amp_se, \n                    ymax = amp_mean + amp_se), \n                width = 0.1, \n                color = \"black\") +\n  labs(title = \"Bar Plot of with Standard Errors\",\n       x = \"Gender\",\n       y = \"Mean AMP score\") +\n  theme_linedraw()",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#exercise-plot-for-self-reports",
    "href": "chapters/visualization.html#exercise-plot-for-self-reports",
    "title": "9  Visualization",
    "section": "15.3 Exercise: Plot for self-reports",
    "text": "15.3 Exercise: Plot for self-reports\nMake a similar plot for the self-reports.\n\nUse coord_flip() to swap the X and Y axes.\n\n\nExercise: How to capitalize ‘Male’ and ‘Female’ by wrangling the data before plotting?",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/visualization.html#exercise",
    "href": "chapters/visualization.html#exercise",
    "title": "9  Visualization",
    "section": "17.1 Exercise",
    "text": "17.1 Exercise\nCreate a plot that assesses the association between self report scores and AMP scores. By wrangling data_processed more prior to plotting, and using facet_grid(), compare a) men vs women and b) participants who are 30+ years old vs younger than 30.\nImprove the appearance of the plot, including its text, colors, theme, etc.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/license.html",
    "href": "chapters/license.html",
    "title": "10  License and citation",
    "section": "",
    "text": "© Ian Hussey (2025)\nText and figures are licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) license.\nCode is licensed under the MIT License.\nYou are free to copy, share, adapt, and reuse the contents of this book — text, figures, and code — for any purpose, including commercial use, provided you cite it.\nCitation:\nHussey, I. (2025) Improving your statistical inferences using Monte Carlo simulation studies in tidyverse. github.com/ianhussey/improving-your-statistical-inferences-through-monte-carlo-simulation-studies",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>License and citation</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#namespace-collisons-a-common-source-of-errors",
    "href": "chapters/fundamentals.html#namespace-collisons-a-common-source-of-errors",
    "title": "2  Fundamentals",
    "section": "2.4 Namespace collisons: a common source of errors",
    "text": "2.4 Namespace collisons: a common source of errors\nSome common packages have identically named functions with different syntax. For example, if you load both {dplyr} and {MASS}, use of the function select() can refer to either dplyr::select() or MASS::select(), and your code might not run if the other package is loaded.\nYou can see if you have two identically named functions loaded by opening the help menu and seeing if more than one entry appears (e.g. with ?select()).\nAvoid this by loading only the packages you need. Debug errors by thinking about these common namespace collisions:\n\n\n\n\n\n\n\n\n\nFunction\ntidyverse Source\nConflicting Package(s)\nNotes\n\n\n\n\nfilter\ndplyr\nstats\nstats::filter() is for signal processing (time series)\n\n\nlag\ndplyr\nstats\nDifferent semantics: dplyr::lag() is simpler\n\n\nselect\ndplyr\nMASS\nMASS::select() is for stepwise regression\n\n\nslice\ndplyr\nIRanges / S4Vectors\nCommon in Bioconductor workflows\n\n\nrename\ndplyr\nMASS\nMASS::rename() is deprecated, but may still load\n\n\nsummarise\ndplyr\nHmisc\nHmisc::summarize() differs in behavior\n\n\nintersect\ndplyr\nbase\ndplyr re-exports base::intersect()\n\n\nunion\ndplyr\nbase\ndplyr re-exports base::union()\n\n\nsetdiff\ndplyr\nbase\ndplyr re-exports base::setdiff()\n\n\ncount\ndplyr\nplyr\nDifferent behavior/output in plyr::count()\n\n\ndesc\ndplyr\nIRanges\nConflicts with IRanges sorting\n\n\nmutate\ndplyr\nplyr\nConflicts common when plyr is loaded\n\n\narrange\ndplyr\nplyr\nSubtle differences; dplyr preferred\n\n\n\nSolve this issue either by specifying which package should be used each time you use the function (e.g., dplyr::select() instead of select()) or by specifying below your library() calls which version is preferred:\n\n\nCode\nlibrary(conflicted)\nconflict_prefer(name = \"select\", winner = \"dplyr\")\n\n\n[conflicted] Will prefer dplyr::select over any other package.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#section",
    "href": "chapters/fundamentals.html#section",
    "title": "2  Fundamentals",
    "section": "2.7 ",
    "text": "2.7",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#accessing-the-help-menu",
    "href": "chapters/fundamentals.html#accessing-the-help-menu",
    "title": "2  Fundamentals",
    "section": "2.3 Accessing the help menu",
    "text": "2.3 Accessing the help menu\nFor any function in a loaded package, simply type ? before the function’s name to bring up the help menu. This helps you understand the function’s purpose, its arguments, and outputs.\n\n\nCode\n?select\n\n\nIf you scroll to the bottom of a function’s help page, you’ll find an ‘Index’ hyperlink. Clicking this brings you to a list of all the package’s functions. Once you get nerdy, this can be a very useful way to discover and learn all a package’s functions.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  },
  {
    "objectID": "chapters/fundamentals.html#dependencies",
    "href": "chapters/fundamentals.html#dependencies",
    "title": "2  Fundamentals",
    "section": "2.2 Dependencies",
    "text": "2.2 Dependencies\nInstall libraries from CRAN with install.packages(). This only needs to be done once, not on every run of the script.\n\n\nCode\ninstall.packages(tidyverse)\n\n\nIn-development libraries are sometimes not on CRAN and can be installed directly from GitHub with devtools::install_github().\n\n\nCode\ninstall.packages(devtools)\ndevtools::install_github(\"ianhussey/tides\") # username/repository\n\n\nNecessary packages (aka dependencies) are loaded with library(). For tidiness, these should all be loaded at the start of your script.\n\n\nCode\nlibrary(tidyverse) # umbrella package that loads dplyr/tidyr/ggplot2 and others",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals</span>"
    ]
  }
]