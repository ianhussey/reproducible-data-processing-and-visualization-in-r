---
title: "Loading, viewing, and saving data"
format:
  html:
    toc: true
    toc_float: true
    code-fold: show
    code-tools: true
    self-contained: true
---

```{r}
#| include: false

# settings, placed in a chunk that will not show in the .html file (because include=FALSE) 

# disables scientific notation so that small numbers appear as eg "0.00001" rather than "1e-05"
options(scipen = 999)  

```

## Loading .csv files

### Relative vs. absolute paths: Avoid using `setwd()!`

When we write .R scripts, we often use `setwd()` to define where files should be loaded from and saved to. The problem with `setwd()` is that it hard-codes file paths that are usually specific to the computer and user. For example, if I write an .R script that includes `setwd("C:/Users/IanHussey/Documents/R_course/")`, before loading some data using `read.csv()`. If I email you this script and data file, it script won't work on your machine unless your folders are identically named; you have to change the file path in `setwd()`. This lowers the reproducibility of the code, as it can't be run trivially by other people on other computers.

This is because `setwd()` uses 'absolute' paths that point to a specific location in a directory structure. One of the very useful features of RMarkdown (.Rmd) and Quarto (.qmd) files is that they instead use 'relative' paths, which specify where a file or directory is *in relation to* the .Rmd or .qmd script. That is, the working directory is by definition wherever the .Rmd or .qmd file is, without being specified.

If I have a directory - located anywhere on my hard drive - called 'R_course' that contains the folders 'code' and 'data', and the 'data' directory itself contains the directories 'processed' and 'raw'. Imagine the files within these directories are as follows:

``` text
R_course/
├── code/
│   ├── analysis.qmd
│   ├── data_shouldnt_usually_go_here.csv
│   └── analysis.qmd
└── data/
    ├── processed/
    │   └── data_processed.csv
    └── raw/
        ├── data_demographics_raw.csv
        ├── data_selfreports_raw.csv
        ├── code_shouldnt_usually_go_here.qmd
        └── data_behavioraltask_raw.csv
```

Because .qmd files use 'relative' paths, to load the 'data_shouldnt_usually_go_here.csv' file I only need to do the following, without any `setwd()` call:

```{r}
#| eval: false # this code chunk is set to not run as the data file doesn't exist
dat <- read.csv("data_shouldnt_usually_go_here.csv")
```

Of course, code and data should be clearly separated within a project so 'data_shouldnt_usually_go_here.csv' should not usually go in that directory, as the name suggests.

If I instead wanted to load 'data_processed.csv', I would do this as follows. This data file actually exists in this project, so the code will run assuming you have the data files in the correct location relative to this .qmd script.

```{r}
dat_processed <- read.csv("../data/processed/data_processed.csv")
```

This is parsed as follows: `../` tells RStudio to go 'up' one directory level from 'analysis.qmd' to the 'R_course' folder that contains it. `data/` then tells it to go 'down' one level into the 'data' folder inside 'R_course'. Likewise, `processed/` then tells it to go 'down' another level into the 'processed' folder, before loading the 'data_processed.csv' file.

Note that `../` can be stacked to go 'up' multiple directory levels, e.g., `../../`.

As long as you send move the entire 'R_course' folder and preserve the relative location between the code and the data, the .qmd file's `read.csv()` call will still work. It doesn't matter whether you the 'R_course' directory to somewhere else on your hard drive, or create a .zip file and email it to someone else, or distribute it via GitHub, or whether they're using Windows or Mac.

Also note that because the directory 'R_course' is never specified in the `read.csv()` call, it can be called anything else and still work. The same goes for the name of the script which calls `read.csv()` - in this case, the script you're reading is called 'loading_data.qmd' and the code still works.

FYI, you can also use relative paths in regular .R files using the {here} library (see <https://here.r-lib.org/>).

### Check your learning

**Question:** Using the above file structure diagram, what R code is needed to load the 'data_shouldnt_usually_go_here.csv' file from the 'code_shouldnt_usually_go_here.qmd'? 

::: {.callout-note collapse=true title="Click to show answer"}
```{r}
#| eval: false # this code chunk is set to not run as the code file doesn't exist
dat <- read.csv("../../code/data_shouldnt_usually_go_here.csv")
```
:::

## Viewing data frames

### In your environment

Data frames (and other objects) that have already been loaded into your R environment will appear under the 'files' tab in RStudio. 

You can view them by clicking on them in the files tab, or in the Source window (where code appears) with Cmd+click (on Mac) or Ctrl+click (on Windows). 

```{r}
#| eval: false 
#| include: false

# To view the contents of 'dat_processed', double click 'dat_processed' below to highlight it, then press and hold Cmd (on Mac) or Ctrl (on Windows) + click 'dat_processed' 

dat_processed

```

### Printing data frames below chunks

To print a data frame below the code chunk, you can;

Run the object name:

```{r}
dat_processed
```

Use `print()`:

```{r}
print(dat_processed)
```

### Printing data frames more nicely

Printing data frames by calling their name or using `print()` don't produce very attractive tables. You can improve this using a combination of the {knitr} and {kableExtra} packages. 

Note that this code uses the 'pipe', which we cover in more detail in the next chapter.

```{r}
library(knitr)
library(kableExtra)

dat_processed %>%
  knitr::kable(align = "r") %>%
  kableExtra::kable_styling(full_width = FALSE)
```

```{r}
#| echo: false
#| include: false
# You can also print more APA-style tables, although they're slightly harder to read, using `kableExtra::kable_classic()`. 
# This will work when your script runs on your local machine, but won't render on the website version of this book for reasons I can't quite figure out.
# This chunk is set to not run or show for the book, but you can run the code below directly if you're using the script locally and therefore able to read this.

dat_processed |>
  knitr::kable(align = "r") |>
  kableExtra::kable_classic(full_width = FALSE)
```

## Saving .csv files

Writing .csv files to disk is as easy as loading them.

```{r}

write.csv(x = dat_processed, # the data frame to save
          file = "../data/processed/data_processed.csv") # the file to save it to

```

## Loading .xlsx files

While .csv files are a good default file format to use for most projects, Excel, SPSS, and other file formats can also be loaded.

There are several packages available to load Excel files in particular. Any of them are fine *except* `library(xlsx)` which requires you to install rJava, which often causes compatibility issues. `library(readxl)` is a safer bet. Because excel files can contain multiple sheets, the source can be specified with the `sheet` argument.

```{r}
library(readxl)

dat_likert_1 <- readxl::read_excel(path = "../data/raw/data_likert.xlsx", 
                                   sheet = "data1")
```

### Check your learning

**Question:** How would you know what arguments `readxl::read_excel()` takes?

::: {.callout-note collapse=true title="Click to show answer"}

By consulting the help menu with `r ?readxl::read_excel()`.

:::

### Preserving the raw data / skipping rows when loading

With a few exceptions (e.g., removing identifying information before making data public), you should not manually modify raw data.

Sometimes extra rows etc. make a data file harder to read into R. For example, the column names in 'data_likert.xlsx' are on the fourth row, causing a mess when you load the file:

```{r}
# head() allows you to see the first few rows of an R object. conversely, tail() shows the last few. 
head(dat_likert_1)
```

Handle with with code, not by deleting the information in those rows. When using `read.csv()` or `readxl::read_excel()` this can be done using the `skip` argument.

```{r}
dat_likert_1 <- readxl::read_excel(path = "../data/raw/data_likert.xlsx", 
                                   sheet = "data1", 
                                   skip = 3)

dat_likert_1
```

## Combining multiple data sets

You can combine multiple data sets with (nearly) the same structure using `dplyr::bind_rows()`. In this case, 'data_likert.xlsx' have mostly the same columns, with sheet 1 also having the 'likert_2' column. Missing columns are filled with NA when using `dplyr::bind_rows()`. This has its advantages over base R's `rbind()` which requires that column names must match between the objects.

```{r}
library(dplyr)

dat_likert_1 <- readxl::read_excel("../data/raw/data_likert.xlsx", sheet = "data1", skip = 3)
dat_likert_2 <- readxl::read_excel("../data/raw/data_likert.xlsx", sheet = "data2", skip = 3)

dat_likert <- dplyr::bind_rows(dat_likert_1,
                               dat_likert_2)

dat_likert
```

## Loading and writing .rda files

R objects can also be saved and loaded as .rda files. This can be very useful if you want to a) compress the data to make it smaller (using the `compress = "gz"` argument) or b) to preserve things like column types and factor levels. However, it does slightly reduce the interoperability of the data as not everyone else uses R. 

```{r}
library(readr)

# write
readr::write_rds(x = dat_likert, 
                 file = "../data/raw/dat_likert.rda",
                 compress = "gz")

# read
dat_likert <- readr::read_rds(file = "../data/raw/dat_likert.rda")
```

## Loading multiple data files at once

Some psychology software such as PsychoPy often saves each participant's data as a separate .csv file. FYI you can write code to find all files of a given type (e.g., .csv) in a folder, read them all in, and bind all the data together as a single data frame. Note that this code uses some packages and functions we won't cover until later in the course. I include it here just so that you know that it can be done quite easily.

```{r}
#| eval: false # this code chunk is set to not run as the code file doesn't exist
library(purrr)

# list all the files in a directory
file_names <- list.files(path = "../data/raw/individual_files", 
                         pattern = "\\.csv$", 
                         full.names = TRUE)

# use (or 'map') the read_csv function onto each of the file names 
data_combined <- purrr::map_dfr(.x = file_names, .f = read.csv)
```


